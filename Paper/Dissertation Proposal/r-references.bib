@Manual{R-base,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2023},
  url = {https://www.R-project.org/},
}
@Manual{R-papaja,
  title = {{papaja}: {Prepare} reproducible {APA} journal articles with {R Markdown}},
  author = {Frederik Aust and Marius Barth},
  year = {2023},
  note = {R package version 0.1.2},
  url = {https://github.com/crsh/papaja},
}
@Manual{R-tinylabels,
  title = {{tinylabels}: Lightweight Variable Labels},
  author = {Marius Barth},
  year = {2023},
  note = {R package version 0.2.4},
  url = {https://cran.r-project.org/package=tinylabels},
}

@article{liddellAnalyzingOrdinalData2018,
  title = {Analyzing Ordinal Data with Metric Models: {{What}} Could Possibly Go Wrong?},
  shorttitle = {Analyzing Ordinal Data with Metric Models},
  author = {Liddell, Torrin M. and Kruschke, John K.},
  year = {2018},
  journal = {Journal of Experimental Social Psychology},
  volume = {79},
  pages = {328--348},
  publisher = {Elsevier Science},
  address = {Netherlands},
  issn = {1096-0465},
  doi = {10.1016/j.jesp.2018.08.009},
  abstract = {We surveyed all articles in the Journal of Personality and Social Psychology (JPSP), Psychological Science (PS), and the Journal of Experimental Psychology: General (JEP:G) that mentioned the term ``Likert,'' and found that 100\% of the articles that analyzed ordinal data did so using a metric model. We present novel evidence that analyzing ordinal data as if they were metric can systematically lead to errors. We demonstrate false alarms (i.e., detecting an effect where none exists, Type I errors) and failures to detect effects (i.e., loss of power, Type II errors). We demonstrate systematic inversions of effects, for which treating ordinal data as metric indicates the opposite ordering of means than the true ordering of means. We show the same problems---false alarms, misses, and inversions---for interactions in factorial designs and for trend analyses in regression. We demonstrate that averaging across multiple ordinal measurements does not solve or even ameliorate these problems. A central contribution is a graphical explanation of how and when the misrepresentations occur. Moreover, we point out that there is no sure-fire way to detect these problems by treating the ordinal values as metric, and instead we advocate use of ordered-probit models (or similar) because they will better describe the data. Finally, although frequentist approaches to some ordered-probit models are available, we use Bayesian methods because of their flexibility in specifying models and their richness and accuracy in providing parameter estimates. An R script is provided for running an analysis that compares ordered-probit and metric models. (PsycINFO Database Record (c) 2018 APA, all rights reserved)},
  keywords = {Experimental Psychology,Mathematical Modeling,Statistical Analysis,Statistical Data,Type I Errors,Type II Errors},
  file = {/Users/jimmy_z/Zotero/storage/DHL6L7IK/Liddell and Kruschke - 2018 - Analyzing ordinal data with metric models What co.pdf;/Users/jimmy_z/Zotero/storage/S5FAVZ76/2018-51082-031.html}
}

@incollection{agrestiCategoricalDataAnalysis2011,
  title = {Categorical {{Data Analysis}}},
  booktitle = {International {{Encyclopedia}} of {{Statistical Science}}},
  author = {Agresti, Alan and Kateri, Maria},
  editor = {Lovric, Miodrag},
  year = {2011},
  pages = {206--208},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-04898-2_161},
  urldate = {2024-04-12},
  isbn = {978-3-642-04898-2},
  langid = {english}
}

@article{abellSystematicReviewSimulation2023,
  title = {A Systematic Review of Simulation Studies Which Compare Existing Statistical Methods to Account for Non-Compliance in Randomised Controlled Trials},
  author = {Abell, Lucy and Maher, Francesca and Jennings, Angus C and Gray, Laura J},
  year = {2023},
  month = dec,
  journal = {BMC Med Res Methodol},
  volume = {23},
  pages = {300},
  issn = {1471-2288},
  doi = {10.1186/s12874-023-02126-w},
  urldate = {2024-04-12},
  abstract = {Introduction Non-compliance is a common challenge for researchers and may reduce the power of an intention-to-treat analysis. Whilst a per protocol approach attempts to deal with this issue, it can result in biased estimates. Several methods to resolve this issue have been identified in previous reviews, but there is limited evidence supporting their use. This review aimed to identify simulation studies which compare such methods, assess the extent to which certain methods have been investigated and determine their performance under various scenarios. Methods A systematic search of several electronic databases including MEDLINE and Scopus was carried out from conception to 30th November 2022. Included papers were published in a peer-reviewed journal, readily available in the English language and focused on comparing relevant methods in a superiority randomised controlled trial under a simulation study. Articles were screened using these criteria and a predetermined extraction form used to identify relevant information. A quality assessment appraised the risk of bias in individual studies. Extracted data was synthesised using tables, figures and a narrative summary. Both screening and data extraction were performed by two independent reviewers with disagreements resolved by consensus. Results Of 2325 papers identified, 267 full texts were screened and 17 studies finally included. Twelve methods were identified across papers. Instrumental variable methods were commonly considered, but many authors found them to be biased in some settings. Non-compliance was generally assumed to be all-or-nothing and only occurring in the intervention group, although some methods considered it as time-varying. Simulation studies commonly varied the level and type of non-compliance and factors such as effect size and strength of confounding. The quality of papers was generally good, although some lacked detail and justification. Therefore, their conclusions were deemed to be less reliable. Conclusions It is common for papers to consider instrumental variable methods but more studies are needed that consider G-methods and compare a wide range of methods in realistic scenarios. It is difficult to make conclusions about the best method to deal with non-compliance due to a limited body of evidence and the difficulty in combining results from independent simulation studies. PROSPERO registration number CRD42022370910. Supplementary Information The online version contains supplementary material available at 10.1186/s12874-023-02126-w.},
  pmcid = {PMC10724933},
  pmid = {38104108},
  file = {/Users/jimmy_z/Zotero/storage/7PZKLG63/Abell et al. - 2023 - A systematic review of simulation studies which co.pdf}
}

@article{aglerInterpretationUseMediation2017,
  title = {On the {{Interpretation}} and {{Use}} of {{Mediation}}: {{Multiple Perspectives}} on {{Mediation Analysis}}},
  shorttitle = {On the {{Interpretation}} and {{Use}} of {{Mediation}}},
  author = {Agler, Robert and De Boeck, Paul},
  year = {2017},
  month = nov,
  journal = {Front. Psychol.},
  volume = {8},
  publisher = {Frontiers},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2017.01984},
  urldate = {2024-04-08},
  abstract = {{$<$}p{$>$}Mediation analysis has become a very popular approach in psychology, and it is one that is associated with multiple perspectives that are often at odds, often implicitly. Explicitly discussing these perspectives and their motivations, advantages, and disadvantages can help to provide clarity to conversations and research regarding the use and refinement of mediation models. We discuss five such pairs of perspectives on mediation analysis, their associated advantages and disadvantages, and their implications: with vs. without a mediation hypothesis, specific effects vs. a global model, directness vs. indirectness of causation, effect size vs. null hypothesis testing, and hypothesized vs. alternative explanations. Discussion of the perspectives is facilitated by a small simulation study. Some philosophical and linguistic considerations are briefly discussed, as well as some other perspectives we do not develop here.{$<$}/p{$>$}},
  langid = {english},
  keywords = {causation,Direct effect,indirect effect,Mediation,Total effect},
  file = {/Users/jimmy_z/Zotero/storage/ZVTXC8BT/Agler and De Boeck - 2017 - On the Interpretation and Use of Mediation Multip.pdf}
}

@article{aguinisEffectSizePower2005,
  title = {Effect {{Size}} and {{Power}} in {{Assessing Moderating Effects}} of {{Categorical Variables Using Multiple Regression}}: {{A}} 30-{{Year Review}}},
  shorttitle = {Effect {{Size}} and {{Power}} in {{Assessing Moderating Effects}} of {{Categorical Variables Using Multiple Regression}}},
  author = {Aguinis, Herman and Beaty, James C. and Boik, Robert J. and Pierce, Charles A.},
  year = {2005},
  journal = {Journal of Applied Psychology},
  volume = {90},
  number = {1},
  pages = {94--107},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1854},
  doi = {10.1037/0021-9010.90.1.94},
  abstract = {The authors conducted a 30-year review (1969-1998) of the size of moderating effects of categorical variables as assessed using multiple regression. The median observed effect size (f{$^2$}) is only .002, but 72\% of the moderator tests reviewed had power of .80 or greater to detect a targeted effect conventionally defined as small. Results suggest the need to minimize the influence of artifacts that produce a downward bias in the observed effect size and put into question the use of conventional definitions of moderating effect sizes. As long as an effect has a meaningful impact, the authors advise researchers to conduct a power analysis and plan future research designs on the basis of smaller and more realistic targeted effect sizes. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Effect Size (Statistical),Multiple Regression,Statistical Power,Statistical Variables},
  file = {/Users/jimmy_z/Zotero/storage/FLFZUQAZ/2004-22497-007.html}
}

@article{alginaNoteEstimatingJoreskogYang2001a,
  title = {A Note on Estimating the {{J{\"o}reskog-Yang}} Model for Latent Variable Interaction Using {{LISREL}} 8.3.},
  author = {Algina, James and Moulder, Bradley C.},
  year = {2001},
  journal = {Structural Equation Modeling},
  volume = {8},
  number = {1},
  pages = {40--52},
  publisher = {Lawrence Erlbaum},
  address = {US},
  issn = {1532-8007},
  doi = {10.1207/S15328007SEM0801_3},
  abstract = {D. A. Kenny and C. M. Judd (1984) developed a latent variable interaction model for observed variables centered around their population means. They estimated the model by using a covariance matrix calculated from sample-mean-centered variables and products of these variables. Subsequently, J{\"o}reskog and Yang (1996) identified the need to include intercepts for the measurement and structural equations and estimated the model by using a covariance matrix calculated from noncentered observed variables and products of these variables, and means of the observed variables and the products of noncentered variables. Evidence is presented that the J{\"o}reskog-Yang procedure for estimating the Kenny-Judd interaction model is subject to severe convergence problems when implemented in LISREL8.3 and means for the indicators of the latent exogenous variables are nonzero. An alternative procedure is presented that solves the convergence problem and provides consistent estimators of the parameters. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Estimation,Interaction Analysis (Statistics),Latent Variables,Models},
  file = {/Users/jimmy_z/Zotero/storage/FUZLC4IR/2001-03013-003.html}
}

@article{asparouhovBayesianEstimationSingle2021,
  title = {Bayesian Estimation of Single and Multilevel Models with Latent Variable Interactions},
  author = {Asparouhov, Tihomir and Muth{\'e}n, Bengt},
  year = {2021},
  journal = {Structural Equation Modeling},
  volume = {28},
  number = {2},
  pages = {314--328},
  publisher = {Taylor \& Francis},
  address = {United Kingdom},
  issn = {1532-8007},
  doi = {10.1080/10705511.2020.1761808},
  abstract = {In this article, we discuss single and multilevel SEM models with latent variable interactions. We describe the Bayesian estimation for these models and show through simulation studies that the Bayesian method outperforms other methods such as the maximum-likelihood method. We show that multilevel moderation models can easily be estimated with the Bayesian method. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Bayesian Analysis,Latent Variables,Simulation,Statistical Estimation,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/7YJ84ZFJ/2020-48398-001.html}
}

@article{ayturkExploringPerformanceLatent2021,
  title = {Exploring the {{Performance}} of {{Latent Moderated Structural Equations Approach}} for {{Ordered-Categorical Items}}},
  author = {Ayt{\"u}rk, Ezgi and Cham, Heining and Jennings, Patricia A. and Brown, Joshua L.},
  year = {2021},
  month = may,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {28},
  number = {3},
  pages = {410--422},
  publisher = {Routledge},
  issn = {1070-5511},
  doi = {10.1080/10705511.2020.1810047},
  urldate = {2024-03-10},
  abstract = {Latent moderated structural equations (LMS) is a popular method in estimating latent interaction effects. Mplus has implemented a variant of LMS (LMS-cat) that uses categorical confirmatory factor analysis to handle ordered-categorical indicators. We conducted a simulation study to examine the performance of the LMS-cat in varying sample size, interaction effect size, missing data rate and scenario, as well as number and symmetry of item response category conditions. Results showed that the LMS-cat is an excellent method in estimating structural parameters (i.e., interaction effect and lower-order effects). However, it could produce highly biased measurement parameters (i.e., factor loadings, and item category thresholds). We illustrated the LMS-cat by testing the interaction effect between participation in teachers` support activities and that of teachers` counterfactual activities (meditation, meditative movement, vigorous physical exercise) on teachers` sense of self-efficacy.},
  keywords = {categorical data,Latent interaction,latent moderated structural equations},
  file = {/Users/jimmy_z/Zotero/storage/X782RWHR/Aytürk et al. - 2021 - Exploring the Performance of Latent Moderated Stru.pdf}
}

@article{ayturkLatentVariableInteractions2020,
  title = {Latent {{Variable Interactions With Ordered-Categorical Indicators}}: {{Comparisons}} of {{Unconstrained Product Indicator}} and {{Latent Moderated Structural Equations Approaches}}},
  shorttitle = {Latent {{Variable Interactions With Ordered-Categorical Indicators}}},
  author = {Ayt{\"u}rk, Ezgi and Cham, Heining and Jennings, Patricia A. and Brown, Joshua L.},
  year = {2020},
  month = apr,
  journal = {Educ Psychol Meas},
  volume = {80},
  number = {2},
  pages = {262--292},
  issn = {1552-3888},
  doi = {10.1177/0013164419865017},
  abstract = {Methods to handle ordered-categorical indicators in latent variable interactions have been developed, yet they have not been widely applied. This article compares the performance of two popular latent variable interaction modeling approaches in handling ordered-categorical indicators: unconstrained product indicator (UPI) and latent moderated structural equations (LMS). We conducted a simulation study across sample sizes, indicators' distributions and category conditions. We also studied four strategies to create sets of product indicators for UPI. Results supported using a parceling strategy to create product indicators in the UPI approach or using the LMS approach when the categorical indicators are symmetrically distributed. We applied these models to study the interaction effect between third- to fifth-grade students' social skills improvement and teacher-student closeness on their state English language arts test scores.},
  langid = {english},
  pmcid = {PMC7047260},
  pmid = {32158022},
  keywords = {categorical data,latent interaction,parceling,product indicator},
  file = {/Users/jimmy_z/Zotero/storage/3G6J94XV/Aytürk et al. - 2020 - Latent Variable Interactions With Ordered-Categori.pdf}
}

@book{azenCategoricalDataAnalysis2021,
  title = {Categorical {{Data Analysis}} for the {{Behavioral}} and {{Social Sciences}}},
  author = {Azen, Razia and Walker, Cindy M.},
  year = {2021},
  month = may,
  edition = {2},
  publisher = {Routledge},
  address = {New York},
  doi = {10.4324/9780429330308},
  abstract = {Featuring a practical approach with numerous examples, the second edition of Categorical Data Analysis for the Behavioral and Social Sciences focuses on helping the reader develop a conceptual understanding of categorical methods, making it a much more accessible text than others on the market. The authors cover common categorical analysis methods and emphasize specific research questions that can be addressed by each analytic procedure, including how to obtain results using SPSS, SAS, and R, so that readers are able to address the research questions they wish to answer. Each chapter begins with a "Look Ahead" section to highlight key content. This is followed by an in-depth focus and explanation of the relationship between the initial research question, the use of software to perform the analyses, and how to interpret the output substantively. Included at the end of each chapter are a range of software examples and questions to test knowledge. New to the second edition: The addition of R syntax for all analyses and an update of SPSS and SAS syntax. The addition of a new chapter on GLMMs. Clarification of concepts and ideas that graduate students found confusing, including revised problems at the end of the chapters. Written for those without an extensive mathematical background, this book is ideal for a graduate course in categorical data analysis taught in departments of psychology, educational psychology, human development and family studies, sociology, public health, and business. Researchers in these disciplines interested in applying these procedures will also appreciate this book's accessible approach.},
  isbn = {978-0-429-33030-8}
}

@article{blackwellReducingModelMisspecification2022,
  title = {Reducing {{Model Misspecification}} and {{Bias}} in the {{Estimation}} of {{Interactions}}},
  author = {Blackwell, Matthew and Olson, Michael P.},
  year = {2022},
  month = oct,
  journal = {Political Analysis},
  volume = {30},
  number = {4},
  pages = {495--514},
  issn = {1047-1987, 1476-4989},
  doi = {10.1017/pan.2021.19},
  urldate = {2024-03-25},
  abstract = {Analyzing variation in treatment effects across subsets of the population is an important way for social scientists to evaluate theoretical arguments. A common strategy in assessing such treatment effect heterogeneity is to include a multiplicative interaction term between the treatment and a hypothesized effect modifier in a regression model. Unfortunately, this approach can result in biased inferences due to unmodeled interactions between the effect modifier and other covariates, and including these interactions can lead to unstable estimates due to overfitting. In this paper, we explore the usefulness of machine learning algorithms for stabilizing these estimates and show how many off-the-shelf adaptive methods lead to two forms of bias: direct and indirect regularization bias. To overcome these issues, we use a post-double selection approach that utilizes several lasso estimators to select the interactions to include in the final model. We extend this approach to estimate uncertainty for both interaction and marginal effects. Simulation evidence shows that this approach has better performance than competing methods, even when the number of covariates is large. We show in two empirical examples that the choice of method leads to dramatically different conclusions about effect heterogeneity.},
  langid = {english},
  keywords = {interactions,lasso,machine learning,regression},
  file = {/Users/jimmy_z/Zotero/storage/2CRUPDKE/Blackwell and Olson - 2022 - Reducing Model Misspecification and Bias in the Es.pdf}
}

@article{bollenLatentVariablesPsychology2002b,
  title = {Latent Variables in Psychology and the Social Sciences},
  author = {Bollen, Kenneth A.},
  year = {2002},
  journal = {Annu Rev Psychol},
  volume = {53},
  pages = {605--634},
  issn = {0066-4308},
  doi = {10.1146/annurev.psych.53.100901.135239},
  abstract = {The paper discusses the use of latent variables in psychology and social science research. Local independence, expected value true scores, and nondeterministic functions of observed variables are three types of definitions for latent variables. These definitions are reviewed and an alternative "sample realizations" definition is presented. Another section briefly describes identification, latent variable indeterminancy, and other properties common to models with latent variables. The paper then reviews the role of latent variables in multiple regression, probit and logistic regression, factor analysis, latent curve models, item response theory, latent class analysis, and structural equation models. Though these application areas are diverse, the paper highlights the similarities as well as the differences in the manner in which the latent variables are defined and used. It concludes with an evaluation of the different definitions of latent variables and their properties.},
  langid = {english},
  pmid = {11752498},
  keywords = {Factor Analysis Statistical,Humans,Psychology,Social Sciences}
}

@incollection{bollenTwostageLeastSquares1998,
  title = {Two-Stage Least Squares Estimation of Interaction Effects},
  booktitle = {Interaction and Nonlinear Effects in Structural Equation Modeling},
  author = {Bollen, Kenneth A. and Paxton, Pamela},
  year = {1998},
  pages = {125--151},
  publisher = {Lawrence Erlbaum Associates Publishers},
  address = {Mahwah, NJ, US},
  abstract = {Provides a largely nontechnical description of an alternative technique to include interactions of latent variables in structural equation modeling. This technique avoids many of the problems associated with other methods. Specifically, the purposes are to: (1) give an overview of a 2-stage least squares (2SLS) method to estimate interactions of latent variables, (2) provide guidance on the selection of the instrumental variables that are part of the procedure, (3) contrast this method with other multiple-indicator methods, and (4) compare the results of the 2SLS method with the others using both a simulation and an empirical example. The next section gives a generic description of a model with interactions of latent variables with multiple indicators. Following that, a section is presented on the 2-stage least squares method to model such interactions. Then the authors discuss the D. A. Kenny and C. M. Judd (1984) approach and related methods for handling such interactions. The next section compares the 2 techniques with the simulation and empirical data that Kenny and Judd provided in their original paper. Another empirical examples of the 2SLS method follows.  SAS programs are appended. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  isbn = {978-0-8058-2950-1 978-0-8058-2951-8},
  keywords = {Latent Variables,Least Squares,Statistical Variables,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/D97C7ICW/1998-07854-006.html}
}

@article{hoaglinReportingComputationBasedResults1975,
  title = {The {{Reporting}} of {{Computation-Based Results}} in {{Statistics}}},
  author = {Hoaglin, David C. and Andrews, David F.},
  year = {1975},
  month = aug,
  journal = {The American Statistician},
  volume = {29},
  number = {3},
  pages = {122--126},
  publisher = {Taylor \& Francis},
  issn = {0003-1305},
  doi = {10.1080/00031305.1975.10477393},
  urldate = {2024-04-12},
  file = {/Users/jimmy_z/Zotero/storage/UB478KQK/Hoaglin and Andrews - 1975 - The Reporting of Computation-Based Results in Stat.pdf}
}

@article{simmonsFalsePositivePsychologyUndisclosed2011,
  title = {False-{{Positive Psychology}}: {{Undisclosed Flexibility}} in {{Data Collection}} and {{Analysis Allows Presenting Anything}} as {{Significant}}},
  shorttitle = {False-{{Positive Psychology}}},
  author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
  year = {2011},
  month = nov,
  journal = {Psychol Sci},
  volume = {22},
  number = {11},
  pages = {1359--1366},
  publisher = {SAGE Publications Inc},
  issn = {0956-7976},
  doi = {10.1177/0956797611417632},
  urldate = {2024-04-12},
  abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists' nominal endorsement of a low rate of false-positive findings ({$\leq$} .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/HKTJ4VJS/Simmons et al. - 2011 - False-Positive Psychology Undisclosed Flexibility.pdf}
}

@article{boomsmaReportingMonteCarlo2013,
  title = {Reporting {{Monte Carlo Studies}} in {{Structural Equation Modeling}}},
  author = {Boomsma, Anne},
  year = {2013},
  month = jul,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {20},
  number = {3},
  pages = {518--540},
  publisher = {Routledge},
  issn = {1070-5511},
  doi = {10.1080/10705511.2013.797839},
  urldate = {2024-04-10},
  abstract = {In structural equation modeling, Monte Carlo simulations have been used increasingly over the last two decades, as an inventory from the journal Structural Equation Modeling illustrates. Reaching out to a broad audience, this article provides guidelines for reporting Monte Carlo studies in that field. The framework of discourse is set by a number of steps to be taken in such research, matching outlines of experimental design by Paxton, Curran, Bollen, Kirby, and Chen (2001) and Skrondal (2000). Throughout the article, reference is made to exemplary publications and, occasionally, to imperfect reporting.},
  keywords = {guidelines,Monte Carlo studies,reporting,structural equation modeling},
  file = {/Users/jimmy_z/Zotero/storage/5KQ7PYDJ/Boomsma - 2013 - Reporting Monte Carlo Studies in Structural Equati.pdf}
}

@article{boomsmaRobustnessLISRELSmall1982,
  title = {The Robustness of {{LISREL}} against Small Sample Sizes in Factor Analysis Models},
  author = {Boomsma, A.},
  year = {1982},
  journal = {Part I},
  series = {Part {{I}} ; 1. - {{Amsterdam}} [u.a.] : {{North-Holland Publ}}. {{Co}}.. - 1982, p. 149-173},
  volume = {1}
}

@book{brownConfirmatoryFactorAnalysis2015a,
  title = {Confirmatory Factor Analysis for Applied Research, 2nd Ed},
  author = {Brown, Timothy A.},
  year = {2015},
  series = {Confirmatory Factor Analysis for Applied Research, 2nd Ed},
  pages = {xvii, 462},
  publisher = {The Guilford Press},
  address = {New York, NY, US},
  abstract = {With its emphasis on practical and conceptual aspects, rather than mathematics or formulas, This accessible book has established itself as the go-to resource on confirmatory factor analysis (CFA). Detailed, worked-through examples drawn from psychology, management, and sociology studies illustrate the procedures, pitfalls, and extensions of CFA methodology. The text shows how to formulate, program, and interpret CFA models using popular latent variable software packages (LISREL, Mplus, EQS, SAS/CALIS); understand the similarities and differences between CFA and exploratory factor analysis (EFA); and report results from a CFA study. It is filled with useful advice and tables that outline the procedures. The companion website (www.guilford.com/brown3-materials) offers data and program syntax files for most of the research examples, as well as links to CFA-related resources. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  isbn = {978-1-4625-1779-4 978-1-4625-1536-3 978-1-4625-1781-7},
  keywords = {Applied Psychology,Computer Software,Confirmatory Factor Analysis,Factor Analysis,Factor Structure,Latent Variables,Mathematical Modeling,Methodology},
  file = {/Users/jimmy_z/Zotero/storage/Q8WGRWEP/2015-10560-000.html}
}

@article{burtonDesignSimulationStudies2006,
  title = {The Design of Simulation Studies in Medical Statistics},
  author = {Burton, Andrea and Altman, Douglas G. and Royston, Patrick and Holder, Roger L.},
  year = {2006},
  month = dec,
  journal = {Stat Med},
  volume = {25},
  number = {24},
  pages = {4279--4292},
  issn = {0277-6715},
  doi = {10.1002/sim.2673},
  abstract = {Simulation studies use computer intensive procedures to assess the performance of a variety of statistical methods in relation to a known truth. Such evaluation cannot be achieved with studies of real data alone. Designing high-quality simulations that reflect the complex situations seen in practice, such as in prognostic factors studies, is not a simple process. Unfortunately, very few published simulation studies provide sufficient details to allow readers to understand fully all the processes required to design a simulation study. When planning a simulation study, it is recommended that a detailed protocol be produced, giving full details of how the study will be performed, analysed and reported. This paper details the important considerations necessary when designing any simulation study, including defining specific objectives of the study, determining the procedures for generating the data sets and the number of simulations to perform. A checklist highlighting the important considerations when designing a simulation study is provided. A small review of the literature identifies the current practices within published simulation studies.},
  langid = {english},
  pmid = {16947139},
  keywords = {Biomedical Research,Biometry,Computer Simulation,Humans,Research Design}
}

@article{carletonCenterEpidemiologicStudies2013a,
  title = {The {{Center}} for {{Epidemiologic Studies Depression Scale}}: {{A Review}} with a {{Theoretical}} and {{Empirical Examination}} of {{Item Content}} and {{Factor Structure}}},
  shorttitle = {The {{Center}} for {{Epidemiologic Studies Depression Scale}}},
  author = {Carleton, R. Nicholas and Thibodeau, Michel A. and Teale, Michelle J. N. and Welch, Patrick G. and Abrams, Murray P. and Robinson, Thomas and Asmundson, Gordon J. G.},
  year = {2013},
  month = mar,
  journal = {PLoS One},
  volume = {8},
  number = {3},
  pages = {e58067},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0058067},
  urldate = {2024-03-13},
  abstract = {Background The Center for Epidemiologic Studies Depression Scale (CES-D; Radloff, 1977) is a commonly used freely available self-report measure of depressive symptoms. Despite its popularity, several recent investigations have called into question the robustness and suitability of the commonly used 4-factor 20-item CES-D model. The goal of the current study was to address these concerns by confirming the factorial validity of the CES-D. Methods and Findings Differential item functioning estimates were used to examine sex biases in item responses, and confirmatory factor analyses were used to assess prior CES-D factor structures and new models heeding current theoretical and empirical considerations. Data used for the analyses included undergraduate (n{$\mkern1mu$}={$\mkern1mu$}948; 74\% women), community (n{$\mkern1mu$}={$\mkern1mu$}254; 71\% women), rehabilitation (n{$\mkern1mu$}={$\mkern1mu$}522; 53\% women), clinical (n{$\mkern1mu$}={$\mkern1mu$}84; 77\% women), and National Health and Nutrition Examination Survey (NHANES; n{$\mkern1mu$}={$\mkern1mu$}2814; 56\% women) samples. Differential item functioning identified an item as inflating CES-D scores in women. Comprehensive comparison of the several models supported a novel, psychometrically robust, and unbiased 3-factor 14-item solution, with factors (i.e., negative affect, anhedonia, and somatic symptoms) that are more in line with current diagnostic criteria for depression. Conclusions Researchers and practitioners may benefit from using the novel factor structure of the CES-D and from being cautious in interpreting results from the originally proposed scale. Comprehensive results, implications, and future research directions are discussed.},
  pmcid = {PMC3585724},
  pmid = {23469262},
  file = {/Users/jimmy_z/Zotero/storage/WMX3YLGT/Carleton et al. - 2013 - The Center for Epidemiologic Studies Depression Sc.pdf}
}

@article{chamEstimatingLatentVariable2012b,
  title = {Estimating {{Latent Variable Interactions With Non-Normal Observed Data}}: {{A Comparison}} of {{Four Approaches}}},
  shorttitle = {Estimating {{Latent Variable Interactions With Non-Normal Observed Data}}},
  author = {Cham, Heining and West, Stephen G. and Ma, Yue and Aiken, Leona S.},
  year = {2012},
  month = nov,
  journal = {Multivariate Behav Res},
  volume = {47},
  number = {6},
  pages = {840--876},
  issn = {1532-7906},
  doi = {10.1080/00273171.2012.732901},
  abstract = {A Monte Carlo simulation was conducted to investigate the robustness of four latent variable interaction modeling approaches (Constrained Product Indicator [CPI], Generalized Appended Product Indicator [GAPI], Unconstrained Product Indicator [UPI], and Latent Moderated Structural Equations [LMS]) under high degrees of non-normality of the observed exogenous variables. Results showed that the CPI and LMS approaches yielded biased estimates of the interaction effect when the exogenous variables were highly non-normal. When the violation of non-normality was not severe (normal; symmetric with excess kurtosis {$<$} 1), the LMS approach yielded the most efficient estimates of the latent interaction effect with the highest statistical power. In highly non-normal conditions, the GAPI and UPI approaches with ML estimation yielded unbiased latent interaction effect estimates, with acceptable actual Type-I error rates for both the Wald and likelihood ratio tests of interaction effect at N {$\geq$} 500. An empirical example illustrated the use of the four approaches in testing a latent variable interaction between academic self-efficacy and positive family role models in the prediction of academic performance.},
  langid = {english},
  pmcid = {PMC3583564},
  pmid = {23457417},
  file = {/Users/jimmy_z/Zotero/storage/6S9CL4VY/Cham et al. - 2012 - Estimating Latent Variable Interactions With Non-N.pdf}
}

@article{chamFullInformationMaximum2017,
  title = {Full {{Information Maximum Likelihood Estimation}} for {{Latent Variable Interactions With Incomplete Indicators}}},
  author = {Cham, Heining and Reshetnyak, Evgeniya and Rosenfeld, Barry and Breitbart, William},
  year = {2017},
  journal = {Multivariate Behav Res},
  volume = {52},
  number = {1},
  pages = {12--30},
  issn = {1532-7906},
  doi = {10.1080/00273171.2016.1245600},
  abstract = {Researchers have developed missing data handling techniques for estimating interaction effects in multiple regression. Extending to latent variable interactions, we investigated full information maximum likelihood (FIML) estimation to handle incompletely observed indicators for product indicator (PI) and latent moderated structural equations (LMS) methods. Drawing on the analytic work on missing data handling techniques in multiple regression with interaction effects, we compared the performance of FIML for PI and LMS analytically. We performed a simulation study to compare FIML for PI and LMS. We recommend using FIML for LMS when the indicators are missing completely at random (MCAR) or missing at random (MAR) and when they are normally distributed. FIML for LMS produces unbiased parameter estimates with small variances, correct Type I error rates, and high statistical power of interaction effects. We illustrated the use of these methods by analyzing the interaction effect between advanced cancer patients' depression and change of inner peace well-being on future hopelessness levels.},
  langid = {english},
  pmcid = {PMC5489914},
  pmid = {27834491},
  keywords = {Algorithms,Computer Simulation,Data Interpretation Statistical,Latent interaction,Likelihood Functions,maximum likelihood,missing data,product indicator,Regression Analysis,Sample Size},
  file = {/Users/jimmy_z/Zotero/storage/DIS6CC54/Cham et al. - 2017 - Full Information Maximum Likelihood Estimation for.pdf}
}

@article{cheungAccuracyParameterEstimates2017,
  title = {Accuracy of {{Parameter Estimates}} and {{Confidence Intervals}} in {{Moderated Mediation Models}}: {{A Comparison}} of {{Regression}} and {{Latent Moderated Structural Equations}}},
  shorttitle = {Accuracy of {{Parameter Estimates}} and {{Confidence Intervals}} in {{Moderated Mediation Models}}},
  author = {Cheung, Gordon W. and Lau, Rebecca S.},
  year = {2017},
  month = oct,
  journal = {Organizational Research Methods},
  volume = {20},
  number = {4},
  pages = {746--769},
  publisher = {SAGE Publications Inc},
  issn = {1094-4281},
  doi = {10.1177/1094428115595869},
  urldate = {2024-03-26},
  abstract = {Currently, the most popular analytical method for testing moderated mediation is the regression approach, which is based on observed variables and assumes no measurement error. It is generally acknowledged that measurement errors result in biased estimates of regression coefficients. What has drawn relatively less attention is that the confidence intervals produced by regression are also biased when the variables are measured with errors. Therefore, we extend the latent moderated structural equations (LMS) method---which corrects for measurement errors when estimating latent interaction effects---to the study of the moderated mediation of latent variables. Simulations were conducted to compare the regression approach and the LMS approach. The results show that the LMS method produces accurate estimated effects and confidence intervals. By contrast, regression not only substantially underestimates the effects but also produces inaccurate confidence intervals. It is likely that the statistically significant moderated mediation effects that have been reported in previous studies using regression include biased estimated effects and confidence intervals that do not include the true values.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/T5HJZ42P/Cheung and Lau - 2017 - Accuracy of Parameter Estimates and Confidence Int.pdf}
}

@article{cheungTestingModerationBusiness2021,
  title = {Testing {{Moderation}} in {{Business}} and {{Psychological Studies}} with {{Latent Moderated Structural Equations}}},
  author = {Cheung, Gordon W. and {Cooper-Thomas}, Helena D. and Lau, Rebecca S. and Wang, Linda C.},
  year = {2021},
  month = dec,
  journal = {J Bus Psychol},
  volume = {36},
  number = {6},
  pages = {1009--1033},
  issn = {1573-353X},
  doi = {10.1007/s10869-020-09717-0},
  urldate = {2024-03-25},
  abstract = {Most organizational researchers understand the detrimental effects of measurement errors in testing relationships among latent variables and hence adopt structural equation modeling (SEM) to control for measurement errors. Nonetheless, many of them revert to regression-based approaches, such as moderated multiple regression (MMR), when testing for moderating and other nonlinear effects. The predominance of MMR is likely due to the limited evidence showing the superiority of latent interaction approaches over regression-based approaches combined with the previous complicated procedures for testing latent interactions. In this teaching note, we first briefly explain the latent moderated structural equations (LMS) approach, which estimates latent interaction effects while controlling for measurement errors. Then we explain the reliability-corrected single-indicator LMS (RCSLMS) approach to testing latent interactions with summated scales and correcting for measurement errors, yielding results which approximate those from LMS. Next, we report simulation results illustrating that LMS and RCSLMS outperform MMR in terms of accuracy of point estimates and confidence intervals for interaction effects under various conditions. Then, we show how LMS and RCSLMS can be implemented with Mplus, providing an example-based tutorial to demonstrate a 4-step procedure for testing a range of latent interactions, as well as the decisions at each step. Finally, we conclude with answers to some frequently asked questions when testing latent interactions. As supplementary files to support researchers, we provide a narrated PowerPoint presentation, all Mplus syntax and output files, data sets for numerical examples, and Excel files for conducting the loglikelihood values difference test and plotting the latent interaction effects.},
  langid = {english},
  keywords = {Interaction effects,Latent moderated structural equations,Moderated multiple regression,Moderating effects,Reliability-corrected single-indicator LMS},
  file = {/Users/jimmy_z/Zotero/storage/RSPJ438K/Cheung et al. - 2021 - Testing Moderation in Business and Psychological S.pdf}
}

@article{floraYourCoefficientAlpha2020,
  title = {Your {{Coefficient Alpha Is Probably Wrong}}, but {{Which Coefficient Omega Is Right}}? {{A Tutorial}} on {{Using R}} to {{Obtain Better Reliability Estimates}}},
  shorttitle = {Your {{Coefficient Alpha Is Probably Wrong}}, but {{Which Coefficient Omega Is Right}}?},
  author = {Flora, David B.},
  year = {2020},
  month = dec,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {3},
  number = {4},
  pages = {484--501},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/2515245920951747},
  urldate = {2024-04-12},
  abstract = {Measurement quality has recently been highlighted as an important concern for advancing a cumulative psychological science. An implication is that researchers should move beyond mechanistically reporting coefficient alpha toward more carefully assessing the internal structure and reliability of multi-item scales. Yet a researcher may be discouraged upon discovering that a prominent alternative to alpha, namely, coefficient omega, can be calculated in a variety of ways. In this Tutorial, I alleviate this potential confusion by describing alternative forms of omega and providing guidelines for choosing an appropriate omega estimate pertaining to the measurement of a target construct represented with a confirmatory factor analysis model. Several applied examples demonstrate how to compute different forms of omega in R.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/95YRM3T4/Flora - 2020 - Your Coefficient Alpha Is Probably Wrong, but Whic.pdf}
}

@article{greenReliabilitySummedItem2009,
  title = {Reliability of {{Summed Item Scores Using Structural Equation Modeling}}: {{An Alternative}} to {{Coefficient Alpha}}},
  shorttitle = {Reliability of {{Summed Item Scores Using Structural Equation Modeling}}},
  author = {Green, Samuel B. and Yang, Yanyun},
  year = {2009},
  month = mar,
  journal = {Psychometrika},
  volume = {74},
  number = {1},
  pages = {155--167},
  issn = {1860-0980},
  doi = {10.1007/s11336-008-9099-3},
  urldate = {2024-04-12},
  abstract = {A method is presented for estimating reliability using structural equation modeling (SEM) that allows for nonlinearity between factors and item scores. Assuming the focus is on consistency of summed item scores, this method for estimating reliability is preferred to those based on linear SEM models and to the most commonly reported estimate of reliability, coefficient alpha.},
  langid = {english},
  keywords = {factor analysis of categorical data,reliability,reliability of scales with Likert items,structural equation modeling}
}

@article{cortinaHowAreWe2021a,
  title = {How Are We Testing Interactions in Latent Variable Models? {{Surging}} Forward or Fighting Shy?},
  shorttitle = {How Are We Testing Interactions in Latent Variable Models?},
  author = {Cortina, Jose M. and {Markell-Goldstein}, Hannah M. and Green, Jennifer P. and Chang, Yingyi},
  year = {2021},
  journal = {Organizational Research Methods},
  volume = {24},
  number = {1},
  pages = {26--54},
  publisher = {Sage Publications},
  address = {US},
  issn = {1552-7425},
  doi = {10.1177/1094428119872531},
  abstract = {Latent variable models and interaction effects have both been common in the organizational sciences for some time. Methods for incorporating interactions into latent variable models have existed since at least Kenny and Judd, and a great many articles and books have developed these methods further. In the present article, we present an empirical review of the methods that organizational science investigators use to test their interaction hypotheses. We show that it is very common for investigators to use fully latent methods to test additive portions of their models, but to abandon such methods when testing the multiplicative portions of their models. By contrast, investigators whose models do not contain interactions tend to stick with fully latent methods throughout. As there is little rational basis for this pattern, it is likely due to continued discomfort regarding the proper application of existing fully latent methods. Thus, we end by offering R code that implements some of the more sophisticated fully latent approaches, and by offering a sequence of decisions that investigators can follow in order to choose the best analytic approach. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Latent Variables,Models,Multiple Regression,Organizational Behavior,Quantitative Methods,Sciences,Statistical Variables}
}

@article{croasmunUsingLikertTypeScales2011,
  title = {Using {{Likert-Type Scales}} in the {{Social Sciences}}},
  author = {Croasmun, James T. and Ostrom, Lee},
  year = {2011},
  journal = {Journal of Adult Education},
  volume = {40},
  number = {1},
  pages = {19--22},
  publisher = {Mountain Plains Adult Education Association},
  issn = {0090-4244},
  urldate = {2024-03-17},
  abstract = {Likert scales are useful in social science and attitude research projects. The General Self-Efficacy Exam is a test used to determine whether factors in educational settings affect participant's learning self-efficacy. The original instrument had 10 efficacy items and used a 4-point Likert scale. The Cronbach's alphas for the original test ranged from 0.76 to 0.90. A 5-item Likert scale was created from this instrument by first adding a "3 = neutral/undecided" option and also by adding five negatively-worded items to the instrument. The instrument was piloted with 20 participants. The Cronbach's alpha for this pilot study was 0.87. The instrument was subsequently used in a large research study, and the Cronbach's alpha was found to be 0.88. This yielded an instrument that showed strong internal consistency.},
  langid = {english},
  keywords = {Attitude Measures,Evaluation Research,Item Analysis,Likert Scales,Measures (Individuals),Questionnaires,Replication (Evaluation),Research Projects,Self Efficacy,Social Sciences},
  annotation = {ERIC Number: EJ961998},
  file = {/Users/jimmy_z/Zotero/storage/N8B5KT4R/Croasmun and Ostrom - 2011 - Using Likert-Type Scales in the Social Sciences.pdf}
}

@article{dawsonModerationManagementResearch2014,
  title = {Moderation in {{Management Research}}: {{What}}, {{Why}}, {{When}}, and {{How}}},
  shorttitle = {Moderation in {{Management Research}}},
  author = {Dawson, Jeremy F.},
  year = {2014},
  month = mar,
  journal = {J Bus Psychol},
  volume = {29},
  number = {1},
  pages = {1--19},
  issn = {1573-353X},
  doi = {10.1007/s10869-013-9308-7},
  urldate = {2024-03-11},
  abstract = {Many theories in management, psychology, and other disciplines rely on moderating variables: those which affect the strength or nature of the relationship between two other variables. Despite the near-ubiquitous nature of such effects, the methods for testing and interpreting them are not always well understood. This article introduces the concept of moderation and describes how moderator effects are tested and interpreted for a series of model types, beginning with straightforward two-way interactions with Normal outcomes, moving to three-way and curvilinear interactions, and then to models with non-Normal outcomes including binary logistic regression and Poisson regression. In particular, methods of interpreting and probing these latter model types, such as simple slope analysis and slope difference tests, are described. It then gives answers to twelve frequently asked questions about testing and interpreting moderator effects.},
  langid = {english},
  keywords = {Interactions,Moderation,Regression,Simple slopes},
  file = {/Users/jimmy_z/Zotero/storage/J9JW9V2A/Dawson - 2014 - Moderation in Management Research What, Why, When.pdf}
}

@article{devellisClassicalTestTheory2006,
  title = {Classical {{Test Theory}}},
  author = {DeVellis, Robert F.},
  year = {2006},
  month = nov,
  journal = {Medical Care},
  volume = {44},
  number = {11},
  pages = {S50},
  issn = {0025-7079},
  doi = {10.1097/01.mlr.0000245426.10853.30},
  urldate = {2024-03-13},
  abstract = {Classical test theory (CTT) comprises a set of concepts and methods that provide a basis for many of the measurement tools currently used in health research. The assumptions and concepts underlying CTT are discussed. These include item and scale characteristics that derive from CTT as well as types of reliability and validity. Procedures commonly used in the development of scales under CTT are summarized, including factor analysis and the creation of scale scores. The advantages and disadvantages of CTT, its use across populations, and its continued use in the face of more recent measurement models are also discussed.},
  langid = {american},
  file = {/Users/jimmy_z/Zotero/storage/6BPQUT2V/Classical_Test_Theory.11.html}
}

@Article{mirt,
    title = {{mirt}: A Multidimensional Item Response Theory Package
      for the {R} Environment},
    author = {R. Philip Chalmers},
    journal = {Journal of Statistical Software},
    year = {2012},
    volume = {48},
    number = {6},
    pages = {1--29},
    doi = {10.18637/jss.v048.i06},
  }

@Manual{openmx,
    title = {OpenMx: Extended Structural Equation Modelling},
    author = {Steven M. Boker and Michael C. Neale and Hermine H. Maes
      and Michael Spiegel and Timothy R. Brick and Ryne Estabrook and
      Timothy C. Bates and Ross J. Gore and Michael D. Hunter and
      Joshua N. Pritikin and Mahsa Zahery and Robert M. Kirkpatrick},
    year = {2023},
    note = {R package version 2.21.11},
    url = {https://CRAN.R-project.org/package=OpenMx},
  }

@Article{lavaan,
    title = {{lavaan}: An {R} Package for Structural Equation
      Modeling},
    author = {Yves Rosseel},
    journal = {Journal of Statistical Software},
    year = {2012},
    volume = {48},
    number = {2},
    pages = {1--36},
    doi = {10.18637/jss.v048.i02},
  }

@article{devliegerHypothesisTestingUsing2016a,
  title = {Hypothesis {{Testing Using Factor Score Regression}}},
  author = {Devlieger, Ines and Mayer, Axel and Rosseel, Yves},
  year = {2016},
  month = oct,
  journal = {Educ Psychol Meas},
  volume = {76},
  number = {5},
  pages = {741--770},
  issn = {0013-1644},
  doi = {10.1177/0013164415607618},
  urldate = {2024-04-11},
  abstract = {In this article, an overview is given of four methods to perform factor score regression (FSR), namely regression FSR, Bartlett FSR, the bias avoiding method of Skrondal and Laake, and the bias correcting method of Croon. The bias correcting method is extended to include a reliable standard error. The four methods are compared with each other and with structural equation modeling (SEM) by using analytic calculations and two Monte Carlo simulation studies to examine their finite sample characteristics. Several performance criteria are used, such as the bias using the unstandardized and standardized parameterization, efficiency, mean square error, standard error bias, type I error rate, and power. The results show that the bias correcting method, with the newly developed standard error, is the only suitable alternative for SEM. While it has a higher standard error bias than SEM, it has a comparable bias, efficiency, mean square error, power, and type I error rate.},
  pmcid = {PMC5965529},
  pmid = {29795886},
  file = {/Users/jimmy_z/Zotero/storage/4CLZDZJG/Devlieger et al. - 2016 - Hypothesis Testing Using Factor Score Regression.pdf}
}

@article{estabrookComparisonFactorScore2013b,
  title = {A {{Comparison}} of {{Factor Score Estimation Methods}} in the {{Presence}} of {{Missing Data}}: {{Reliability}} and an {{Application}} to {{Nicotine Dependence}}},
  shorttitle = {A {{Comparison}} of {{Factor Score Estimation Methods}} in the {{Presence}} of {{Missing Data}}},
  author = {Estabrook, Ryne and Neale, Michael},
  year = {2013},
  month = jan,
  journal = {Multivariate Behav Res},
  volume = {48},
  number = {1},
  pages = {1--27},
  issn = {0027-3171},
  doi = {10.1080/00273171.2012.730072},
  urldate = {2024-04-12},
  abstract = {Factor score estimation is a controversial topic in psychometrics, and the estimation of factor scores from exploratory factor models has historically received a great deal of attention. However, both confirmatory factor models and the existence of missing data have generally been ignored in this debate. This article presents a simulation study that compares the reliability of sum scores, regression-based and expected posterior methods for factor score estimation for confirmatory factor models in the presence of missing data. Although all methods perform reasonably well with complete data, expected posterior-weighted (full) maximum likelihood methods are significantly more reliable than sum scores and regression estimators in the presence of missing data. Factor score reliability for complete data can be predicted by  formula for factor communality. Furthermore, factor score reliability for incomplete data can be reasonably approximated by communality raised to the  11-P(Missing) power. An empirical demonstration shows that the full maximum likelihood method best preserves the relationship between nicotine dependence and a genetic predictor under missing data. Implications and recommendations for applied research are discussed.},
  pmcid = {PMC3773873},
  pmid = {24049215},
  file = {/Users/jimmy_z/Zotero/storage/2A57QE47/Estabrook and Neale - 2013 - A Comparison of Factor Score Estimation Methods in.pdf}
}

@article{fairchildEvaluatingMediationModeration2010a,
  title = {Evaluating Mediation and Moderation Effects in School Psychology: {{A}} Presentation of Methods and Review of Current Practice},
  shorttitle = {Evaluating Mediation and Moderation Effects in School Psychology},
  author = {Fairchild, Amanda J. and McQuillin, Samuel D.},
  year = {2010},
  month = feb,
  journal = {Journal of School Psychology},
  volume = {48},
  number = {1},
  pages = {53--84},
  issn = {0022-4405},
  doi = {10.1016/j.jsp.2009.09.001},
  urldate = {2024-03-11},
  abstract = {Third variable effects elucidate the relation between two other variables, and can describe why they are related or under what conditions they are related. This article demonstrates methods to analyze two third-variable effects: moderation and mediation. The utility of examining moderation and mediation effects in school psychology is described and current use of the analyses in applied school psychology research is reviewed and evaluated. Proper statistical methods to test the effects are presented, and different effect size measures for the models are provided. Extensions of the basic moderator and mediator models are also described.},
  keywords = {Interaction effect,Mediation,Moderation},
  file = {/Users/jimmy_z/Zotero/storage/MIZWHV3G/Fairchild and McQuillin - 2010 - Evaluating mediation and moderation effects in sch.pdf}
}

@article{fanEffectsSampleSize1999,
  title = {Effects of Sample Size, Estimation Methods, and Model Specification on Structural Equation Modeling Fit Indexes},
  author = {Fan, Xitao and Thompson, Bruce and Wang, Lin},
  year = {1999},
  month = jan,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {6},
  number = {1},
  pages = {56--83},
  publisher = {Routledge},
  issn = {1070-5511},
  doi = {10.1080/10705519909540119},
  urldate = {2024-04-12},
  abstract = {A Monte Carlo simulation study was conducted to investigate the effects on structural equation modeling (SEM) fit indexes of sample size, estimation method, and model specification. Based on a balanced experimental design, samples were generated from a prespecified population covariance matrix and fitted to structural equation models with different degrees of model misspecification. Ten SEM fit indexes were studied. Two primary conclusions were suggested: (a) some fit indexes appear to be noncomparable in terms of the information they provide about model fit for misspecified models and (b) estimation method strongly influenced almost all the fit indexes examined, especially for misspecified models. These 2 issues do not seem to have drawn enough attention from SEM practitioners. Future research should study not only different models vis-{\`a}-vis model complexity, but a wider range of model specification conditions, including correctly specified models and models specified incorrectly to varying degrees.},
  file = {/Users/jimmy_z/Zotero/storage/UPM9ARIC/Fan et al. - 1999 - Effects of sample size, estimation methods, and mo.pdf}
}

@article{feinbergConductingSimulationStudies2016,
  title = {Conducting {{Simulation Studies}} in {{Psychometrics}}},
  author = {Feinberg, Richard A. and Rubright, Jonathan D.},
  year = {2016},
  journal = {Educational Measurement: Issues and Practice},
  volume = {35},
  number = {2},
  pages = {36--49},
  issn = {1745-3992},
  doi = {10.1111/emip.12111},
  urldate = {2024-04-10},
  abstract = {Simulation studies are fundamental to psychometric discourse and play a crucial role in operational and academic research. Yet, resources for psychometricians interested in conducting simulations are scarce. This Instructional Topics in Educational Measurement Series (ITEMS) module is meant to address this deficiency by providing a comprehensive introduction to the topic of simulation that can be easily understood by measurement specialists at all levels of training and experience. Specifically, this module describes the vocabulary used in simulations, reviews their applications in recent literature, and recommends specific guidelines for designing simulation studies and presenting results. Additionally, an example (including computer code in R) is given to demonstrate how common aspects of simulation studies can be implemented in practice and to provide a template to help users build their own simulation.},
  copyright = {Copyright {\copyright} 2016 by the National Council on Measurement in Education},
  langid = {english},
  keywords = {psychometrics,research design,simulation study},
  file = {/Users/jimmy_z/Zotero/storage/7WHTPKW3/Feinberg and Rubright - 2016 - Conducting Simulation Studies in Psychometrics.pdf;/Users/jimmy_z/Zotero/storage/KBHZEY5J/emip.html}
}

@article{fisicaroPowerReliabilityCase1992,
  title = {Power and {{Reliability}}: {{The Case}} of {{Homogeneous True Score Regression Across Treatments}}},
  shorttitle = {Power and {{Reliability}}},
  author = {Fisicaro, Sebastiano A. and Lautenschlager, Gary J.},
  year = {1992},
  month = sep,
  journal = {Educational and Psychological Measurement},
  volume = {52},
  number = {3},
  pages = {505--511},
  publisher = {SAGE Publications Inc},
  issn = {0013-1644},
  doi = {10.1177/0013164492052003001},
  urldate = {2024-03-13},
  abstract = {As part of their investigation of the relation between reliability of measures and statistical power, Nicewander and Price (1983) examined the situation in which true score regressions are homogeneous across treatments. They derived an equation indicating that the measure, X or Y, yielding the greater power depends on the reliabilities (pXX'. and pYY', respectively) and the squared linear correlation between true scores for X and Y (pT(X)T(Y)2). Typically, however, researchers cannot compute a direct estimate of pT(X)T(Y)2 The authors eliminate this problem by (a) pointing out situations in which the value of pT(X)T(Y)2 is either irrelevant or 1.0 and (b) demonstrating that their equation otherwise can be expressed in terms of pXX' and pXY only.},
  langid = {english}
}

@article{gonzalezAccommodatingLatentXM2023,
  title = {Accommodating a {{Latent XM Interaction}} in {{Statistical Mediation Analysis}}},
  author = {Gonzalez, Oscar and Valente, Matthew J.},
  year = {2023},
  journal = {Multivariate Behav Res},
  volume = {58},
  number = {4},
  pages = {659--674},
  issn = {1532-7906},
  doi = {10.1080/00273171.2022.2119928},
  abstract = {Statistical mediation analysis is used in the social sciences and public health to uncover potential mechanisms, known as mediators, by which a treatment led to a change in an outcome. Recently, the estimation of the treatment-by-mediator interaction (i.e., the XM interaction) has been shown to play a pivotal role in understanding the equivalence between the traditional mediation effects in linear models and the causal mediation effects in the potential outcomes framework. However, there is limited guidance on how to estimate the XM interaction when the mediator is latent. In this article, we discuss eight methods to accommodate latent XM interactions in statistical mediation analysis, which fall in two categories: using structural models (e.g., latent moderated structural equations, Bayesian mediation, unconstrained product indicator method, multiple-group models) or scoring the mediator prior to estimating the XM interaction (e.g., summed scores and factor scores, with and without attenuation correction). Simulation results suggest that finite-sample bias is low, type 1 error rates and coverage of percentile bootstrap confidence intervals and Bayesian credible intervals are close to the nominal values, and statistical power is similar across approaches. The methods are demonstrated with an applied example, syntax is provided for their implementation, and general considerations are discussed.},
  langid = {english},
  pmcid = {PMC10090233},
  pmid = {36223100},
  keywords = {latent interactions,latent variable scores,Statistical mediation,structural models}
}

@article{hallgrenConductingSimulationStudies2013,
  title = {Conducting {{Simulation Studies}} in the {{R Programming Environment}}},
  author = {Hallgren, Kevin A.},
  year = {2013},
  month = oct,
  journal = {Tutor Quant Methods Psychol},
  volume = {9},
  number = {2},
  pages = {43--60},
  issn = {1913-4126},
  urldate = {2024-04-10},
  abstract = {Simulation studies allow researchers to answer specific questions about data analysis, statistical power, and best-practices for obtaining accurate results in empirical research. Despite the benefits that simulation research can provide, many researchers are unfamiliar with available tools for conducting their own simulation studies. The use of simulation studies need not be restricted to researchers with advanced skills in statistics and computer programming, and such methods can be implemented by researchers with a variety of abilities and interests. The present paper provides an introduction to methods used for running simulation studies using the R statistical programming environment and is written for individuals with minimal experience running simulation studies or using R. The paper describes the rationale and benefits of using simulations and introduces R functions relevant for many simulation studies. Three examples illustrate different applications for simulation studies, including (a) the use of simulations to answer a novel question about statistical analysis, (b) the use of simulations to estimate statistical power, and (c) the use of simulations to obtain confidence intervals of parameter estimates through bootstrapping. Results and fully annotated syntax from these examples are provided.},
  pmcid = {PMC4110976},
  pmid = {25067989},
  file = {/Users/jimmy_z/Zotero/storage/HL9NHP7G/Hallgren - 2013 - Conducting Simulation Studies in the R Programming.pdf}
}

@book{hancockStructuralEquationModeling2006,
  title = {Structural {{Equation Modeling}}: {{A Second Course}}},
  shorttitle = {Structural {{Equation Modeling}}},
  author = {Hancock, Gregory R. and Mueller, Ralph O.},
  year = {2006},
  month = jan,
  publisher = {IAP},
  abstract = {This volume is intended to serve as a didactically-oriented resource covering a broad range of advanced topics often not discussed in introductory courses on structural equation modeling (SEM). Such topics are important in furthering the understanding of foundations and assumptions underlying SEM as well as in exploring SEM as a potential tool to address new types of research questions that might not have arisen during a first course. Chapters focus on the clear explanation and application of topics, rather than on analytical derivations, and contain syntax and partial output files from popular SEM software.},
  googlebooks = {VfonDwAAQBAJ},
  isbn = {978-1-60752-761-9},
  langid = {english},
  keywords = {Education / Research,Education / Statistics,Mathematics / Probability & Statistics / General}
}

@article{harringComparisonMethodsEstimating2012,
  title = {A Comparison of Methods for Estimating Quadratic Effects in Nonlinear Structural Equation Models},
  author = {Harring, Jeffrey R. and Weiss, Brandi A. and Hsu, Jui-Chen},
  year = {2012},
  month = jun,
  journal = {Psychol Methods},
  volume = {17},
  number = {2},
  pages = {193--214},
  issn = {1939-1463},
  doi = {10.1037/a0027539},
  abstract = {Two Monte Carlo simulations were performed to compare methods for estimating and testing hypotheses of quadratic effects in latent variable regression models. The methods considered in the current study were (a) a 2-stage moderated regression approach using latent variable scores, (b) an unconstrained product indicator approach, (c) a latent moderated structural equation method, (d) a fully Bayesian approach, and (e) marginal maximum likelihood estimation. Of the 5 estimation methods, it was found that overall the methods based on maximum likelihood estimation and the Bayesian approach performed best in terms of bias, root-mean-square error, standard error ratios, power, and Type I error control, although key differences were observed. Similarities as well as disparities among methods are highlight and general recommendations articulated. As a point of comparison, all 5 approaches were fit to a reparameterized version of the latent quadratic model to educational reading data.},
  langid = {english},
  pmcid = {PMC3481550},
  pmid = {22429193},
  keywords = {Bayes Theorem,Bias,Data Interpretation Statistical,Humans,Likelihood Functions,Models Statistical,Monte Carlo Method,Nonlinear Dynamics,Regression Analysis,Statistics as Topic},
  file = {/Users/jimmy_z/Zotero/storage/HNF6JCMB/Harring et al. - 2012 - A comparison of methods for estimating quadratic e.pdf}
}

@article{hindsSystematicReviewQuality2018,
  title = {A Systematic Review of the Quality of Reporting of Simulation Studies about Methods for the Analysis of Complex Longitudinal Patient-Reported Outcomes Data},
  author = {Hinds, Aynslie M. and Sajobi, Tolulope T. and Sebille, V{\'e}ronique and Sawatzky, Richard and Lix, Lisa M.},
  year = {2018},
  month = oct,
  journal = {Qual Life Res},
  volume = {27},
  number = {10},
  pages = {2507--2516},
  issn = {1573-2649},
  doi = {10.1007/s11136-018-1861-0},
  abstract = {PURPOSE: This study describes the characteristics and quality of reporting for published computer simulation studies about statistical methods to analyze complex longitudinal (i.e., repeated measures) patient-reported outcomes (PROs); we included methods for longitudinal latent variable measurement and growth models and response shift. METHODS: Scopus, PsycINFO, PubMed, EMBASE, and Social Science Citation Index were searched for English-language studies published between 1999 and 2016 using selected keywords. Extracted information included characteristics of the study purpose/objectives, simulation design, software, execution, performance, and results. The quality of reporting was evaluated using published best-practice guidelines. SYNTHESIS: A total of 1470 articles were reviewed and 42 articles met the inclusion criteria. The majority of the included studies (73.8\%) investigated an existing statistical method, primarily a latent variable model (95.2\%). Most studies specified the population model, including variable distributions, mean parameters, and correlation/covariances. The number of time points and sample size(s) were reported by all studies, but justification for the selected values was rarely provided. The majority of the studies (52.4\%) did not report on model non-convergence. Bias, accuracy, and model fit were commonly reported performance metrics. All studies reported results descriptively, and 26.2\% also used an inferential method. CONCLUSIONS: While methodological research on statistical analyses of complex longitudinal PRO data is informed by computer simulation studies, current reporting practices of these studies have not been consistent with best-practice guidelines. Comprehensive reporting of simulation methods and results ensures that the strengths and limitations of the investigated statistical methods are thoroughly explored.},
  langid = {english},
  pmid = {29679367},
  keywords = {Computer Simulation,Humans,Longitudinal,Longitudinal Studies,Measurement invariance,Patient Reported Outcome Measures,Patient-reported outcomes,Quality of Life,Research Design,Review,Simulation}
}

@book{hoyleHandbookStructuralEquation2022,
  title = {Handbook of {{Structural Equation Modeling}}},
  author = {Hoyle, Rick H.},
  year = {2022},
  month = nov,
  publisher = {Guilford Publications},
  abstract = {The definitive one-stop resource on structural equation modeling (SEM) from leading methodologists is now in a significantly revised second edition. Twenty-three new chapters cover model selection, bifactor models, item parceling, multitrait--multimethod models, exploratory SEM, mixture models, SEM with small samples, and more. The book moves from fundamental SEM topics (causality, visualization, assumptions, estimation, model fit, and managing missing data); to major model types focused on unobserved causes of covariance between observed variables; to more complex, specialized applications. Each chapter provides conceptually oriented descriptions, fully explicated analyses, and engaging examples that reveal modeling possibilities for use with the reader's data. The expanded companion website presents full data sets, code, and output for many of the chapters, as well as bonus selected chapters from the prior edition. ~ New to This Edition *Chapters on additional topics not mentioned above: SEM-based meta-analysis, dynamic SEM, machine-learning approaches, and more. *Chapters include computer code associated with example analyses (in Mplus and/or the R package lavaan), along with written descriptions of results. *60\% new material reflects a decade's worth of developments in the mechanics and application of SEM. *Many new contributors and fully rewritten chapters.},
  googlebooks = {PWObEAAAQBAJ},
  isbn = {978-1-4625-5071-5},
  langid = {english},
  keywords = {Business & Economics / Statistics,Education / Statistics,Medical / Nursing / Research & Theory,Psychology / Statistics,Social Science / Statistics}
}

@article{jaccardMeasurementErrorAnalysis1995a,
  title = {Measurement Error in the Analysis of Interaction Effects between Continuous Predictors Using Multiple Regression: {{Multiple}} Indicator and Structural Equation Approaches},
  shorttitle = {Measurement Error in the Analysis of Interaction Effects between Continuous Predictors Using Multiple Regression},
  author = {Jaccard, James and Wan, Choi K.},
  year = {1995},
  journal = {Psychological Bulletin},
  volume = {117},
  number = {2},
  pages = {348--357},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1455},
  doi = {10.1037/0033-2909.117.2.348},
  abstract = {Unreliability of measures produces bias in regression coefficients. Such measurement error is particularly problematic with the use of product terms in multiple regression because the reliability of the product terms is generally quite low relative to its component parts. The use of confirmatory factor analysis as a means of dealing with the problem of unreliability was explored in a simulation study. The design compared traditional regression analysis (which ignores measurement error) with approaches based on latent variable structural equation models that used maximum-likelihood and weighted least squares estimation criteria. The results showed that the latent variable approach coupled with maximum-likelihood estimation methods did a satisfactory job of interaction analysis in the presence of measurement error in terms of Type I and Type II errors. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Confirmatory Factor Analysis,Error of Measurement,Factor Analysis,Multiple Regression,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/6YDWWNAI/1995-19894-001.html}
}

@inproceedings{Jreskog1996NonlinearSE,
  title = {Nonlinear Structural Equation Models: {{The Kenny-Judd}} Model with {{Interaction}} Effects},
  author = {J{\"o}reskog, Karl G. and Yang, Fan},
  year = {1996}
}

@article{kleinMaximumLikelihoodEstimation2000b,
  title = {Maximum Likelihood Estimation of Latent Interaction Effects with the {{LMS}} Method},
  author = {Klein, Andreas and Moosbrugger, Helfried},
  year = {2000},
  month = dec,
  journal = {Psychometrika},
  volume = {65},
  number = {4},
  pages = {457--474},
  issn = {1860-0980},
  doi = {10.1007/BF02296338},
  urldate = {2024-03-10},
  abstract = {In the context of structural equation modeling, a general interaction model with multiple latent interaction effects is introduced. A stochastic analysis represents the nonnormal distribution of the joint indicator vector as a finite mixture of normal distributions. The Latent Moderated Structural Equations (LMS) approach is a new method developed for the analysis of the general interaction model that utilizes the mixture distribution and provides a ML estimation of model parameters by adapting the EM algorithm. The finite sample properties and the robustness of LMS are discussed. Finally, the applicability of the new method is illustrated by an empirical example.},
  langid = {english},
  keywords = {EM algorithm,latent interaction effects,mixture distribution,ML estimation,structural equation modeling (SEM)}
}

@article{kleinQuasimaximumLikelihoodEstimation2007,
  title = {Quasi-Maximum Likelihood Estimation of Structural Equation Models with Multiple Interaction and Quadratic Effects},
  author = {Klein, Andreas G. and Muth{\'e}n, Bengt O.},
  year = {2007},
  journal = {Multivariate Behavioral Research},
  volume = {42},
  number = {4},
  pages = {647--673},
  publisher = {Taylor \& Francis},
  address = {United Kingdom},
  issn = {1532-7906},
  doi = {10.1080/00273170701710205},
  abstract = {In this article, a nonlinear structural equation model is introduced and a quasi-maximum likelihood method for simultaneous estimation and testing of multiple nonlinear effects is developed. The focus of the new methodology lies on efficiency, robustness, and computational practicability. Monte-Carlo studies indicate that the method is highly efficient and that the likelihood ratio test of nonlinear effects is robust and outperforms alternative testing procedures. The new method is applied to empirical data of middle-aged men, where a latent interaction between physical fitness and flexibility in goal adjustment on complaint level is hypothesized. A model with 5 simultaneous nonlinear effects is analyzed, and the hypothesized interaction is quantified and tested positively against an additive model with quadratic and linear effects. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Estimation,Maximum Likelihood,Statistical Analysis,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/G9L3EM9W/Klein and Muthén - 2007 - Quasi-maximum likelihood estimation of structural .pdf;/Users/jimmy_z/Zotero/storage/CI67QC5U/2007-19854-003.html}
}

@article{laiCorrectingUnreliabilityPartial2023a,
  title = {Correcting for Unreliability and Partial Invariance: {{A}} Two-Stage Path Analysis Approach},
  shorttitle = {Correcting for Unreliability and Partial Invariance},
  author = {Lai, Mark H. C. and Tse, Winnie Wing-Yee and Zhang, Gengrui and Li, Yixiao and Hsiao, Yu-Yu},
  year = {2023},
  journal = {Structural Equation Modeling},
  volume = {30},
  number = {2},
  pages = {258--271},
  publisher = {Taylor \& Francis},
  address = {United Kingdom},
  issn = {1532-8007},
  doi = {10.1080/10705511.2022.2125397},
  abstract = {In path analysis, using composite scores without adjustment for measurement unreliability and violations of factorial invariance across groups lead to biased estimates of path coefficients. Although joint modeling of measurement and structural models can theoretically yield consistent structural association estimates, estimating a model with many variables is often impractical in small samples. A viable alternative is two-stage path analysis (2S-PA), where researchers first obtain factor scores and the corresponding individual-specific reliability coefficients, and then use those factor scores to analyze structural associations while accounting for their unreliability. The current paper extends 2S-PA to also account for partial invariance. Two simulation studies show that 2S-PA outperforms joint modeling in terms of model convergence, the efficiency of structural parameter estimation, and confidence interval coverage, especially in small samples and with categorical indicators. We illustrate 2S-PA by reanalyzing data from a multiethnic study that predicts drinking problems using college-related alcohol beliefs. (PsycInfo Database Record (c) 2023 APA, all rights reserved)},
  keywords = {Adjustment,Models,Path Analysis,Simulation},
  file = {/Users/jimmy_z/Zotero/storage/6NYRB2TJ/2023-15704-001.html}
}

@article{laiTwostagePathAnalysis2022b,
  title = {Two-Stage Path Analysis with Definition Variables: {{An}} Alternative Framework to Account for Measurement Error},
  shorttitle = {Two-Stage Path Analysis with Definition Variables},
  author = {Lai, Mark H. C. and Hsiao, Yu-Yu},
  year = {2022},
  month = aug,
  journal = {Psychol Methods},
  volume = {27},
  number = {4},
  pages = {568--588},
  issn = {1939-1463},
  doi = {10.1037/met0000410},
  abstract = {When estimating path coefficients among psychological constructs measured with error, structural equation modeling (SEM), which simultaneously estimates the measurement and structural parameters, is generally regarded as the gold standard. In practice, however, researchers usually first compute composite scores or factor scores, and use those as observed variables in a path analysis, for purposes of simplifying the model or avoiding model convergence issues. Whereas recent approaches, such as reliability adjustment methods and factor score regression, has been proposed to mitigate the bias induced by ignoring measurement error in composite/factor scores with continuous indicators, those approaches are not yet applicable to models with categorical indicators. In this article, we introduce the two-stage path analysis (2S-PA) with definition variables as a general framework for path modeling to handle categorical indicators, in which estimation of factor scores and path coefficients are separated. It thus allows for different estimation methods in the measurement and the structural path models and easier diagnoses of violations of model assumptions. We conducted three simulation studies, ranging from latent regression to mediation analysis with categorical indicators, and showed that 2S-PA generally produced similar estimates to those using SEM in large samples, but gave better convergence rates, less standard error bias, and better control of Type I error rates in small samples. We illustrate 2S-PA using data from a national data set, and show how researchers can implement it in Mplus and OpenMx. Possible extensions and future directions of 2S-PA are discussed. (PsycInfo Database Record (c) 2022 APA, all rights reserved).},
  langid = {english},
  pmid = {34881957},
  keywords = {Humans,Latent Class Analysis,Models Statistical,Reproducibility of Results}
}

@book{thurstoneVectorsMindMultiplefactor1935,
  title = {The Vectors of Mind:  {{Multiple-factor}} Analysis for the Isolation of Primary Traits},
  shorttitle = {The Vectors of Mind},
  author = {Thurstone, L. L.},
  year = {1935},
  series = {The Vectors of Mind:  {{Multiple-factor}} Analysis for the Isolation of Primary Traits},
  pages = {xi, 274},
  publisher = {University of Chicago Press},
  address = {Chicago, IL, US},
  doi = {10.1037/10018-000},
  abstract = {A definitive statement of the position and techniques of the generalized program of factor analysis at date. The argument proceeds in terms of the application of matrix theory to the evaluation of correlation tables, and a mathematical introduction is therefore given to acquaint the reader with the groundwork. Other chapters include the following: the factor problem; the fundamental factor theorem; the centroid method; the principal axes (including Hotelling's special case); the special case of rank one (Spearman's original attack); primary traits; isolation of primary factors; the positive manifold; orthogonal transformations; and the appraisal of abilities. There are appendixes on the concrete steps involved in calculations by the centroid method, a method of finding the roots of a polynomial, and a method for extracting square root with a mechanical calculator. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Achievement Measures,Factor Analysis,Factor Structure,Mathematics,Measurement,Personality Measures,Statistical Analysis},
  file = {/Users/jimmy_z/Zotero/storage/GKVNJKSL/2004-16228-000.html}
}

@article{leeBayesianApproachNonlinear2010,
  title = {A {{Bayesian Approach}} for {{Nonlinear Structural Equation Models With Dichotomous Variables Using Logit}} and {{Probit Links}}},
  author = {Lee, Sik-Yum and Song, Xin-Yuan and Cai, Jing-Heng},
  year = {2010},
  month = apr,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {17},
  number = {2},
  pages = {280--302},
  publisher = {Routledge},
  issn = {1070-5511},
  doi = {10.1080/10705511003659425},
  urldate = {2024-03-10},
  abstract = {Analysis of ordered binary and unordered binary data has received considerable attention in social and psychological research. This article introduces a Bayesian approach, which has several nice features in practical applications, for analyzing nonlinear structural equation models with dichotomous data. We demonstrate how to use the software WinBUGS and R2WinBUGS to obtain Bayesian estimates of the unknown parameters, estimates of latent variables, and the Deviance Information Criterion for model comparison. An illustrative example with an artificial data set is provided. Finally, simulation studies are conducted, not only to reveal the empirical performance of the Bayesian approach, but also to show that incorrectly treating binary data as ordinal, and vice versa, would produce misleading results.},
  file = {/Users/jimmy_z/Zotero/storage/N4S2KL86/Lee et al. - 2010 - A Bayesian Approach for Nonlinear Structural Equat.pdf}
}

@book{liStatisticalMethodologicalMyths2019,
  title = {Statistical and {{Methodological Myths}} and {{Urban Legends}} in {{Strategic Management Research}}: {{The Case}} of {{Moderation Analysis}}},
  shorttitle = {Statistical and {{Methodological Myths}} and {{Urban Legends}} in {{Strategic Management Research}}},
  author = {Li, Ming and Sharp, Barton and Bergh, Donald D. and Vandenberg, Robert},
  year = {2019},
  publisher = {SSRN},
  abstract = {This paper examines whether methodological precedence in applying moderation analysis to strategic management research relies on myths and urban legends, and if doing so affected empirical conclusions, implications for theory development, and practical recommendations. An in-depth analysis of 69 studies published in the Strategic Management Journal between 2000 and 2014 using moderation analysis finds that strategic management scholars typically rely on statistical myths and urban legends when applying moderation analysis including: (1) interpreting main effects separately from their significant interaction with other variables; (2) failing to report reliability values of interaction terms; and (3) relying on hierarchical approaches that can lead to interpretation errors. Further examples illustrate how these practices could lead researchers to draw incomplete and possibly inaccurate conclusions. Overall, problematic precedents have become the gold standards for testing and interpreting moderation models. Best practice recommendations for redirecting future research to more solid methodological grounding are provided.},
  googlebooks = {N0njzwEACAAJ},
  langid = {english}
}

@article{lodderModelingInteractionsLatent2019a,
  title = {Modeling {{Interactions Between Latent Variables}} in {{Research}} on {{Type D Personality}}: {{A Monte Carlo Simulation}} and {{Clinical Study}} of {{Depression}} and {{Anxiety}}},
  shorttitle = {Modeling {{Interactions Between Latent Variables}} in {{Research}} on {{Type D Personality}}},
  author = {Lodder, Paul and Denollet, Johan and Emons, Wilco H. M. and Nefs, Giesje and Pouwer, Frans and Speight, Jane and Wicherts, Jelte M.},
  year = {2019},
  journal = {Multivariate Behav Res},
  volume = {54},
  number = {5},
  pages = {637--665},
  issn = {1532-7906},
  doi = {10.1080/00273171.2018.1562863},
  abstract = {Several approaches exist to model interactions between latent variables. However, it is unclear how these perform when item scores are skewed and ordinal. Research on Type D personality serves as a good case study for that matter. In Study 1, we fitted a multivariate interaction model to predict depression and anxiety with Type D personality, operationalized as an interaction between its two subcomponents negative affectivity (NA) and social inhibition (SI). We constructed this interaction according to four approaches: (1) sum score product; (2) single product indicator; (3) matched product indicators; and (4) latent moderated structural equations (LMS). In Study 2, we compared these interaction models in a simulation study by assessing for each method the bias and precision of the estimated interaction effect under varying conditions. In Study 1, all methods showed a significant Type D effect on both depression and anxiety, although this effect diminished after including the NA and SI quadratic effects. Study 2 showed that the LMS approach performed best with respect to minimizing bias and maximizing power, even when item scores were ordinal and skewed. However, when latent traits were skewed LMS resulted in more false-positive conclusions, while the Matched PI approach adequately controlled the false-positive rate.},
  langid = {english},
  pmid = {30977400},
  keywords = {anxiety,Anxiety,Computer Simulation,depression,Depression,Humans,Interpersonal Relations,Latent Class Analysis,latent interaction,Latent prediction model,Monte Carlo Method,Multivariate Analysis,nonnormality,Psychiatric Status Rating Scales,SEM,Social Behavior,structural equation modeling,Type D personality,Type D Personality},
  file = {/Users/jimmy_z/Zotero/storage/KXGI5BCG/Lodder et al. - 2019 - Modeling Interactions Between Latent Variables in .pdf}
}

@article{marshStructuralEquationModels2004a,
  title = {Structural Equation Models of Latent Interactions: Evaluation of Alternative Estimation Strategies and Indicator Construction},
  shorttitle = {Structural Equation Models of Latent Interactions},
  author = {Marsh, Herbert W. and Wen, Zhonglin and Hau, Kit-Tai},
  year = {2004},
  month = sep,
  journal = {Psychol Methods},
  volume = {9},
  number = {3},
  pages = {275--300},
  issn = {1082-989X},
  doi = {10.1037/1082-989X.9.3.275},
  abstract = {Interactions between (multiple indicator) latent variables are rarely used because of implementation complexity and competing strategies. Based on 4 simulation studies, the traditional constrained approach performed more poorly than did 3 new approaches--unconstrained, generalized appended product indicator, and quasi-maximum-likelihood (QML). The authors' new unconstrained approach was easiest to apply. All 4 approaches were relatively unbiased for normally distributed indicators, but the constrained and QML approaches were more biased for nonnormal data; the size and direction of the bias varied with the distribution but not with the sample size. QML had more power, but this advantage was qualified by consistently higher Type I error rates. The authors also compared general strategies for defining product indicators to represent the latent interaction factor.},
  langid = {english},
  pmid = {15355150},
  keywords = {Analysis of Variance,Humans,Likelihood Functions,Mathematical Computing,Models Statistical,Nonlinear Dynamics,Psychology Experimental,Software}
}

@article{maslowskyEstimatingInterpretingLatent2015c,
  title = {Estimating and Interpreting Latent Variable Interactions: {{A}} Tutorial for Applying the Latent Moderated Structural Equations Method},
  shorttitle = {Estimating and Interpreting Latent Variable Interactions},
  author = {Maslowsky, Julie and Jager, Justin and Hemken, Douglas},
  year = {2015},
  month = jan,
  journal = {Int J Behav Dev},
  volume = {39},
  number = {1},
  pages = {87--96},
  issn = {0165-0254},
  doi = {10.1177/0165025414552301},
  abstract = {Latent variables are common in psychological research. Research questions involving the interaction of two variables are likewise quite common. Methods for estimating and interpreting interactions between latent variables within a structural equation modeling framework have recently become available. The latent moderated structural equations (LMS) method is one that is built into Mplus software. The potential utility of this method is limited by the fact that the models do not produce traditional model fit indices, standardized coefficients, or effect sizes for the latent interaction, which renders model fitting and interpretation of the latent variable interaction difficult. This article compiles state-of-the-science techniques for assessing LMS model fit, obtaining standardized coefficients, and determining the size of the latent interaction effect in order to create a tutorial for new users of LMS models. The recommended sequence of model estimation and interpretation is demonstrated via a substantive example and a Monte Carlo simulation. Finally, extensions of this method are discussed, such as estimating quadratic effects of latent factors and interactions between latent slope and intercept factors, which hold significant potential for testing and advancing developmental theories.},
  langid = {english},
  pmcid = {PMC4606468},
  pmid = {26478643},
  keywords = {latent variables,methodology,structural equation modeling},
  file = {/Users/jimmy_z/Zotero/storage/C3QPEYDR/Maslowsky et al. - 2015 - Estimating and interpreting latent variable intera.pdf}
}

@article{meijerHowMeasurementError2021,
  title = {How Measurement Error Affects Inference in Linear Regression},
  author = {Meijer, Erik and Oczkowski, Edward and Wansbeek, Tom},
  year = {2021},
  month = jan,
  journal = {Empir Econ},
  volume = {60},
  number = {1},
  pages = {131--155},
  issn = {1435-8921},
  doi = {10.1007/s00181-020-01942-z},
  urldate = {2024-03-25},
  abstract = {Measurement error biases OLS results. When the measurement error variance in absolute or relative (reliability) form is known, adjustment is simple. We link the (known) estimators for these cases to GMM theory and provide simple derivations of their standard errors. Our focus is on the test statistics. We show monotonic relations between the t-statistics and \$\$R{\textasciicircum}2\$\$s of the (infeasible) estimator if there was no measurement error, the inconsistent OLS estimator, and the consistent estimator that corrects for measurement error and show the relation between the t-value and the magnitude of the assumed measurement error variance or reliability. We also discuss how standard errors can be computed when the measurement error variance or reliability is estimated, rather than known, and we indicate how the estimators generalize to the panel data context, where we have to deal with dependency among observations. By way of illustration, we estimate a hedonic wine price function for different values of the reliability of the proxy used for the wine quality variable.},
  langid = {english},
  keywords = {C21,C52,Expert rating,Generalized method of moments,Hedonic regression,L15,Measurement error,Q11,Structural equation model,Wine quality},
  file = {/Users/jimmy_z/Zotero/storage/XXWER2PU/Meijer et al. - 2021 - How measurement error affects inference in linear .pdf}
}

@article{muthenModelingInteractionsLatent2003,
  title = {Modeling Interactions between Latent and Observed Continuous Variables Using Maximum-Likelihood Estimation in {{Mplus}}},
  author = {Muth{\'e}n, Bengt and Asparouhov, Tihomir and Muth{\'e}n, Muth{\'e}n},
  year = {2003},
  month = jan,
  journal = {Mplus Web Notes},
  volume = {6}
}

@article{morrisUsingSimulationStudies2019,
  title = {Using Simulation Studies to Evaluate Statistical Methods},
  author = {Morris, Tim P. and White, Ian R. and Crowther, Michael J.},
  year = {2019},
  journal = {Statistics in Medicine},
  volume = {38},
  number = {11},
  pages = {2074--2102},
  issn = {1097-0258},
  doi = {10.1002/sim.8086},
  urldate = {2024-04-10},
  abstract = {Simulation studies are computer experiments that involve creating data by pseudo-random sampling. A key strength of simulation studies is the ability to understand the behavior of statistical methods because some ``truth'' (usually some parameter/s of interest) is known from the process of generating the data. This allows us to consider properties of methods, such as bias. While widely used, simulation studies are often poorly designed, analyzed, and reported. This tutorial outlines the rationale for using simulation studies and offers guidance for design, execution, analysis, reporting, and presentation. In particular, this tutorial provides a structured approach for planning and reporting simulation studies, which involves defining aims, data-generating mechanisms, estimands, methods, and performance measures (``ADEMP''); coherent terminology for simulation studies; guidance on coding simulation studies; a critical discussion of key performance measures and their estimation; guidance on structuring tabular and graphical presentation of results; and new graphical presentations. With a view to describing recent practice, we review 100 articles taken from Volume 34 of Statistics in Medicine, which included at least one simulation study and identify areas for improvement.},
  copyright = {{\copyright} 2019 The Authors. Statistics~in~Medicine Published by John Wiley \& Sons Ltd.},
  langid = {english},
  keywords = {graphics for simulation,Monte Carlo,simulation design,simulation reporting,simulation studies},
  file = {/Users/jimmy_z/Zotero/storage/95VPVF9W/Morris et al. - 2019 - Using simulation studies to evaluate statistical m.pdf}
}

@article{moulderComparisonMethodsEstimating2002b,
  title = {Comparison of Methods for Estimating and Testing Latent Variable Interactions},
  author = {Moulder, Bradley C. and Algina, James},
  year = {2002},
  journal = {Structural Equation Modeling},
  volume = {9},
  number = {1},
  pages = {1--19},
  publisher = {Lawrence Erlbaum},
  address = {US},
  issn = {1532-8007},
  doi = {10.1207/S15328007SEM0901_1},
  abstract = {Structural equation modeling methods for estimating and testing hypotheses about an interaction between continuous variables were investigated. The methods were (1) K. A. Bollen's (1996) 2-stage least squares (TSLS) method, R. A. Ping's (1996) 2-step maximum likelihood (ML) method, and J. Jaccard and C. K. Wan's (1995) ML method for the Kenny--Judd model (D. A. Kenny and C. M. Judd, 1984); (2) a 2-step ML procedure and ML estimation of the J{\"o}reskog--Yang model (K. G. J{\"o}reskog and F. Yang 1996); and (3) ML estimation of a revised J{\"o}reskog--Yang model. The TSLS procedure exhibited more bias and lower power than the other methods. Under ML estimation of the J{\"o}reskog--Yang model, Type I error rates were not well controlled when robust standard errors were used. Among the remaining procedures, the Jaccard--Wan procedure and ML estimation of the revised J{\"o}reskog--Yang procedure were most effective, with the latter having some small advantages over the former. A technical description of the simulation is appended. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Empirical Methods,Estimation,Latent Variables,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/Q5L2ZIKI/2002-10162-001.html}
}

@article{nordLatentInteractionsOrdinal2023,
  title = {Latent {{Interactions}} with {{Ordinal Categorical Indicators}} and {{Non-Gaussian Bivariate Copulas}}},
  author = {Nord, Jayden},
  year = {2023},
  month = jan,
  journal = {ETD collection for University of Nebraska-Lincoln},
  pages = {1--333},
  file = {/Users/jimmy_z/Zotero/storage/NA53NQKI/AAI30489410.html}
}

@article{osborneFourAssumptionsMultiple2002,
  title = {{Four assumptions of multiple regression that researchers should always test}},
  author = {Osborne, Jason W. and Waters, Elaine},
  year = {2002},
  month = jan,
  journal = {Practical Assessment, Research, and Evaluation},
  volume = {8},
  number = {1},
  publisher = {University of Massachusetts Amherst Libraries},
  issn = {1531-7714},
  doi = {10.7275/r222-hv23},
  urldate = {2024-03-13},
  abstract = {Most statistical tests rely upon certain assumptions about the variables used in the analysis.  When these assumptions are not met the results may not be trustworthy, resulting in a Type I or Type II error, or over- or under-estimation of significance or effect size(s).  As Pedhazur (1997, p. 33) notes, "Knowledge and understanding of the situations when violations of assumptions lead to serious biases, and when they are of little consequence, are essential to meaningful data analysis".  However, as Osborne, Christensen, and Gunter (2001) observe, few articles report having tested assumptions of the statistical tests they rely on for drawing their conclusions.  This creates a situation where we have a rich literature in education and social science, but we are forced to call into question the validity of many of these results, conclusions, and assertions, as we have no idea whether the assumptions of the statistical tests were met.  Our goal for this paper is to present a discussion of the assumptions of multiple regression tailored toward the practicing researcher. Several assumptions of multiple regression are ``robust'' to violation (e.g., normal distribution of errors), and others are fulfilled in the proper design of a study (e.g., independence of observations).  Therefore, we will focus on the assumptions of multiple regression that are not robust to violation, and that researchers can deal with if violated.   Specifically, we will discuss the assumptions of linearity, reliability of measurement, homoscedasticity, and normality. Accessed 630,254 times on https://pareonline.net from January 07, 2002 to December 31, 2019. For downloads from January 1, 2020 forward, please click on the PlumX Metrics link to the right.},
  langid = {None},
  file = {/Users/jimmy_z/Zotero/storage/IWMWA2QI/Osborne and Waters - 2002 - Four assumptions of multiple regression that resea.pdf}
}

@article{rogersParameterRecoveryModel2004,
  title = {Parameter {{Recovery}} and {{Model Fit Using Multidimensional Composites}}: {{A Comparison}} of {{Four Empirical Parceling Algorithms}}},
  shorttitle = {Parameter {{Recovery}} and {{Model Fit Using Multidimensional Composites}}},
  author = {Rogers, William M. and Schmitt, Neal},
  year = {2004},
  journal = {Multivariate Behavioral Research},
  volume = {39},
  number = {3},
  pages = {379--412},
  publisher = {Lawrence Erlbaum},
  address = {US},
  issn = {1532-7906},
  doi = {10.1207/S15327906MBR3903_1},
  abstract = {Manifest variables in covariance structure analysis are often combined to form parcels for use as indicators in a measurement model. The purpose of the present study was to evaluate four empirical algorithms for creating such parcels, focusing on the effects of dimensionality on accuracy of parameter estimation and model fit. Results suggest that accuracy of parameter estimation is primarily a function of the nature and number of dimensions in a composite, and that greater dimensionality also renders parceling methods more similar with respect to accuracy of estimation. Conversely, model fit is predominantly influenced by the parceling algorithm and number of parcels formed. An integrative analysis of the degree to which model fit signals accuracy of estimation highlights the respective advantages and disadvantages of the parceling algorithms. Results suggest that a Radial parceling algorithm may offer advantages over Correlational, Factorial, or Random assignment of items to parcels. The behavior of the Radial algorithm, and iterative algorithms in general, warrant further investigation. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Algorithms,Analysis of Covariance,Empirical Methods,Multivariate Analysis,Variability Measurement}
}

@article{pagePRISMA2020Statement2021,
  title = {The {{PRISMA}} 2020 Statement: An Updated Guideline for Reporting Systematic Reviews},
  shorttitle = {The {{PRISMA}} 2020 Statement},
  author = {Page, Matthew J. and McKenzie, Joanne E. and Bossuyt, Patrick M. and Boutron, Isabelle and Hoffmann, Tammy C. and Mulrow, Cynthia D. and Shamseer, Larissa and Tetzlaff, Jennifer M. and Akl, Elie A. and Brennan, Sue E. and Chou, Roger and Glanville, Julie and Grimshaw, Jeremy M. and Hr{\'o}bjartsson, Asbj{\o}rn and Lalu, Manoj M. and Li, Tianjing and Loder, Elizabeth W. and {Mayo-Wilson}, Evan and McDonald, Steve and McGuinness, Luke A. and Stewart, Lesley A. and Thomas, James and Tricco, Andrea C. and Welch, Vivian A. and Whiting, Penny and Moher, David},
  year = {2021},
  month = mar,
  journal = {BMJ},
  volume = {372},
  pages = {n71},
  publisher = {British Medical Journal Publishing Group},
  issn = {1756-1833},
  doi = {10.1136/bmj.n71},
  urldate = {2024-04-12},
  abstract = {{$<$}p{$>$}The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews.{$<$}/p{$>$}},
  chapter = {Research Methods \&amp; Reporting},
  copyright = {{\copyright} Author(s) (or their employer(s)) 2019. Re-use permitted under CC                 BY. No commercial re-use. See rights and permissions. Published by                 BMJ.. http://creativecommons.org/licenses/by/4.0/This is an Open Access article distributed in accordance with the terms of the Creative Commons Attribution (CC BY 4.0) license, which permits others to distribute, remix, adapt and build upon this work, for commercial use, provided the original work is properly cited. See: http://creativecommons.org/licenses/by/4.0/.},
  langid = {english},
  pmid = {33782057},
  file = {/Users/jimmy_z/Zotero/storage/AA34BYYB/Page et al. - 2021 - The PRISMA 2020 statement an updated guideline fo.pdf}
}

@article{rdz-navarroReexaminingNonlinearStructural2015,
  title = {Reexamining {{Nonlinear Structural Equation Modeling Procedures}}: {{The Effect}} of {{Parallel}} and {{Congeneric Measures}}},
  shorttitle = {Reexamining {{Nonlinear Structural Equation Modeling Procedures}}},
  author = {{Rdz-Navarro}, Karina and Alvarado, Jes{\'u}s M.},
  year = {2015},
  journal = {Multivariate Behav Res},
  volume = {50},
  number = {6},
  pages = {645--661},
  issn = {1532-7906},
  doi = {10.1080/00273171.2015.1071236},
  abstract = {The current study examines the performance of the extended unconstrained approach (EXUC) and the latent moderated structural equation modeling procedure (LMS) in situations where quadratic and interaction terms are tested simultaneously and investigates their limitations with regard to the employment of parallel and congeneric measures, relatively low indicator reliabilities, and relatively large numbers of indicators. By means of a Monte Carlo study, we found LMS to be the best option for testing multiple nonlinear effects given sufficient sample size (n {$\geq$} 500) and normally distributed exogenous variables. Its advantages became more prominent when indicator reliabilities were heterogeneous and small. The EXUC was a viable option for estimating the model when indicators were parallel and exhibited large indicator reliabilities. An empirical example of the results is provided, and the relevance of measurement model characteristics to assess nonlinear relationships is discussed.},
  langid = {english},
  pmid = {26717124},
  keywords = {Behavioral Research,extended unconstrained approach,Humans,interaction effects,latent moderated structural equations,Models Statistical,Monte Carlo Method,Nonlinear Dynamics,nonlinear SEM,quadratic effects,Reproducibility of Results,Sample Size}
}

@article{rizopoulosGeneralizedLatentVariable2008,
  title = {Generalized Latent Variable Models with Non-Linear Effects},
  author = {Rizopoulos, Dimitris and Moustaki, Irini},
  year = {2008},
  journal = {British Journal of Mathematical and Statistical Psychology},
  volume = {61},
  number = {2},
  pages = {415--438},
  issn = {2044-8317},
  doi = {10.1348/000711007X213963},
  urldate = {2024-03-10},
  abstract = {Until recently, item response models such as the factor analysis model for metric responses, the two-parameter logistic model for binary responses and the multinomial model for nominal responses considered only the main effects of latent variables without allowing for interaction or polynomial latent variable effects. However, non-linear relationships among the latent variables might be necessary in real applications. Methods for fitting models with non-linear latent terms have been developed mainly under the structural equation modelling approach. In this paper, we consider a latent variable model framework for mixed responses (metric and categorical) that allows inclusion of both non-linear latent and covariate effects. The model parameters are estimated using full maximum likelihood based on a hybrid integration--maximization algorithm. Finally, a method for obtaining factor scores based on multiple imputation is proposed here for the non-linear model.},
  copyright = {2008 The British Psychological Society},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/4DKH4JDL/Rizopoulos and Moustaki - 2008 - Generalized latent variable models with non-linear.pdf;/Users/jimmy_z/Zotero/storage/LH4WDRX4/000711007X213963.html}
}

@article{rockliffeIncludingNonEnglishLanguage2022,
  title = {Including Non-{{English}} Language Articles in Systematic Reviews: {{A}} Reflection on Processes for Identifying Low-Cost Sources of Translation Support},
  shorttitle = {Including Non-{{English}} Language Articles in Systematic Reviews},
  author = {Rockliffe, Lauren},
  year = {2022},
  month = jan,
  journal = {Res Synth Methods},
  volume = {13},
  number = {1},
  pages = {2--5},
  issn = {1759-2887},
  doi = {10.1002/jrsm.1508},
  abstract = {Non-English language (NEL) articles are commonly excluded from published systematic reviews. The high cost associated with professional translation services and associated time commitment are often cited as barriers. Whilst there is debate as to the impact of excluding such articles from systematic reviews, doing so can introduce various biases. In order to encourage researchers to consider including these articles in future reviews, this paper aims to reflect on the experience and process of conducting a systematic review which included NEL articles. It provides an overview of the different approaches used to identify sources of low-cost translation support and considers the relative merits of, among others, seeking support through universities, social media, word-of-mouth, and use of personal contacts.},
  langid = {english},
  pmid = {34169665},
  keywords = {bias,Bias,cost savings,Humans,language,Language,research activities,systematic review,Systematic Reviews as Topic,translations},
  file = {/Users/jimmy_z/Zotero/storage/HTSU9P9J/Rockliffe - 2022 - Including non-English language articles in systema.pdf}
}

@article{rosseelStructuralMeasurementApproach2022,
  title = {A Structural after Measurement Approach to Structural Equation Modeling},
  author = {Rosseel, Yves and Loh, Wen Wei},
  year = {2022},
  month = nov,
  journal = {Psychol Methods},
  issn = {1939-1463},
  doi = {10.1037/met0000503},
  abstract = {In structural equation modeling (SEM), the measurement and structural parts of the model are usually estimated simultaneously. In this article, we revisit the long-standing idea that we should first estimate the measurement part, and then estimate the structural part. We call this the "structural-after-measurement" (SAM) approach to SEM. We describe a formal framework for the SAM approach under settings where the latent variables and their indicators are continuous. We review earlier SAM methods and establish how they are specific instances of the SAM framework. Decoupled estimation for the measurement and structural parts using SAM possesses three key advantages over simultaneous estimation in standard SEM. First, estimates are more robust against local model misspecifications. Second, estimation routines are less vulnerable to convergence issues in small samples. Third, estimates exhibit smaller finite sample biases under correctly specified models. We propose two variants of the SAM approach. "Local" SAM expresses the mean vector and variance-covariance matrix of the latent variables as a function of the observed summary statistics and the parameters of the measurement model. "Global" SAM holds the parameters of the measurement part fixed while estimating the parameters of the structural part. Our framework includes two-step corrected standard errors, and permits computing both local and global fit measures. Nonetheless, the SAM approach is an estimation strategy, and should not be regarded as a model-building tool. (PsycInfo Database Record (c) 2022 APA, all rights reserved).},
  langid = {english},
  pmid = {36355708},
  file = {/Users/jimmy_z/Zotero/storage/Z4BU92MM/Rosseel and Loh - 2022 - A structural after measurement approach to structu.pdf}
}

@article{preacherGeneralMultilevelSEM2010,
  title = {A General Multilevel {{SEM}} Framework for Assessing Multilevel Mediation},
  author = {Preacher, Kristopher J. and Zyphur, Michael J. and Zhang, Zhen},
  year = {2010},
  month = sep,
  journal = {Psychol Methods},
  volume = {15},
  number = {3},
  pages = {209--233},
  issn = {1939-1463},
  doi = {10.1037/a0020141},
  abstract = {Several methods for testing mediation hypotheses with 2-level nested data have been proposed by researchers using a multilevel modeling (MLM) paradigm. However, these MLM approaches do not accommodate mediation pathways with Level-2 outcomes and may produce conflated estimates of between- and within-level components of indirect effects. Moreover, these methods have each appeared in isolation, so a unified framework that integrates the existing methods, as well as new multilevel mediation models, is lacking. Here we show that a multilevel structural equation modeling (MSEM) paradigm can overcome these 2 limitations of mediation analysis with MLM. We present an integrative 2-level MSEM mathematical framework that subsumes new and existing multilevel mediation approaches as special cases. We use several applied examples and accompanying software code to illustrate the flexibility of this framework and to show that different substantive conclusions can be drawn using MSEM versus MLM.},
  langid = {english},
  pmid = {20822249},
  keywords = {Behavioral Research,Causality,Data Interpretation Statistical,Humans,Models Statistical,Multilevel Analysis,Psychology,Research Design},
  file = {/Users/jimmy_z/Zotero/storage/HPR59M68/Preacher et al. - 2010 - A general multilevel SEM framework for assessing m.pdf}
}

@article{ruckerMediationAnalysisSocial2011,
  title = {Mediation {{Analysis}} in {{Social Psychology}}: {{Current Practices}} and {{New Recommendations}}},
  shorttitle = {Mediation {{Analysis}} in {{Social Psychology}}},
  author = {Rucker, Derek D. and Preacher, Kristopher J. and Tormala, Zakary L. and Petty, Richard E.},
  year = {2011},
  journal = {Social and Personality Psychology Compass},
  volume = {5},
  number = {6},
  pages = {359--371},
  issn = {1751-9004},
  doi = {10.1111/j.1751-9004.2011.00355.x},
  urldate = {2024-04-08},
  abstract = {A key aim of social psychology is to understand the psychological processes through which independent variables affect dependent variables in the social domain. This objective has given rise to statistical methods for mediation analysis. In mediation analysis, the significance of the relationship between the independent and dependent variables has been integral in theory testing, being used as a basis to determine (1) whether to proceed with analyses of mediation and (2) whether one or several proposed mediator(s) fully or partially accounts for an effect. Synthesizing past research and offering new arguments, we suggest that the collective evidence raises considerable concern that the focus on the significance between the independent and dependent variables, both before and after mediation tests, is unjustified and can impair theory development and testing. To expand theory involving social psychological processes, we argue that attention in mediation analysis should be shifted towards assessing the magnitude and significance of indirect effects.},
  copyright = {{\copyright} 2011 The Authors. Social and Personality Psychology Compass {\copyright} 2011 Blackwell Publishing Ltd},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/4NVLUSXY/Rucker et al. - 2011 - Mediation Analysis in Social Psychology Current P.pdf}
}

@article{sainaniWhatComputerSimulation2015,
  title = {What Is {{Computer Simulation}}?},
  author = {Sainani, Kristin L.},
  year = {2015},
  month = dec,
  journal = {PM R},
  volume = {7},
  number = {12},
  pages = {1290--1293},
  issn = {1934-1563},
  doi = {10.1016/j.pmrj.2015.10.010},
  langid = {english},
  pmid = {26597107},
  keywords = {Computer Simulation,Education Medical,Humans,Physical and Rehabilitation Medicine},
  file = {/Users/jimmy_z/Zotero/storage/F9U3ITAK/Sainani - 2015 - What is Computer Simulation.pdf}
}

@incollection{schermelleh-engelEstimatingNonlinearEffects1998,
  title = {Estimating {{Nonlinear Effects Using}} a {{Latent Moderated Structural Equations Approach}}},
  booktitle = {Interaction and {{Nonlinear Effects}} in {{Structural Equation Modeling}}},
  author = {{Schermelleh-Engel}, Karin and Klein, Andreas and Moosbrugger, Helfried},
  year = {1998},
  publisher = {Routledge},
  abstract = {The use of structural equation modelling has become increasingly common in the social and behavioural sciences. Based on a stochastic analysis of the multivariate density function of indicator variables, latent moderated structural Equations (LMS) implements iterative maximum likelihood estimation for the model parameters. K. A. Bollen developed a general method that makes use of the two stage least squares for structural equation models with nonlinear functions of latent variables. In structural equation modelling, the latent variables in the equation are usually linearly related. But in some cases, theory suggests that in addition to the linear effects a product of the latent predictor variables may have an additional effect on a latent criterion variable. In view of non-normality problems with latent interaction models, a stochastic analysis of the density functions involved by interaction models could provide a theoretical background for the development of efficient estimation methods and a better understanding of the major problems associated with latent interaction.},
  isbn = {978-1-315-09261-4}
}

@article{siepeSimulationStudiesMethodological2023,
  title = {Simulation {{Studies}} for {{Methodological Research}} in {{Psychology}}},
  author = {Siepe, Bj{\"o}rn S. and Barto{\v s}, Franti{\v s}ek and Pawel, Samuel and Boulesteix, Anne-Laure},
  year = {2023},
  month = jun,
  publisher = {OSF},
  urldate = {2024-04-10},
  abstract = {Our overall goal is to assess the design and reporting standards of simulation studies in methodological psychology journals. Following a previous study by Morris et al. (2019), we will review aims, data-generating processes, estimands, methods, and performance measures (``ADEMP'') as well as the reporting of results. Building on the literature review, we will design a pre registration template for simulation studies. We will then showcase this template in a small simulation study of our own.      Hosted on the Open Science Framework},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/RXJ7ZCEH/dfgvu.html}
}

@article{leeBayesianMethodsAnalyzing2007,
  title = {Bayesian Methods for Analyzing Structural Equation Models with Covariates, Interaction, and Quadratic Latent Variables},
  author = {Lee, Sik-Yum and Song, Xin-Yuan and Tang, Nian-Sheng},
  year = {2007},
  journal = {Structural Equation Modeling},
  volume = {14},
  number = {3},
  pages = {404--434},
  publisher = {Taylor \& Francis},
  address = {United Kingdom},
  issn = {1532-8007},
  doi = {10.1080/10705510701301511},
  abstract = {The analysis of interaction among latent variables has received much attention. This article introduces a Bayesian approach to analyze a general structural equation model that accommodates the general nonlinear terms of latent variables and covariates. This approach produces a Bayesian estimate that has the same statistical optimal properties as a maximum likelihood estimate. Other advantages over the traditional approaches are discussed. More important, we demonstrate through examples how to use the freely available software WinBUGS to obtain Bayesian results for estimation and model comparison. Simulation studies are conducted to assess the empirical performances of the approach for situations with various sample sizes and prior inputs. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Analysis of Covariance,Interaction Analysis (Statistics),Latent Variables,Statistical Analysis,Statistical Variables,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/SD9UAKGS/2007-12387-003.html}
}

@article{songMaximumLikelihoodAnalysis2005,
  title = {Maximum {{Likelihood Analysis}} of {{Nonlinear Structural Equation Models With Dichotomous Variables}}},
  author = {Song, Xin-Yuan and Lee, Sik-Yum},
  year = {2005},
  month = apr,
  journal = {Multivariate Behav Res},
  volume = {40},
  number = {2},
  pages = {151--177},
  issn = {0027-3171},
  doi = {10.1207/s15327906mbr4002_1},
  abstract = {In this article, a maximum likelihood approach is developed to analyze structural equation models with dichotomous variables that are common in behavioral, psychological and social research. To assess nonlinear causal effects among the latent variables, the structural equation in the model is defined by a nonlinear function. The basic idea of the development is to augment the observed dichotomous data with the hypothetical missing data that involve the latent underlying continuous measurements and the latent variables in the model. An EM algorithm is implemented. The conditional expectation in the E-step is approximated via observations simulated from the appropriate conditional distributions by a Metropolis-Hastings algorithm within the Gibbs sampler, whilst the M-step is completed by conditional maximization. Convergence is monitored by bridge sampling. Standard errors are also obtained. Results from a simulation study and a real example are presented to illustrate the methodology.},
  langid = {english},
  pmid = {26760105}
}

@article{tomitakaDistributionItemResponses2018,
  title = {Distribution of Item Responses and Total Item Scores for the {{Center}} for {{Epidemiologic Studies Depression Scale}} ({{CES-D}}): {{Data}} from the {{Irish Longitudinal Study}} on {{Ageing}} ({{TILDA}})},
  shorttitle = {Distribution of Item Responses and Total Item Scores for the {{Center}} for {{Epidemiologic Studies Depression Scale}} ({{CES-D}})},
  author = {Tomitaka, Shinichiro and Kawasaki, Yohei and Ide, Kazuki and Akutagawa, Maiko and Ono, Yutaka and Furukawa, Toshiaki A.},
  year = {2018},
  month = aug,
  journal = {PLOS ONE},
  volume = {13},
  number = {8},
  pages = {e0202607},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0202607},
  urldate = {2024-03-13},
  abstract = {Background Previous studies have shown that item responses and total scores on depression screening scales follow characteristic distribution patterns in the United States and Japanese general populations. However, the degree to which these findings, especially in terms of item responses, can be generalized to a European population is unknown. Thus, we analyzed the item responses and total score distribution for the Center for Epidemiologic Studies Depression Scale (CES-D) in a representative Irish cohort from a large, recent study---the Irish Longitudinal Study on Ageing (TILDA). Methods We used CES-D data from the 2009--2011 TILDA (8504 individuals). Responses for the 16 depressive symptoms included ``rarely,'' ``some of the time,'' ``occasionally,'' and ``all of the time.'' Item response patterns and total score distribution across these 16 depressive symptom items were examined using graphical analyses and exponential regression modeling. Results Lines for item responses followed the same pattern across the 16 items. These lines were characterized by intersections in the vicinity of a single point between ``rarely'' and ``some of the time'' and parallel patterns from ``some of the time'' to ``all of the time'' on a log-normal scale. Total scores for the 16 items exhibited an exponential pattern, except for at the lower end of the distribution. Conclusions The present findings suggest that item responses and total scores on depression screening scales among the general population follow the same characteristic patterns across populations from multiple nations.},
  langid = {english},
  keywords = {Depression,Epidemiology of aging,Insomnia,Ireland,Longitudinal studies,Normal distribution,Surveys,United States},
  file = {/Users/jimmy_z/Zotero/storage/FQ5EZEUJ/Tomitaka et al. - 2018 - Distribution of item responses and total item scor.pdf}
}

@article{wallMethodMomentsTechnique2003,
  title = {A Method of Moments Technique for Fitting Interaction Effects in Structural Equation Models},
  author = {Wall, Melanie M. and Amemiya, Yasuo},
  year = {2003},
  journal = {British Journal of Mathematical and Statistical Psychology},
  volume = {56},
  number = {1},
  pages = {47--63},
  publisher = {British Psychological Society},
  address = {United Kingdom},
  issn = {2044-8317},
  doi = {10.1348/000711003321645331},
  abstract = {The desire to fit structural equation models containing an interaction term has received much methodological attention in the social science literature. This paper presents a technique for the cross-product structural model that utilizes factor score estimates and results in closed-form moments-type estimators. The technique, which does not require normality for the underlying factors, was originally introduced in a very general form by Wall and Amemiya (2000) for any polynomial structural model. In this paper, the practical implementation of this method, including standard error estimation, is presented specifically for the cross-product model. The procedure is applied to an example from social/behavioural epidemiology where the flexibility of the cross-product model provides a useful description of the underlying theory. A simulation study is also presented comparing the method of moments for the cross-product model with three other procedures. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Interaction Analysis (Statistics),Structural Equation Modeling}
}

@article{wallGeneralizedAppendedProduct2001a,
  title = {Generalized Appended Product Indicator Procedure for Nonlinear Structural Equation Analysis},
  author = {Wall, Melanie M. and Amemiya, Yasuo},
  year = {2001},
  journal = {Journal of Educational and Behavioral Statistics},
  volume = {26},
  number = {1},
  pages = {1--30},
  publisher = {American Educational Research Assn},
  address = {US},
  issn = {1935-1054},
  doi = {10.3102/10769986026001001},
  abstract = {This article considers estimation of polynomial structural models. An existing method is shown to have a limitation that the produced estimator is inconsistent for most practical situations. A procedure is introduced and defined for a general model using products of observed indicators. The resulting estimator is consistent without assuming any distributional form for the underlying factors or errors. Identification assessment and standard error estimation are discussed. A simulation study addresses statistical issues including comparisons of discrepancy functions and the choice of appended product indicators. Application of the presented procedure in a substance abuse prevention study is also reported. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Statistical Analysis,Statistical Estimation,Statistical Variables,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/WWNGRW3X/2002-13051-001.html}
}

@article{pietersSixMethodsLatent2022,
  title = {Six {{Methods}} for {{Latent Moderation Analysis}} in {{Marketing Research}}: {{A Comparison}} and {{Guidelines}}},
  shorttitle = {Six {{Methods}} for {{Latent Moderation Analysis}} in {{Marketing Research}}},
  author = {Pieters, Constant and Pieters, Rik and Lemmens, Aur{\'e}lie},
  year = {2022},
  month = oct,
  journal = {Journal of Marketing Research},
  volume = {59},
  number = {5},
  pages = {941--962},
  publisher = {SAGE Publications Inc},
  issn = {0022-2437},
  doi = {10.1177/00222437221077266},
  urldate = {2024-04-12},
  abstract = {It is common in moderation analysis that at least one of the target moderation variables is latent and measured with measurement error. This article compares six methods for latent moderation analysis: multigroup, means, corrected means, factor scores, product indicators, and latent product. It reviews their use in marketing research, describes their assumptions, and compares their performance with Monte Carlo simulations. Several recommendations follow from the results. First, although the means method is the most frequently used method in the review (95\% of articles), it should only be used when reliabilities of the moderation variables are close to 1, which is rare. Then, all methods except the multigroup method perform similarly well. Second, the results support using the factor scores method and latent product method when reliabilities are smaller than 1. These methods perform best with parameter and standard error bias less than or equal to 5\% under most investigated conditions. Third, specific settings can warrant using the multigroup method (if the moderator is discrete), the corrected means method (if moderation variables are single indicators), and the product indicators method (if indicators are nonnormally distributed). Practical guidelines and sample code for four statistical platforms (SPSS, Stata, R, and Mplus) are provided.},
  langid = {english}
}

@article{weziak-bialowolskaWellBeingLifeWellBeing2020,
  title = {Well-{{Being}} in {{Life}} and {{Well-Being}} at {{Work}}: {{Which Comes First}}? {{Evidence From}} a {{Longitudinal Study}}},
  shorttitle = {Well-{{Being}} in {{Life}} and {{Well-Being}} at {{Work}}},
  author = {{Weziak-Bialowolska}, Dorota and Bialowolski, Piotr and Sacco, Pier Luigi and VanderWeele, Tyler J. and McNeely, Eileen},
  year = {2020},
  journal = {Front Public Health},
  volume = {8},
  pages = {103},
  issn = {2296-2565},
  doi = {10.3389/fpubh.2020.00103},
  abstract = {Understanding reciprocal relationships between specific arenas in life and at work is critical for designing interventions to improve workplace health and safety. Most studies about the links between dimensions of well-being in life and at work have been cross-sectional and usually narrowly focused on one of the dimensions of the work-life well-being link. The issues of causality and feedback between life and work well-being have often not been addressed. We overcome these issues by measuring six aspects of well-being for both the work arena and life in general, using longitudinal data with a clear temporal sequence of cause and effect, and by explicitly accounting for feedback with potential effects in both directions. Nine hundred and fifty-four Mexican apparel factory workers at a major global brand participated in two waves of the Worker Well-Being Survey. Data on life satisfaction and job satisfaction, happiness and positive affect, meaning and purpose, health, and social relationships in life and at work were used. Lagged regression controlling for confounders and prior outcomes was employed. Sensitivity analysis was used to assess the robustness of the results to potential unmeasured confounding. For the relationships between life satisfaction and job satisfaction and between happiness in life and happiness at work effects in both directions were found. Nevertheless, indication of a larger effect of life satisfaction on job satisfaction than the reverse was obtained. For depression and meaning in life, there was evidence for an effect of life well-being on work-related well-being, but not for the reverse. For social relationships and purpose, there was evidence for an effect of work-related well-being on life well-being, but not the reverse. Relationships based on the longitudinal data were considerably weaker than their respective cross-sectional associations. This study contributes to our understanding of the nature of the relationship between aspects of well-being in the arenas of life and work. Findings from this study may facilitate the development of novel workplace programs promoting working conditions that enable lifelong flourishing in life and at work.},
  langid = {english},
  pmcid = {PMC7160299},
  pmid = {32328472},
  keywords = {Cross-Sectional Studies,happiness,health,Humans,job and life satisfaction,Job Satisfaction,Longitudinal Studies,meaning and purpose in life and at work,social relationships,Surveys and Questionnaires,well-being at work,well-being in life,Workplace},
  file = {/Users/jimmy_z/Zotero/storage/YQVMQNNT/Weziak-Bialowolska et al. - 2020 - Well-Being in Life and Well-Being at Work Which C.pdf}
}

@article{whismanDesigningTestingInterpreting2005,
  title = {Designing, {{Testing}}, and {{Interpreting Interactions}} and {{Moderator Effects}} in {{Family Research}}},
  author = {Whisman, Mark A. and McClelland, Gary H.},
  year = {2005},
  journal = {Journal of Family Psychology},
  volume = {19},
  number = {1},
  pages = {111--120},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1293},
  doi = {10.1037/0893-3200.19.1.111},
  abstract = {This article is a primer on issues in designing, testing, and interpreting interaction or moderator effects in research on family psychology. The first section focuses on procedures for testing and interpreting simple effects and interactions, as well as common errors in testing moderators (e.g., testing differences among subgroup correlations, omitting components of products, and using median splits). The second section, devoted to difficulties in detecting interactions, covers such topics as statistical power, measurement error, distribution of variables, and mathematical constraints of ordinal interactions. The third section, devoted to design issues, focuses on recommendations such as including reliable measures, enhancing statistical power, and oversampling extreme scores. The topics covered should aid understanding of existing moderator research as well as improve future research on interaction effects. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Experimental Design,Experimentation,Family,Family Relations,Statistical Analysis,Statistical Power,Testing},
  file = {/Users/jimmy_z/Zotero/storage/CXF7M3H2/2005-02946-011.html}
}

@article{wolfSampleSizeRequirements2013,
  title = {Sample {{Size Requirements}} for {{Structural Equation Models}}: {{An Evaluation}} of {{Power}}, {{Bias}}, and {{Solution Propriety}}},
  shorttitle = {Sample {{Size Requirements}} for {{Structural Equation Models}}},
  author = {Wolf, Erika J. and Harrington, Kelly M. and Clark, Shaunna L. and Miller, Mark W.},
  year = {2013},
  month = dec,
  journal = {Educational and Psychological Measurement},
  volume = {73},
  number = {6},
  pages = {913--934},
  publisher = {SAGE Publications Inc},
  issn = {0013-1644},
  doi = {10.1177/0013164413495237},
  urldate = {2024-04-12},
  abstract = {Determining sample size requirements for structural equation modeling (SEM) is a challenge often faced by investigators, peer reviewers, and grant writers. Recent years have seen a large increase in SEMs in the behavioral science literature, but consideration of sample size requirements for applied SEMs often relies on outdated rules-of-thumb. This study used Monte Carlo data simulation techniques to evaluate sample size requirements for common applied SEMs. Across a series of simulations, we systematically varied key model properties, including number of indicators and factors, magnitude of factor loadings and path coefficients, and amount of missing data. We investigated how changes in these parameters affected sample size requirements with respect to statistical power, bias in the parameter estimates, and overall solution propriety. Results revealed a range of sample size requirements (i.e., from 30 to 460 cases), meaningful patterns of association between parameters and sample size, and highlight the limitations of commonly cited rules-of-thumb. The broad ``lessons learned'' for determining SEM sample size requirements are discussed.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/H8X6ZQJD/Wolf et al. - 2013 - Sample Size Requirements for Structural Equation M.pdf}
}

@article{mooijaartAlternativeApproachNonlinear2010,
  title = {An Alternative Approach for Nonlinear Latent Variable Models},
  author = {Mooijaart, Ab and Bentler, Peter M.},
  year = {2010},
  journal = {Structural Equation Modeling},
  volume = {17},
  number = {3},
  pages = {357--373},
  publisher = {Taylor \& Francis},
  address = {United Kingdom},
  issn = {1532-8007},
  doi = {10.1080/10705511.2010.488997},
  abstract = {In the last decades there has been an increasing interest in nonlinear latent variable models. Since the seminal paper of Kenny and Judd, several methods have been proposed for dealing with these kinds of models. This article introduces an alternative approach. The methodology involves fitting some third-order moments in addition to the means and covariances. This article discusses how the model equations can be formulated and how several standard tests, like the model fit and Lagrange multiplier tests, can be performed. The new method compares favorably with the maximum likelihood method in several studies and can provide evidence of interaction that earlier approaches might ignore. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Algorithms,Latent Variables,Maximum Likelihood,Statistical Correlation,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/GRCU25EA/2010-14461-001.html}
}

@article{parkModelsVisuospatialVerbal2002,
  title = {Models of Visuospatial and Verbal Memory across the Adult Life Span},
  author = {Park, Denise C. and Lautenschlager, Gary and Hedden, Trey and Davidson, Natalie S. and Smith, Anderson D. and Smith, Pamela K.},
  year = {2002},
  journal = {Psychology and Aging},
  volume = {17},
  number = {2},
  pages = {299--320},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1498},
  doi = {10.1037/0882-7974.17.2.299},
  abstract = {The authors investigated the distinctiveness and interrelationships among visuospatial and verbal memory processes in short-term, working, and long-term memories in 345 adults. Beginning in the 20s, a continuous, regular decline occurs for processing-intensive tasks (e.g., speed of processing, working memory, and long-term memory), whereas verbal knowledge increases across the life span. There is little differentiation in the cognitive architecture of memory across the life span. Visuospatial and verbal working memory are distinct but highly interrelated systems with domain-specific short-term memory subsystems. In contrast to recent neuroimaging data, there is little evidence for dedifferentiation of function at the behavioral level in old compared with young adults. The authors conclude that efforts to connect behavioral and brain data yield a more complete understanding of the aging mind. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Adult Development,Age Differences,Aging,Cognitive Ability,Long Term Memory,Short Term Memory,Verbal Memory,Visuospatial Memory}
}

@article{normanLikertScalesLevels2010,
  title = {Likert Scales, Levels of Measurement and the "Laws" of Statistics},
  author = {Norman, Geoff},
  year = {2010},
  month = dec,
  journal = {Adv Health Sci Educ Theory Pract},
  volume = {15},
  number = {5},
  pages = {625--632},
  issn = {1573-1677},
  doi = {10.1007/s10459-010-9222-y},
  abstract = {Reviewers of research reports frequently criticize the choice of statistical methods. While some of these criticisms are well-founded, frequently the use of various parametric methods such as analysis of variance, regression, correlation are faulted because: (a) the sample size is too small, (b) the data may not be normally distributed, or (c) The data are from Likert scales, which are ordinal, so parametric statistics cannot be used. In this paper, I dissect these arguments, and show that many studies, dating back to the 1930s consistently show that parametric statistics are robust with respect to violations of these assumptions. Hence, challenges like those above are unfounded, and parametric methods can be utilized without concern for "getting the wrong answer".},
  langid = {english},
  pmid = {20146096},
  keywords = {Analysis of Variance,Educational Measurement,Factor Analysis Statistical,Humans,Regression Analysis,Sample Size,Statistics as Topic}
}

@article{brandtSimulationStudyComparing2014,
  title = {A {{Simulation Study Comparing Recent Approaches}} for the {{Estimation}} of {{Nonlinear Effects}} in {{SEM Under}} the {{Condition}} of {{Nonnormality}}},
  author = {Brandt, Holger and Kelava, Augustin and Klein, Andreas},
  year = {2014},
  month = apr,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {21},
  number = {2},
  pages = {181--195},
  publisher = {Routledge},
  issn = {1070-5511},
  doi = {10.1080/10705511.2014.882660},
  urldate = {2024-04-12},
  abstract = {In the past decade new approaches for the estimation of latent nonlinear interaction and quadratic effects in structural equation modeling have been proposed (Kelava \& Brandt, 2009; Klein \& Moosbrugger, 2000; Klein \& Muth{\'e}n, 2007; Marsh, Wen, \& Hau, 2004; Mooijaart \& Bentler, 2010; Wall \& Amemiya, 2003). Most approaches have been developed for the analysis of normally distributed latent predictor variables. In this article, we investigate the performance of five recent approaches under the condition of nonnormally distributed data: the extended unconstrained approach (Kelava \& Brandt, 2009), LMS (Klein \& Moosbrugger, 2000), QML (Klein \& Muth{\'e}n, 2007), the 2SMM approach (Wall \& Amemiya, 2003), and the method of moments approach by Mooijaart and Bentler (2010). Advantages and limitations of the approaches are discussed.},
  keywords = {estimators,interaction,nonlinear structural equation models,nonnormality,quadratic}
}

@book{casellaStatisticalInference2002,
  title = {Statistical Inference},
  author = {Casella, George and Berger, Roger L.},
  year = {2002},
  edition = {2nd ed},
  publisher = {Thomson Learning},
  address = {Australia ; ~Pacific Grove, CA},
  isbn = {978-0-534-24312-8},
  lccn = {QA276 ~.C37 2002},
  keywords = {Estadistica matamatica,Inferencia estatistica,Inferencia parametrica,Mathematical statistics,Probabilidades,Probabilites,Probabilities,Statistique mathematique}
}

@article{wolfSampleSizeRequirements2013a,
  title = {Sample {{Size Requirements}} for {{Structural Equation Models}}: {{An Evaluation}} of {{Power}}, {{Bias}}, and {{Solution Propriety}}},
  shorttitle = {Sample {{Size Requirements}} for {{Structural Equation Models}}},
  author = {Wolf, Erika J. and Harrington, Kelly M. and Clark, Shaunna L. and Miller, Mark W.},
  year = {2013},
  month = dec,
  journal = {Educ Psychol Meas},
  volume = {76},
  number = {6},
  pages = {913--934},
  issn = {0013-1644},
  doi = {10.1177/0013164413495237},
  urldate = {2024-04-12},
  abstract = {Determining sample size requirements for structural equation modeling (SEM) is a challenge often faced by investigators, peer reviewers, and grant writers. Recent years have seen a large increase in SEMs in the behavioral science literature, but consideration of sample size requirements for applied SEMs often relies on outdated rules-of-thumb. This study used Monte Carlo data simulation techniques to evaluate sample size requirements for common applied SEMs. Across a series of simulations, we systematically varied key model properties, including number of indicators and factors, magnitude of factor loadings and path coefficients, and amount of missing data. We investigated how changes in these parameters affected sample size requirements with respect to statistical power, bias in the parameter estimates, and overall solution propriety. Results revealed a range of sample size requirements (i.e., from 30 to 460 cases), meaningful patterns of association between parameters and sample size, and highlight the limitations of commonly cited rules-of-thumb. The broad ``lessons learned'' for determining SEM sample size requirements are discussed.},
  pmcid = {PMC4334479},
  pmid = {25705052},
  file = {/Users/jimmy_z/Zotero/storage/U2E9IEI7/Wolf et al. - 2013 - Sample Size Requirements for Structural Equation M.pdf}
}

@article{wuComparisonStrategiesForming2013,
  title = {A Comparison of Strategies for Forming Product Indicators for Unequal Numbers of Items in Structural Equation Models of Latent Interactions},
  author = {Wu, Yan and Wen, Zhonglin and Marsh, Herb and Hau, Kit-Tai},
  year = {2013},
  month = oct,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {20},
  pages = {551--567},
  doi = {10.1080/10705511.2013.824772},
  abstract = {This Monte Carlo simulation study investigated different strategies for forming product indicators for the unconstrained approach in analyzing latent interaction models when the exogenous factors are measured by unequal numbers of indicators under both normal and nonnormal conditions. Product indicators were created by (a) multiplying parcels of the larger scale by items of the smaller scale, and (b) matching items according to reliability to create several product indicators, ignoring those items with lower reliability. Two scaling approaches were compared where parceling was not involved: (a) fixing the factor variances, and (b) fixing 1 loading to 1 for each factor. The unconstrained approach was compared with the latent moderated structural equations (LMS) approach. Results showed that under normal conditions, the LMS approach was preferred because the biases of its interaction estimates and associated standard errors were generally smaller, and its power was higher than that of the unconstrained approach. Under nonnormal conditions, however, the unconstrained approach was generally more robust than the LMS approach. It is recommended to form product indicators by using items with higher reliability (rather than parceling) in the matching and then to specify the model by fixing 1 loading of each factor to unity when adopting the unconstrained approach.}
}

@book{aikenMultipleRegressionTesting1991b,
  title = {Multiple Regression:  {{Testing}} and Interpreting Interactions},
  shorttitle = {Multiple Regression},
  author = {Aiken, Leona S. and West, Stephen G.},
  year = {1991},
  series = {Multiple Regression:  {{Testing}} and Interpreting Interactions},
  pages = {xi, 212},
  publisher = {Sage Publications, Inc},
  address = {Thousand Oaks, CA, US},
  abstract = {This book provides clear prescriptions for the probing and interpretation of continuous variable interactions that are the analogs of existing prescriptions for categorical variable interactions. We provide prescriptions for probing and interpreting two- and three-way continuous variable interactions, including those involving nonlinear components. The interaction of continuous and categorical variables, the hallmark of analysis of covariance and related procedures, is treated as a special case of our general prescriptions. The issue of power of tests for continuous variable interactions, and the impact of measurement error on power are also addressed. Simple approaches for operationalizing the prescriptions for post hoc tests of interactions with standard statistical computer packages are provided.  The text is designed for researchers and graduate students who are familiar with multiple regression analysis involving simple linear relationships of a set of continuous predictors to a criterion. Hence the material is accessible to typical lower level graduate students in the social sciences, education, and business. The text can usefully serve as a supplement to introductory graduate level statistics courses. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-0-8039-3605-8},
  keywords = {Error of Measurement,Interaction Variance,Multiple Regression,Statistical Reliability},
  file = {/Users/jimmy_z/Zotero/storage/2M474KLY/1991-97932-000.html}
}

@article{ettnerNewEvidenceRelationship1996,
  title = {New Evidence on the Relationship between Income and Health},
  author = {Ettner, S. L.},
  year = {1996},
  month = feb,
  journal = {J Health Econ},
  volume = {15},
  number = {1},
  pages = {67--85},
  issn = {0167-6296},
  doi = {10.1016/0167-6296(95)00032-1},
  abstract = {Using data from the National Survey of Families and Households, the Survey of Income and Program Participation, and the National Health Interview Survey, I estimate the structural impact of income on the following measures of health: self-assessed health status, work and functional limitations, bed days, average daily consumption of alcohol, and scales of depressive symptoms and alcoholic behavior. Both ordinary and IV estimates indicate that increases in income significantly improve mental and physical health but increase the prevalence of alcohol consumption. Cost-benefit analyses of government policies that may reduce disposable income should take into account potential effects on morbidity.},
  langid = {english},
  pmid = {10157429},
  keywords = {Activities of Daily Living,Adult,Alcohol Drinking,Attitude to Health,Depression,Employment,Health Status Indicators,Health Surveys,Humans,Income,Middle Aged,Models Economic,Regression Analysis,Socioeconomic Factors,United States}
}

@article{newsomChangesAdolescentResponse2003,
  title = {Changes in Adolescent Response Patterns on the {{MMPI}}/{{MMPI-A}} across Four Decades},
  author = {Newsom, Cassandra Rutledge and Archer, Robert P. and Trumbetta, Susan and Gottesman, Irving I.},
  year = {2003},
  journal = {Journal of Personality Assessment},
  volume = {81},
  number = {1},
  pages = {74--84},
  publisher = {Lawrence Erlbaum},
  address = {US},
  issn = {1532-7752},
  doi = {10.1207/S15327752JPA8101_07},
  abstract = {The purpose of this study was to explore changes in adolescent self-presentation on the Minnesota Multiphasic Personality Inventory (MMPI; Hathaway \& McKinley, 1940) and MMPI-A Butcher et al., 1992) over a 40-year period. The primary samples used for comparison in this study include 1,235 adolescents, age 14 through 16, derived from the MMPI-A normative sample (Butcher et al., 1992) collected in 1989 and 10,514 adolescents, age 14 through 16, collected in 1948 and 1954 from Hathaway and Monachesi's (1963) study of adolescent personality and behavior. MMPI basic scale and item-level data were also included for 817 adolescents, age 14 through 16, collected by Colligan and Offord (1992) in 1985 as a further comparison. Between-sample analyses at the profile level revealed that adolescents from the MMPI-A normative sample scored significantly higher across basic clinical scales and lower on validity scales L and K than adolescents from the Hathaway and Monachesi (1963) sample, with mean data from the Colligan and Offord (1992) sample typically falling at a midpoint value. Analyses of Harris-Lingoes (Harris \& Lingoes, 1955) subscale and item-level data were conducted to provide refined definitions of the contents of scale-level changes. Results were interpreted as reflecting... (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Minnesota Multiphasic Personality Inventory,Personality Measures,Personality Traits,Social Change,Trends},
  file = {/Users/jimmy_z/Zotero/storage/7723GMU3/2003-99679-007.html}
}

@Manual{R-base,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2022},
  url = {https://www.R-project.org/},
}
@Manual{R-papaja,
  title = {{papaja}: {Prepare} reproducible {APA} journal articles with {R Markdown}},
  author = {Frederik Aust and Marius Barth},
  year = {2022},
  note = {R package version 0.1.1.9001},
  url = {https://github.com/crsh/papaja},
}
@Manual{R-tinylabels,
  title = {{tinylabels}: Lightweight Variable Labels},
  author = {Marius Barth},
  year = {2023},
  note = {R package version 0.2.4},
  url = {https://cran.r-project.org/package=tinylabels},
}
@Manual{R-dplyr,
  title = {dplyr: A Grammar of Data Manipulation},
  author = {Hadley Wickham and Romain François and Lionel Henry and Kirill Müller and Davis Vaughan},
  year = {2023},
  note = {R package version 1.1.3},
  url = {https://CRAN.R-project.org/package=dplyr},
}
@Manual{R-tidyr,
  title = {tidyr: Tidy Messy Data},
  author = {Hadley Wickham and Davis Vaughan and Maximilian Girlich},
  year = {2024},
  note = {R package version 1.3.1},
  url = {https://CRAN.R-project.org/package=tidyr},
}

@article{alginaNoteEstimatingJoreskogYang2001,
  title = {A Note on Estimating the {{J{\"o}reskog-Yang}} Model for Latent Variable Interaction Using {{LISREL}} 8.3.},
  author = {Algina, James and Moulder, Bradley C.},
  year = {2001},
  journal = {Structural Equation Modeling},
  volume = {8},
  number = {1},
  pages = {40--52},
  publisher = {Lawrence Erlbaum},
  address = {US},
  issn = {1532-8007},
  doi = {10.1207/S15328007SEM0801_3},
  abstract = {D. A. Kenny and C. M. Judd (1984) developed a latent variable interaction model for observed variables centered around their population means. They estimated the model by using a covariance matrix calculated from sample-mean-centered variables and products of these variables. Subsequently, J{\"o}reskog and Yang (1996) identified the need to include intercepts for the measurement and structural equations and estimated the model by using a covariance matrix calculated from noncentered observed variables and products of these variables, and means of the observed variables and the products of noncentered variables. Evidence is presented that the J{\"o}reskog-Yang procedure for estimating the Kenny-Judd interaction model is subject to severe convergence problems when implemented in LISREL8.3 and means for the indicators of the latent exogenous variables are nonzero. An alternative procedure is presented that solves the convergence problem and provides consistent estimators of the parameters. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Estimation,Interaction Analysis (Statistics),Latent Variables,Models},
  file = {/Users/jimmy_z/Zotero/storage/W84UK2XX/2001-03013-003.html}
}

@article{andersonComparisonBiasMean1996,
  title = {A {{Comparison}} of Bias and Mean Squared Error in Parameter Estimates of Interaction Effects: {{Moderated}} Multiple Regression versus Error-in-Variables Regression},
  shorttitle = {A {{Comparison}} of {{Bias}} and {{Mean Squared Error}} in {{Parameter Estimates}} of {{Interaction Effects}}},
  author = {Anderson, Lance E. and {Stone-Romero}, Eugene F. and Tisak, John},
  year = {1996},
  month = jan,
  journal = {Multivariate Behavioral Research},
  volume = {31},
  number = {1},
  pages = {69--94},
  publisher = {Routledge},
  issn = {0027-3171},
  doi = {10.1207/s15327906mbr3101_5},
  urldate = {2024-03-05},
  abstract = {The results of moderated multiple regression (MMR) are highly affected by the unreliability of the predictor variables (regressors). Errors-in-variables regression (EIVR) may remedy this problem as it corrects for measurement error in the regressors, and thus provides less biased parameter estimates. However, little is known about the properties of the EIVR estimators in the moderator variable context. The present study used simulation methods to compare the moderator variable detection capabilities of MMR and EIVR. Specifically, the study examined the bias and mean squared error of the MMR and EIVR estimates under varying conditions of sample size, reliability of the predictor variables, and intercorrelations among the predictor variables. Findings showed that EIVR estimates are superior to MMR estimates when sample size is high (i.e., at least 250) and the reliabilities of the predictors are high (i.e., rij {$\geq$} .65). However, MMR appears to be the better strategy when reliabilities or sample size are low.},
  pmid = {26750710},
  file = {/Users/jimmy_z/Zotero/storage/UZ35PJVY/Anderson et al. - 1996 - A Comparison of Bias and Mean Squared Error in Par.pdf}
}

@article{bartlettStatisticalConceptionMental1937,
  title = {The Statistical Conception of Mental Factors},
  author = {Bartlett, M. S.},
  year = {1937},
  journal = {British Journal of Psychology. General Section},
  volume = {28},
  number = {1},
  pages = {97--104},
  issn = {2044-8295},
  doi = {10.1111/j.2044-8295.1937.tb00863.x},
  urldate = {2024-02-26},
  copyright = {1937 The British Psychological Society},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/WT9QMDW2/j.2044-8295.1937.tb00863.html}
}

@article{bollenLatentVariablesPsychology2002a,
  title = {Latent Variables in Psychology and the Social Sciences},
  author = {Bollen, Kenneth A.},
  year = {2002},
  journal = {Annual Review of Psychology},
  volume = {53},
  number = {1},
  pages = {605--634},
  publisher = {Annual Reviews},
  address = {US},
  issn = {1545-2085},
  doi = {10.1146/annurev.psych.53.100901.135239},
  abstract = {The paper discusses the use of latent variables in psychology and social science research. Local independence, expected value true scores, and nondeterministic functions of observed variables are three types of definitions for latent variables. These definitions are reviewed and an alternative "sample realizations" definition is presented. Another section briefly describes identification, latent variable indeterminancy, and other properties common to models with latent variables. The paper then reviews the role of latent variables in multiple regression, probit and logistic regression, factor analysis, latent curve models, item response theory, latent class analysis, and structural equation models. Though these application areas are diverse, the paper highlights the similarities as well as the differences in the manner in which the latent variables are defined and used. It concludes with an evaluation of the different definitions of latent variables and their properties. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Latent Variables,Methodology,Psychology,Social Sciences,Statistical Analysis,Statistical Variables,Theories},
  file = {/Users/jimmy_z/Zotero/storage/HN2BCC4F/2001-09759-022.html}
}

@book{bollenStructuralEquationsLatent1989d,
  title = {Structural Equations with Latent Variables},
  author = {Bollen, Kenneth A.},
  year = {1989},
  series = {Structural Equations with Latent Variables},
  pages = {xiv, 514},
  publisher = {John Wiley \& Sons},
  address = {Oxford, England},
  doi = {10.1002/9781118619179},
  abstract = {"Structural Equations with Latent Variables" is a comprehensive treatment of the general structural equation system better known as the LISREL model. The book serves three purposes. First, it demonstrates the generality of this model. Rather than treating path analysis, recursive and nonrecursive models, classical econometrics, and confirmatory factor analysis as unique, they are treated as special cases of a common model. The second purpose is to emphasize the application of these techniques. Empirical examples appear throughout. Several chapters contain some of the LISREL or EQS programs the author used to obtain the results for the empirical examples. Finally, the book explores the crucial role played by substantive expertise in most stages of the modeling process.  "Structural Equations with Latent Variables" fills the gap existing in the treatment of this subject between introductory texts and specialized papers. It provides social scientists, market researchers, applied statisticians, other analysts, and graduate students with a thorough examination of LISREL/structural equation models. At the same time it presents new material on measurement reliability and validity, overall fit indices, model identification, and other topics. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  isbn = {978-0-471-01171-2},
  keywords = {Computer Software,Factor Analysis,Factor Structure,Latent Variables,Linear Regression,Statistical Measurement,Statistical Variables,Statistics},
  file = {/Users/jimmy_z/Zotero/storage/ANLFPFZA/1989-97716-000.html}
}

@book{bollenTestingStructuralEquation1993,
  title = {Testing Structural Equation Models},
  editor = {Bollen, Kenneth A. and Long, J. Scott},
  year = {1993},
  series = {Testing Structural Equation Models},
  pages = {320},
  publisher = {Sage Publications, Inc},
  address = {Thousand Oaks, CA, US},
  abstract = {should be used as a text in graduate-level courses on sturctural equation models to augment the standard textbooks (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-0-8039-4506-7 978-0-8039-4507-4},
  keywords = {Goodness of Fit,Mathematical Modeling},
  file = {/Users/jimmy_z/Zotero/storage/FVJUE4BJ/1993-97481-000.html}
}

@book{brownConfirmatoryFactorAnalysis2015,
  title = {Confirmatory Factor Analysis for Applied Research, 2nd Ed},
  author = {Brown, Timothy A.},
  year = {2015},
  series = {Confirmatory Factor Analysis for Applied Research, 2nd Ed},
  pages = {xvii, 462},
  publisher = {The Guilford Press},
  address = {New York, NY, US},
  abstract = {With its emphasis on practical and conceptual aspects, rather than mathematics or formulas, This accessible book has established itself as the go-to resource on confirmatory factor analysis (CFA). Detailed, worked-through examples drawn from psychology, management, and sociology studies illustrate the procedures, pitfalls, and extensions of CFA methodology. The text shows how to formulate, program, and interpret CFA models using popular latent variable software packages (LISREL, Mplus, EQS, SAS/CALIS); understand the similarities and differences between CFA and exploratory factor analysis (EFA); and report results from a CFA study. It is filled with useful advice and tables that outline the procedures. The companion website (www.guilford.com/brown3-materials) offers data and program syntax files for most of the research examples, as well as links to CFA-related resources. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  isbn = {978-1-4625-1779-4 978-1-4625-1536-3 978-1-4625-1781-7},
  keywords = {Applied Psychology,Computer Software,Confirmatory Factor Analysis,Factor Analysis,Factor Structure,Latent Variables,Mathematical Modeling,Methodology},
  file = {/Users/jimmy_z/Zotero/storage/C9UNQ9C3/2015-10560-000.html}
}

@article{samejimaEstimationLatentAbility1969,
  title = {Estimation of Latent Ability Using a Response Pattern of Graded Scores},
  author = {Samejima, Fumiko},
  year = {1969},
  journal = {Psychometrika Monograph Supplement},
  volume = {34},
  number = {4, Pt. 2},
  pages = {100--100},
  abstract = {Formulated conditions for the existence of a unique maximum likelihood estimator and a bayes modal estimator. In line with these conditions, operating characteristics were introduced and discussed of graded responses when the thinking process is homogeneous, especially in connection with the normal ogive model and the logistic model. It is made clear that "the estimator specified on the entire response pattern has a substantial advantage to the 1 defined on the simple test score on the normal ogive model, when the values of item discriminating parameters are considerably different from one another, in the sense that it provides . . . Substantially different values of estimates for individual response patterns, reduces the standard errors of measurement when the estimator is the expected value, and decreases the mean-square errors . . . . The relationship between the formula for the item characteristic function and the philosophy of scoring was observed and the utility of asymmetric functional form for the item characteristic function was suggested." (17 ref.) (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Ability,Aptitude Measures,Estimation,Item Analysis (Test),Test Scores}
}

@book{byrneStructuralEquationModeling2016,
  title = {Structural Equation Modeling with {{AMOS}}: {{Basic}} Concepts, Applications, and Programming},
  shorttitle = {Structural {{Equation Modeling With AMOS}}},
  author = {Byrne, Barbara M.},
  year = {2016},
  month = jun,
  edition = {3},
  publisher = {Routledge},
  address = {New York},
  doi = {10.4324/9781315757421},
  abstract = {This bestselling text provides a practical guide to structural equation modeling (SEM) using the Amos Graphical approach. Using clear, everyday language, the text is ideal for those with little to no exposure to either SEM or Amos. The author reviews SEM applications based on actual data taken from her own research. Each chapter "walks" readers through the steps involved (specification, estimation, evaluation, and post hoc modification) in testing a variety of SEM models. Accompanying each application is: an explanation of the issues addressed and a schematic presentation of hypothesized model structure; Amos　 input and output with interpretations; use of the Amos toolbar icons and pull-down menus; and data upon which the model application was based, together with updated references pertinent to the SEM model　 tested. Thoroughly updated throughout, the new edition features: All new screen shots featuring Amos Version 23.　　  Descriptions and illustrations of Amos' new Tables View format which enables the specification of a structural model in spreadsheet form.　　　　  Key concepts and/or techniques that introduce each chapter.  Alternative approaches to model analyses when enabled by Amos thereby allowing users to determine the method best suited to their data.　  Provides analysis of the same model based on continuous and categorical data (Ch. 5) thereby enabling readers to observe two ways of specifying and testing the same model as well as compare results.  All applications based on the Amos graphical mode interface accompanied by more "how to" coverage of graphical techniques unique to Amos. More explanation of key procedures and analyses that address questions posed by readers  All application data files are available at www.routledge.com/9781138797031. The two introductory chapters in Section 1 review the fundamental concepts of SEM methodology and a general overview of the Amos program. Section 2 provides single-group analyses applications including two first-order confirmatory factor analytic (CFA) models, one second-order CFA model, and one full latent variable model. Section 3 presents multiple-group analyses applications with two rooted in the analysis of covariance structures and one in the analysis of mean and covariance structures. Two models that are increasingly popular with SEM practitioners, construct validity and testing change over time using the latent growth curve, are presented in Section 4. The book concludes with a review of the use of bootstrapping to address non-normal data and a review of missing (or incomplete) data in Section 5.  An ideal supplement for graduate level courses in psychology, education, business, and social and health sciences that cover the fundamentals of SEM with a focus on Amos, this practical text continues to be a favorite of both researchers and practitioners. A prerequisite of basic statistics through regression analysis is recommended but no exposure to either SEM or Amos is required.},
  isbn = {978-1-315-75742-1}
}

@article{cartePursuitModerationNine2003b,
  title = {In Pursuit of Moderation: {{Nine}} Common Errors and Their Solutions},
  author = {Carte, Traci A. and Russell, Craig J.},
  year = {2003},
  journal = {MIS Quarterly},
  volume = {27},
  number = {3},
  pages = {479--501},
  publisher = {Management Information Systems Research Center, University of Minnesota},
  issn = {02767783},
  doi = {10.2307/30036541},
  urldate = {2024-02-26},
  abstract = {[One result of the increasing sophistication and complexity of MIS theory and research is the number of studies hypothesizing and testing for moderation effects. A review of the MIS and broader management literatures suggests researchers investigating moderated relationships often commit one or more errors falling into three broad categories: inappropriate use or interpretation of statistics, misalignment of research design with phenomena of interest, and measurement or scaling issues. Examples of nine common errors are presented. Commission of these errors is expected to yield literatures characterized by mixed results at best, and thoroughly erroneous results at worse. Procedures representing examples of best practice and reporting guidelines are provided to help MIS investigators avoid or minimize these errors.]}
}

@book{carrollMeasurementErrorNonlinear2006,
  title = {Measurement Error in Nonlinear Models: {{A}} Modern Perspective, Second Edition},
  shorttitle = {Measurement {{Error}} in {{Nonlinear Models}}},
  author = {Carroll, Raymond J. and Ruppert, David and Stefanski, Leonard A. and Crainiceanu, Ciprian M.},
  year = {2006},
  month = jun,
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  address = {New York},
  doi = {10.1201/9781420010138},
  abstract = {It's been over a decade since the first edition of Measurement Error in Nonlinear Models splashed onto the scene, and research in the field has certainly not cooled in the interim. In fact, quite the opposite has occurred. As a result, Measurement Error in Nonlinear Models: A Modern Perspective, Second Edition has been revamped and ex},
  isbn = {978-0-429-13963-5}
}

@article{chamEstimatingLatentVariable2012a,
  title = {Estimating Latent Variable Interactions with Non-Normal Observed Data: {{A}} Comparison of Four Approaches},
  shorttitle = {Estimating {{Latent Variable Interactions With Non-Normal Observed Data}}},
  author = {Cham, Heining and West, Stephen G. and Ma, Yue and Aiken, Leona S.},
  year = {2012},
  journal = {Multivariate Behav Res},
  volume = {47},
  number = {6},
  pages = {840--876},
  issn = {0027-3171},
  doi = {10.1080/00273171.2012.732901},
  urldate = {2024-02-26},
  abstract = {A Monte Carlo simulation was conducted to investigate the robustness of four latent variable interaction modeling approaches (Constrained Product Indicator [CPI], Generalized Appended Product Indicator [GAPI], Unconstrained Product Indicator [UPI], and Latent Moderated Structural Equations [LMS]) under high degrees of non-normality of the observed exogenous variables. Results showed that the CPI and LMS approaches yielded biased estimates of the interaction effect when the exogenous variables were highly non-normal. When the violation of non-normality was not severe (normal; symmetric with excess kurtosis {$<$} 1), the LMS approach yielded the most efficient estimates of the latent interaction effect with the highest statistical power. In highly non-normal conditions, the GAPI and UPI approaches with ML estimation yielded unbiased latent interaction effect estimates, with acceptable actual Type-I error rates for both the Wald and likelihood ratio tests of interaction effect at N {$\geq$} 500. An empirical example illustrated the use of the four approaches in testing a latent variable interaction between academic self-efficacy and positive family role models in the prediction of academic performance.},
  pmcid = {PMC3583564},
  pmid = {23457417},
  file = {/Users/jimmy_z/Zotero/storage/3KHIFGBY/Cham et al. - 2012 - Estimating Latent Variable Interactions With Non-N.pdf}
}

@article{chinPartialLeastSquares2003,
  title = {A Partial Least Squares Latent Variable Modeling Approach for Measuring Interaction Effects: {{Results}} from a {{Monte Carlo}} Simulation Study and an Electronic-Mail Emotion/Adoption Study},
  shorttitle = {A {{Partial Least Squares Latent Variable Modeling Approach}} for {{Measuring Interaction Effects}}},
  author = {Chin, Wynne W. and Marcolin, Barbara L. and Newsted, Peter R.},
  year = {2003},
  journal = {Information Systems Research},
  volume = {14},
  number = {2},
  pages = {189--217},
  publisher = {Institute for Operations Research \& the Management Sciences (INFORMS)},
  address = {US},
  issn = {1526-5536},
  doi = {10.1287/isre.14.2.189.16018},
  abstract = {The ability to detect and accurately estimate the strength of interaction effects are critical issues that are fundamental to social science research in general and information systems (IS) research in particular. Within the IS discipline, a significant percentage of research has been devoted to examining the conditions and contexts under which relationships may vary, often under the general umbrella of contingency theory. In our survey of IS studies, the majority failed to either detect or provide an estimate of the effect size. In cases where effect sizes are estimated, the numbers are generally small. These data have led some researchers to question both the usefulness of contingency theory and the need to detect interaction effects. This paper addresses this issue by providing a new latent variable modeling approach that can give more accurate estimates of interaction effects by accounting for the measurement error that attenuates the estimated relationships. The capacity of this approach at recovering true effects in comparison to summated regression is demonstrated in a Monte Carlo study that creates a simulated data set in which the underlying true effects are known. Analysis of a second, empirical data set is included to demonstrate the technique's use within IS theory. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Computer Attitudes,Computer Mediated Communication,Emotional States,Error of Measurement,Information Theory,Latent Variables,Simulation},
  file = {/Users/jimmy_z/Zotero/storage/A7DVZM7T/2003-99380-004.html}
}

@book{cohenAppliedMultipleRegression2003,
  title = {Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed},
  author = {Cohen, Jacob and Cohen, Patricia and West, Stephen G. and Aiken, Leona S.},
  year = {2003},
  series = {Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed},
  pages = {xxviii, 703},
  publisher = {Lawrence Erlbaum Associates Publishers},
  address = {Mahwah, NJ, US},
  abstract = {Multiple regression correlation (MRC) analysis is a highly general and therefore very flexible data analytic system. Basic MRC may be used whenever a quantitative variable, the dependent variable, is to be studied as a function of, or in relationship of, any factors of interest, the independent variables. This book strongly emphasizes the critical role of theory in planning MRC analyses, and was written to serve as a textbook and manual in the application of the MRC system for data analysis by students and practitioners in diverse areas in inquiry in the behavioral sciences, health sciences, education, and business. Its orientation is nonmathematical, applied, and data-analytic. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-0-8058-2223-6},
  keywords = {Analysis of Variance,Behavioral Sciences,Multiple Regression,Statistical Correlation,Statistical Variables},
  file = {/Users/jimmy_z/Zotero/storage/75WNQJ9W/2002-18109-000.html}
}

@article{collinsComparisonInclusiveRestrictive2001,
  title = {A Comparison of Inclusive and Restrictive Strategies in Modern Missing Data Procedures},
  author = {Collins, L. M. and Schafer, J. L. and Kam, C. M.},
  year = {2001},
  month = dec,
  journal = {Psychol Methods},
  volume = {6},
  number = {4},
  pages = {330--351},
  issn = {1082-989X},
  abstract = {Two classes of modern missing data procedures, maximum likelihood (ML) and multiple imputation (MI), tend to yield similar results when implemented in comparable ways. In either approach, it is possible to include auxiliary variables solely for the purpose of improving the missing data procedure. A simulation was presented to assess the potential costs and benefits of a restrictive strategy, which makes minimal use of auxiliary variables, versus an inclusive strategy, which makes liberal use of such variables. The simulation showed that the inclusive strategy is to be greatly preferred. With an inclusive strategy not only is there a reduced chance of inadvertently omitting an important cause of missingness, there is also the possibility of noticeable gains in terms of increased efficiency and reduced bias, with only minor costs. As implemented in currently available software, the ML approach tends to encourage the use of a restrictive strategy, whereas the MI approach makes it relatively simple to use an inclusive strategy.},
  langid = {english},
  pmid = {11778676},
  keywords = {Confidence Intervals,Data Collection,Humans,Likelihood Functions,Models Statistical,Psychological Tests,Psychology Experimental,Psychometrics}
}

@book{crainiceanuMeasurementErrorNonlinear2006,
  title = {Measurement Error in Nonlinear Models: {{A}} Modern Perspective},
  shorttitle = {Measurement {{Error}} in {{Nonlinear Models}}},
  author = {Crainiceanu, David Ruppert, Leonard A. Stefanski, Ciprian M., Raymond J. Carroll},
  year = {2006},
  month = jun,
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  address = {New York},
  doi = {10.1201/9781420010138},
  abstract = {It's been over a decade since the first edition of Measurement Error in Nonlinear Models splashed onto the scene, and research in the field has certainly not cooled in the interim. In fact, quite the opposite has occurred. As a result, Measurement Error in Nonlinear Models: A Modern Perspective, Second Edition has been revamped and ex},
  isbn = {978-0-429-13963-5}
}

@article{cronbachCoefficientAlphaInternal1951,
  title = {Coefficient Alpha and the Internal Structure of Tests},
  author = {Cronbach, Lee J.},
  year = {1951},
  month = sep,
  journal = {Psychometrika},
  volume = {16},
  number = {3},
  pages = {297--334},
  issn = {1860-0980},
  doi = {10.1007/BF02310555},
  urldate = {2024-02-26},
  abstract = {A general formula ({$\alpha$}) of which a special case is the Kuder-Richardson coefficient of equivalence is shown to be the mean of all split-half coefficients resulting from different splittings of a test. {$\alpha$} is therefore an estimate of the correlation between two random samples of items from a universe of items like those in the test. {$\alpha$} is found to be an appropriate index of equivalence and, except for very short tests, of the first-factor concentration in the test. Tests divisible into distinct subtests should be so divided before using the formula. The index\$\${\textbackslash}bar r\_\{ij\} \$\$, derived from {$\alpha$}, is shown to be an index of inter-item homogeneity. Comparison is made to the Guttman and Loevinger approaches. Parallel split coefficients are shown to be unnecessary for tests of common types. In designing tests, maximum interpretability of scores is obtained by increasing the first-factor concentration in any separately-scored subtest and avoiding substantial group-factor clusters within a subtest. Scalability is not a requisite.},
  langid = {english},
  keywords = {Common Type,Internal Structure,Public Policy,Random Sample,Statistical Theory},
  file = {/Users/jimmy_z/Zotero/storage/I7BHM3QH/Cronbach - 1951 - Coefficient alpha and the internal structure of te.pdf}
}

@article{cunninghamModerationSportManagement2019a,
  title = {Moderation in Sport Management Research: {{Room}} for Growth},
  shorttitle = {Moderation in {{Sport Management Research}}},
  author = {Cunningham, George B. and Ahn, Na Young},
  year = {2019},
  journal = {Measurement in Physical Education and Exercise Science},
  volume = {23},
  number = {4},
  pages = {301--313},
  publisher = {Routledge},
  issn = {1091-367X},
  doi = {10.1080/1091367X.2018.1472095},
  urldate = {2024-02-26},
  abstract = {Moderators are variables that affect the relationship between a predictor and outcome. They help to clarify otherwise ambiguous patterns of results, extend theory, and signal the growth of a field. Given the importance of moderators, the authors offer an overview of methodological and statistical considerations for testing moderation and then examine sport management scholars' use of moderation in their research. A content analysis of "European Sport Management Quarterly," "Journal of Sport Management," and "Sport Management Review" shows that tests of moderation have not followed the growth in scholarship in the field. Further analyses showed (a) analysis of variance was the most popular analytical tool employed; (b) one in six tests of moderation were conducted incorrectly; and (c) 13\% of tests for moderation were conducted absent specific hypotheses or research questions. The authors offer implications for sport management researchers.},
  langid = {english},
  keywords = {Athletics,Regression (Statistics),Research,Research Methodology,Statistical Analysis,Structural Equation Models},
  annotation = {ERIC Number: EJ1233906},
  file = {/Users/jimmy_z/Zotero/storage/WKWKRLRL/eric-ed-gov.libproxy1.usc.edu.html}
}

@article{daszykowskiRobustStatisticsData2007,
  title = {Robust Statistics in Data Analysis --- {{A}} Review},
  author = {Daszykowski, M. and Kaczmarek, K. and Vander Heyden, Y. and Walczak, B.},
  year = {2007},
  month = feb,
  journal = {Chemometrics and Intelligent Laboratory Systems},
  volume = {85},
  number = {2},
  pages = {203--219},
  issn = {01697439},
  doi = {10.1016/j.chemolab.2006.06.016},
  urldate = {2024-02-26},
  abstract = {Presence of outliers in chemical data affects all least squares models, which are extensively used in chemometrics for data exploration and modeling. Therefore, more and more attention is paid to the so-called robust models and robust statistics that aim to construct models and estimates describing well data majority. Moreover, construction of robust models allows identifying outlying observations. The outliers identification is not only essential for a proper modeling but also for understanding the reasons for unique character of the outlying sample.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/KLYFKJU3/Daszykowski et al. - 2007 - Robust statistics in data analysis — A review.pdf}
}

@book{dekkingModernIntroductionProbability2005a,
  title = {A {{Modern Introduction}} to {{Probability}} and {{Statistics}}},
  author = {Dekking, Frederik Michel and Kraaikamp, Cornelis and Lopuha{\"a}, Hendrik Paul and Meester, Ludolf Erwin},
  year = {2005},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer},
  address = {London},
  doi = {10.1007/1-84628-168-7},
  urldate = {2024-03-06},
  isbn = {978-1-85233-896-1 978-1-84628-168-6},
  keywords = {Analysis,data analysis,Estimator,mathematical statistics,Random variable,simulation,statistics},
  file = {/Users/jimmy_z/Zotero/storage/PEN69UFR/Dekking et al. - 2005 - A Modern Introduction to Probability and Statistic.pdf}
}

@article{devliegerHypothesisTestingUsing2016,
  title = {Hypothesis Testing Using Factor Score Regression},
  author = {Devlieger, Ines and Mayer, Axel and Rosseel, Yves},
  year = {2016},
  month = oct,
  journal = {Educ Psychol Meas},
  volume = {76},
  number = {5},
  pages = {741--770},
  issn = {0013-1644},
  doi = {10.1177/0013164415607618},
  urldate = {2024-02-26},
  abstract = {In this article, an overview is given of four methods to perform factor score regression (FSR), namely regression FSR, Bartlett FSR, the bias avoiding method of Skrondal and Laake, and the bias correcting method of Croon. The bias correcting method is extended to include a reliable standard error. The four methods are compared with each other and with structural equation modeling (SEM) by using analytic calculations and two Monte Carlo simulation studies to examine their finite sample characteristics. Several performance criteria are used, such as the bias using the unstandardized and standardized parameterization, efficiency, mean square error, standard error bias, type I error rate, and power. The results show that the bias correcting method, with the newly developed standard error, is the only suitable alternative for SEM. While it has a higher standard error bias than SEM, it has a comparable bias, efficiency, mean square error, power, and type I error rate.},
  pmcid = {PMC5965529},
  pmid = {29795886},
  file = {/Users/jimmy_z/Zotero/storage/64UYAX6S/Devlieger et al. - 2016 - Hypothesis Testing Using Factor Score Regression.pdf}
}

@article{estabrookComparisonFactorScore2013,
  title = {A Comparison of Factor Score Estimation Methods in the Presence of Missing Data: {{Reliability}} and an Application to Nicotine Dependence},
  shorttitle = {A {{Comparison}} of {{Factor Score Estimation Methods}} in the {{Presence}} of {{Missing Data}}},
  author = {Estabrook, Ryne and Neale, Michael},
  year = {2013},
  month = jan,
  journal = {Multivariate Behav Res},
  volume = {48},
  number = {1},
  pages = {1--27},
  issn = {1532-7906},
  doi = {10.1080/00273171.2012.730072},
  abstract = {Factor score estimation is a controversial topic in psychometrics, and the estimation of factor scores from exploratory factor models has historically received a great deal of attention. However, both confirmatory factor models and the existence of missing data have generally been ignored in this debate. This article presents a simulation study that compares the reliability of sum scores, regression-based and expected posterior methods for factor score estimation for confirmatory factor models in the presence of missing data. Although all methods perform reasonably well with complete data, expected posterior-weighted (full) maximum likelihood methods are significantly more reliable than sum scores and regression estimators in the presence of missing data. Factor score reliability for complete data can be predicted by Guttman's 1955 formula for factor communality. Furthermore, factor score reliability for incomplete data can be reasonably approximated by communality raised to the [Formula: see text] power. An empirical demonstration shows that the full maximum likelihood method best preserves the relationship between nicotine dependence and a genetic predictor under missing data. Implications and recommendations for applied research are discussed.},
  langid = {english},
  pmcid = {PMC3773873},
  pmid = {24049215},
  file = {/Users/jimmy_z/Zotero/storage/SMV8VXQS/Estabrook and Neale - 2013 - A Comparison of Factor Score Estimation Methods in.pdf}
}

@article{foldnesChoiceProductIndicators2014,
  title = {The Choice of Product Indicators in Latent Variable Interaction Models: {{Post}} Hoc Analyses},
  shorttitle = {The Choice of Product Indicators in Latent Variable Interaction Models},
  author = {Foldnes, Nj{\aa}l and Hagtvet, Knut Arne},
  year = {2014},
  journal = {Psychological Methods},
  volume = {19},
  number = {3},
  pages = {444--457},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1463},
  doi = {10.1037/a0035728},
  abstract = {The unconstrained product indicator (PI) approach is a simple and popular approach for modeling nonlinear effects among latent variables. This approach leaves the practitioner to choose the PIs to be included in the model, introducing arbitrariness into the modeling. In contrast to previous Monte Carlo studies, we evaluated the PI approach by 3 post hoc analyses applied to a real-world case adopted from a research effort in social psychology. The measurement design applied 3 and 4 indicators for the 2 latent 1st-order variables, leaving the researcher with a choice among more than 4,000 possible PI configurations. Sixty so-called matched-pair configurations that have been recommended in previous literature are of special interest. In the 1st post hoc analysis we estimated the interaction effect for all PI configurations, keeping the real-world sample fixed. The estimated interaction effect was substantially affected by the choice of PIs, also across matched-pair configurations. Subsequently, a post hoc Monte Carlo study was conducted, with varying sample sizes and data distributions. Convergence, bias, Type I error and power of the interaction test were investigated for each matched-pair configuration and the all-pairs configuration. Variation in estimates across matched-pair configurations for a typical sample was substantial. The choice of specific configuration significantly affected convergence and the interaction test's outcome. The all-pairs configuration performed overall better than the matched-pair configurations. A further advantage of the all-pairs over the matched-pairs approach is its unambiguity. The final study evaluates the all-pairs configuration for small sample sizes and compares it to the non-PI approach of latent moderated structural equations. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Latent Variables,Mathematical Modeling,Statistical Analysis,Statistical Estimation,Structural Equation Modeling}
}

@article{hancockReliabilityAradoxAssessing2011,
  title = {The Reliability Aradox in Assessing Structural Relations within Covariance Structure Models},
  author = {Hancock, Gregory R. and Mueller, Ralph O.},
  year = {2011},
  month = apr,
  journal = {Educational and Psychological Measurement},
  volume = {71},
  number = {2},
  pages = {306--324},
  publisher = {SAGE Publications Inc},
  issn = {0013-1644},
  doi = {10.1177/0013164410384856},
  urldate = {2024-02-26},
  abstract = {A two-step process is commonly used to evaluate data--model fit of latent variable path models, the first step addressing the measurement portion of the model and the second addressing the structural portion of the model. Unfortunately, even if the fit of the measurement portion of the model is perfect, the ability to assess the fit within the structural portion is affected by the quality of the factor--variable relations within the measurement model. The result is that models with poorer quality measurement appear to have better data--model fit, whereas models with better quality measurement appear to have worse data--model fit. The current article illustrates this phenomenon across different classes of fit indices, discusses related structural assessment problems resulting from issues of measurement quality, and endorses a supplemental modeling step evaluating the structural portion of the model in isolation from the measurement model.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/AXEYP3RI/Hancock and Mueller - 2011 - The Reliability Paradox in Assessing Structural Re.pdf}
}

@article{harwellStrategyUsingBias2019,
  title = {A Strategy for Using Bias and {{RMSE}} as Outcomes in {{Monte Carlo}} Studies in Statistics},
  author = {Harwell, Michael},
  year = {2019},
  month = mar,
  journal = {J. Mod. Appl. Stat. Methods},
  volume = {17},
  number = {2},
  pages = {jmasm.eP2938},
  issn = {1538-9472},
  doi = {10.22237/jmasm/1551907966},
  urldate = {2024-02-26},
  abstract = {To help ensure important patterns of bias and accuracy are detected in Monte Carlo studies in statistics this paper proposes conditioning bias and root mean square error (RMSE) measures on estimated Type I and Type II error rates. A small Monte Carlo study is used to illustrate this argument.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/LWHF4D4L/Harwell - 2019 - A Strategy for Using Bias and RMSE as Outcomes in .pdf}
}

@incollection{hershbergerFactorScoreEstimation2005,
  title = {Factor Score Estimation},
  booktitle = {Encyclopedia of {{Statistics}} in {{Behavioral Science}}},
  author = {Hershberger, Scott L.},
  year = {2005},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/0470013192.bsa726},
  urldate = {2024-02-26},
  abstract = {Factors scores are measures of principal components or common factors. Under the principal components model, the factor scores are uniquely determined; under the common factor model, they are not. In the latter situation, the factor scores are indeterminate, potentially having an infinite number of solution sets, and thus their true values can only be estimated. Three methods of factor score estimation are discussed: (a) regression, (b) Bartlett's method, and (c) Anderson and Rubin's method. Although the properties and values of the factor score estimates produced by the three methods differ, the estimates are in general highly correlated.},
  copyright = {Copyright {\copyright} 2005 John Wiley \& Sons, Ltd. All rights reserved.},
  isbn = {978-0-470-01319-9},
  langid = {english},
  keywords = {common factor model,factor analysis,latent variables,principal components model,underidentification},
  file = {/Users/jimmy_z/Zotero/storage/Y27SDQB3/0470013192.html}
}

@article{hooglandRobustnessStudiesCovariance1998,
  title = {Robustness Studies in Covariance Structure Modeling: {{An}} Overview and a Meta-Analysis},
  shorttitle = {Robustness {{Studies}} in {{Covariance Structure Modeling}}},
  author = {HOOGLAND, JEFFREY J. and BOOMSMA, {\relax ANNE}},
  year = {1998},
  month = feb,
  journal = {Sociological Methods \& Research},
  volume = {26},
  number = {3},
  pages = {329--367},
  publisher = {SAGE Publications Inc},
  issn = {0049-1241},
  doi = {10.1177/0049124198026003003},
  urldate = {2024-02-26},
  abstract = {In covariance structure modeling, several estimation methods are available. The robustness of an estimator against specific violations of assumptions can be determined empirically by means of a Monte Carlo study. Many such studies in covariance structure analysis have been published, but the conclusions frequently seem to contradict each other. An overview of robustness studies in covariance structure analysis is given, and an attempt is made to generalize findings. Robustness studies are described and distinguished from each other systematically by means of certain characteristics. These characteristics serve as explanatory variables in a meta-analysis concerning the behavior of parameter estimators, standard error estimators, and goodness-of-fit statistics when the model is correctly specified.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/PEDNRYH9/HOOGLAND and BOOMSMA - 1998 - Robustness Studies in Covariance Structure Modelin.pdf}
}

@article{hsiaoEvaluationTwoMethods2018a,
  title = {Evaluation of Two Methods for Modeling Measurement Errors When Testing Interaction Effects with Observed Composite Scores},
  author = {Hsiao, Yu-Yu and Kwok, Oi-Man and Lai, Mark H. C.},
  year = {2018},
  month = apr,
  journal = {Educ Psychol Meas},
  volume = {78},
  number = {2},
  pages = {181--202},
  issn = {0013-1644},
  doi = {10.1177/0013164416679877},
  urldate = {2024-02-26},
  abstract = {Path models with observed composites based on multiple items (e.g., mean or sum score of the items) are commonly used to test interaction effects. Under this practice, researchers generally assume that the observed composites are measured without errors. In this study, we reviewed and evaluated two alternative methods within the structural equation modeling (SEM) framework, namely, the reliability-adjusted product indicator (RAPI) method and the latent moderated structural equations (LMS) method, which can both flexibly take into account measurement errors. Results showed that both these methods generally produced unbiased estimates of the interaction effects. On the other hand, the path model---without considering measurement errors---led to substantial bias and a low confidence interval coverage rate of nonzero interaction effects. Other findings and implications for future studies are discussed.},
  pmcid = {PMC5965658},
  pmid = {29795952},
  file = {/Users/jimmy_z/Zotero/storage/5NRJL8JY/Hsiao et al. - 2018 - Evaluation of Two Methods for Modeling Measurement.pdf}
}

@article{hsiaoModelingMeasurementErrors2021,
  title = {Modeling Measurement Errors of the Exogenous Composites from Congeneric Measures in Interaction Models},
  author = {Hsiao, Yu-Yu and Kwok, Oi-Man and Lai, Mark H. C.},
  year = {2021},
  journal = {Struct Equ Modeling},
  volume = {28},
  number = {2},
  pages = {250--260},
  issn = {1070-5511},
  doi = {10.1080/10705511.2020.1782206},
  urldate = {2024-02-26},
  abstract = {We investigated the performance of two single indicator methods: latent moderated structural equation (LMS) and reliability-adjusted product indicator (RAPI) methods, on testing interaction effects with congeneric measures, which vary in factor loadings and error variances under a common factor. Additionally, in the simulation study, we compared the performance of four reliability estimates (Cronbach's alpha, omega composite, Coefficient H, and greatest lower bound [GLB]) to adjust for the exogenous composites' measurement errors. Results from the study showed that: while estimating interaction effects with exogenous composites from congeneric measures, the four reliability estimates performed comparably well. Recommendations on the choice of reliability estimates between the LMS and the RAPI methods under different sample sizes and population reliability conditions are further discussed.},
  pmcid = {PMC8259412},
  pmid = {34239281},
  file = {/Users/jimmy_z/Zotero/storage/TY56HZEA/Hsiao et al. - 2021 - Modeling Measurement Errors of the Exogenous Compo.pdf}
}

@incollection{huberRobustStatistics2011,
  title = {Robust {{Statistics}}},
  booktitle = {International {{Encyclopedia}} of {{Statistical Science}}},
  author = {Huber, Peter J.},
  editor = {Lovric, Miodrag},
  year = {2011},
  pages = {1248--1251},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-04898-2_594},
  urldate = {2024-03-08},
  isbn = {978-3-642-04898-2},
  langid = {english}
}

@article{jackmanEstimatingLatentVariable2011a,
  title = {Estimating Latent Variable Interactions with the Unconstrained Approach: {{A}} Comparison of Methods to Form Product Indicators for Large, Unequal Numbers of Items},
  shorttitle = {Estimating {{Latent Variable Interactions With}} the {{Unconstrained Approach}}},
  author = {Jackman, Grace-Anne and Leite, Walter and Cochrane, David},
  year = {2011},
  month = apr,
  journal = {Structural Equation Modeling},
  volume = {18},
  pages = {274--288},
  doi = {10.1080/10705511.2011.557342},
  abstract = {This Monte Carlo simulation study investigated methods of forming product indicators for the unconstrained approach for latent variable interaction estimation when the exogenous factors are measured by large and unequal numbers of indicators. Product indicators were created based on multiplying parcels of the larger scale by indicators of the smaller scale, multiplying the three most reliable indicators of each scale matched by reliability, and matching items by reliability to create as many product indicators as the number of indicators of the smallest scale. The unconstrained approach was compared with the latent moderated structural equations (LMS) approach. All methods considered provided unbiased parameter estimates. Unbiased standard errors were obtained in all conditions with the LMS approach and when the sample size was large with the unconstrained approach. Power levels to test the latent interaction and Type I error rates were similar for all methods but slightly better for the LMS approach.}
}

@article{joreskogStatisticalAnalysisSets1971,
  title = {Statistical Analysis of Sets of Congeneric Tests},
  author = {J{\"o}reskog, K. G.},
  year = {1971},
  month = jun,
  journal = {Psychometrika},
  volume = {36},
  number = {2},
  pages = {109--133},
  issn = {1860-0980},
  doi = {10.1007/BF02291393},
  urldate = {2024-02-26},
  abstract = {Various models for sets of congeneric tests are considered, including models appropriate for the analysis of multitrait-multimethod data. All models are illustrated with real data. The special cases when two or more tests within a set are tau-equivalent or parallel are also considered. All data analyses are done within the framework of a general model by J{\"o}reskog [1970].},
  langid = {english},
  keywords = {Data Analysis,General Model,Public Policy,Real Data,Statistical Theory}
}

@inproceedings{Jreskog1996NonlinearSE,
  title = {Nonlinear Structural Equation Models: {{The Kenny-Judd}} Model with {{Interaction}} Effects},
  author = {J{\"o}reskog, Karl G. and Yang, Fan},
  year = {1996}
}

@article{kennyEstimatingNonlinearInteractive1984a,
  title = {Estimating the Nonlinear and Interactive Effects of Latent Variables},
  author = {Kenny, David A. and Judd, Charles M.},
  year = {1984},
  journal = {Psychological Bulletin},
  volume = {96},
  number = {1},
  pages = {201--210},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1455},
  doi = {10.1037/0033-2909.96.1.201},
  abstract = {Describes a procedure that enables researchers to estimate nonlinear and interactive effects of latent variables in structural equation models. Given that the latent variables are normally distributed, the parameters of such models can be estimated. To do this, products of the measured variables are used as indicators of latent product variables. Estimation must be done using a procedure that allows nonlinear constraints on parameters. The procedure is demonstrated in 3 examples. The 1st 2 examples use artificial data with known parameter values. These parameters are successfully recovered by the procedure. The final complex example uses national election survey data. (14 ref) (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Estimation,Latent Variables,Mathematical Modeling},
  file = {/Users/jimmy_z/Zotero/storage/IAY5ZR2M/1984-27738-001.html}
}

@article{dempsterMaximumLikelihoodIncomplete1977,
  title = {Maximum {{Likelihood}} from {{Incomplete Data}} via the {{EM Algorithm}}},
  author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
  year = {1977},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {39},
  number = {1},
  eprint = {2984875},
  eprinttype = {jstor},
  pages = {1--38},
  publisher = {[Royal Statistical Society, Wiley]},
  issn = {0035-9246},
  urldate = {2024-04-12},
  abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.}
}

@article{kleinMaximumLikelihoodEstimation2000a,
  title = {Maximum Likelihood Estimation of Latent Interaction Effects with the {{LMS}} Method},
  author = {Klein, Andreas and Moosbrugger, Helfried},
  year = {2000},
  journal = {Psychometrika},
  volume = {65},
  number = {4},
  pages = {457--474},
  publisher = {Springer},
  address = {Germany},
  issn = {1860-0980},
  doi = {10.1007/BF02296338},
  abstract = {In the context of structural equation modeling (SEM), a general interaction model with multiple latent interaction effects is introduced. A stochastic analysis represents the nonnormal distribution of the joint indicator vector as a finite mixture of normal distributions. The Latent Moderated Structural Equations (LMS) approach is a new method developed for the analysis of the general interaction model that utilizes the mixture distribution and provides a maximum likelihood (ML) estimation of model parameters by adapting the expectation maximation (EM) algorithm. The finite sample properties and the robustness of LMS are discussed. Finally, the applicability of the new method is illustrated by an empirical example. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Algorithms,Maximum Likelihood,Models,Psychometrics,Sociometry,Statistical Estimation,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/25L3NW4J/2001-16342-002.html}
}

@book{klinePrinciplesPracticeStructural2016,
  title = {Principles and Practice of Structural Equation Modeling, 4th Ed},
  author = {Kline, Rex B.},
  year = {2016},
  series = {Principles and Practice of Structural Equation Modeling, 4th Ed},
  pages = {xvii, 534},
  publisher = {Guilford Press},
  address = {New York, NY, US},
  abstract = {Rex Kline has assembled a fourth edition that retains all the wonderful features of his best selling earlier editions, and he seamlessly integrates recent advances in structural equation modeling (SEM). Rex is a scholar of SEM and has a special gift---of being able to communicate complex statistical concepts in language that all readers can grasp. The accessible style of writing and the many pedagogical features of the book (e.g., chapter-end annotated reading lists, exercises with answers) make it a "must have" for any user of SEM. It is a resource that keeps improving and expanding with each new edition and is the resource I recommend first on this subject---whether the question comes from a beginner or an experienced user. As a scholar of modern statistical practice and techniques. Rex has studied the developments and advances in the world of SEM generally, and he has covered "hot" topics, such as Pearl's structural causal modeling. His coverage of Pearl's graph theory approach to causal reasoning, as many of the reviewers of prepublication drafts of the fourth edition have also noted, is both easy to understand and comprehensive. It's so good, he ought to get a prize for best in presentation! In this new edition, he takes us through causal mediation analysis, conditional process modeling, and confirmatory factor analysis with categorical indicators. Other additions to this masterpiece of pedagogy include insightful discussions of significance testing, the use of bootstrap estimation, and the principles of measurement theory. Although Rex suggests in his Introduction that no single book can cover all of SEM, his book is about as thorough as they come. His didactic approach is refreshing and engaging, and the breadth and depth of material covered is simply impressive. As he notes and you will feel. Rex is a researcher talking to you as a fellow researcher, carefully explaining in conceptually driven terms the logic and principles that underlie the world of SEM. The wealth of examples provide entry points for researchers across a broad array of disciplines. This book will speak to you regardless of your field or specific area of expertise. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-1-4625-2334-4 978-1-4625-2335-1 978-1-4625-2300-9},
  keywords = {Statistical Analysis,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/TJFEYZ7G/2015-56948-000.html}
}

@article{kyriazosAppliedPsychometricsSample2018,
  title = {Applied Psychometrics: {{Sample}} Size and Sample Power Considerations in Factor Analysis ({{EFA}}, {{CFA}}) and {{SEM}} in General},
  shorttitle = {Applied {{Psychometrics}}},
  author = {Kyriazos, Theodoros},
  year = {2018},
  month = jan,
  journal = {Psychology},
  volume = {09},
  pages = {2207--2230},
  doi = {10.4236/psych.2018.98126},
  file = {/Users/jimmy_z/Zotero/storage/ZPYUEKTX/Kyriazos - 2018 - Applied Psychometrics Sample Size and Sample Powe.pdf}
}

@article{laiCorrectingUnreliabilityPartial2023,
  title = {Correcting for Unreliability and Partial Invariance: {{A}} Two-Stage Path Analysis Approach},
  shorttitle = {Correcting for {{Unreliability}} and {{Partial Invariance}}},
  author = {Lai, Mark H. C. and Tse, Winnie Wing-Yee and Zhang, Gengrui and Li, Yixiao and Hsiao, Yu-Yu},
  year = {2023},
  month = mar,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {30},
  number = {2},
  pages = {258--271},
  publisher = {Routledge},
  issn = {1070-5511},
  doi = {10.1080/10705511.2022.2125397},
  urldate = {2024-02-26},
  abstract = {In path analysis, using composite scores without adjustment for measurement unreliability and violations of factorial invariance across groups lead to biased estimates of path coefficients. Although joint modeling of measurement and structural models can theoretically yield consistent structural association estimates, estimating a model with many variables is often impractical in small samples. A viable alternative is two-stage path analysis (2S-PA), where researchers first obtain factor scores and the corresponding individual-specific reliability coefficients, and then use those factor scores to analyze structural associations while accounting for their unreliability. The current paper extends 2S-PA to also account for partial invariance. Two simulation studies show that 2S-PA outperforms joint modeling in terms of model convergence, the efficiency of structural parameter estimation, and confidence interval coverage, especially in small samples and with categorical indicators. We illustrate 2S-PA by reanalyzing data from a multiethnic study that predicts drinking problems using college-related alcohol beliefs.},
  keywords = {Factor scores,measurement error,partial factorial invariance,reliability adjustment,two-stage path analysis},
  file = {/Users/jimmy_z/Zotero/storage/DC9KP982/Lai et al. - 2023 - Correcting for Unreliability and Partial Invarianc.pdf}
}

@article{linStructuralEquationModels2010b,
  title = {Structural Equation Models of Latent Interactions: {{Clarification}} of Orthogonalizing and Double-Mean-Centering Strategies},
  shorttitle = {Structural {{Equation Models}} of {{Latent Interactions}}},
  author = {Lin, Guan-Chyun and Wen, Zhonglin and Marsh, Herbert W. and Lin, Huey-Shyan},
  year = {2010},
  month = jul,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {17},
  number = {3},
  pages = {374--391},
  publisher = {Routledge},
  issn = {1070-5511},
  doi = {10.1080/10705511.2010.488999},
  urldate = {2024-02-26},
  abstract = {The purpose of this investigation is to compare a new (double-mean-centering) strategy to estimating latent interactions in structural equation models with the (single) mean-centering strategy (Marsh, Wen, \& Hau, 2004, 2006) and the orthogonalizing strategy (Little, Bovaird, \& Widaman, 2006; Marsh et al., 2007). A key benefit of the orthogonalizing strategy is that it eliminated the need to estimate a mean structure as required by the mean-centering strategy, but required a potentially cumbersome 2-step estimation procedure. In contrast, the double-mean-centering strategy eliminates both the need for the mean structure and the cumbersome 2-stage estimation procedure. Furthermore, although the orthogonalizing and double-mean-centering strategies are equivalent when all indicators are normally distributed, the double-mean-centering strategy is superior when this normality assumption is violated. In summary, we recommend that applied researchers wanting to estimate latent interaction effects use the double-mean-centering strategy instead of either the single-mean-centering or orthogonalizing strategies, thus allowing them to ignore the cumbersome mean structure.},
  file = {/Users/jimmy_z/Zotero/storage/ZTGIL5E9/Lin et al. - 2010 - Structural Equation Models of Latent Interactions.pdf}
}

@book{lordStatisticalTheoriesMental1968,
  title = {Statistical Theories of Mental Test Scores},
  author = {Lord, F.M. and Novick, M.R. and Birnbaum, Allan},
  year = {1968},
  series = {Statistical Theories of Mental Test Scores},
  publisher = {Addison-Wesley},
  address = {Oxford, England},
  abstract = {A comprehensive theory of mental testing, covering such topics as statistical foundations, classical theory, weak true score models, validity, latent trait models, and strong true score theory.  Harvard Book List (edited) 1971 \#115 (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/jimmy_z/Zotero/storage/UUYJJGWL/1968-35040-000.html}
}

@article{mackinnonHowWhomMediation2008a,
  title = {How and for Whom? {{Mediation}} and Moderation in Health Psychology},
  shorttitle = {How and for Whom?},
  author = {MacKinnon, David P. and Luecken, Linda J.},
  year = {2008},
  month = mar,
  journal = {Health Psychol},
  volume = {27},
  number = {2S},
  pages = {S99-S100},
  issn = {1930-7810},
  doi = {10.1037/0278-6133.27.2(Suppl.).S99},
  abstract = {Health psychology is maturing to include both major studies relating IVs to DVs as well as in-depth investigation of how these relations occur and for whom. These analyses reflect the richness of data collected in investigations of health and hold the promise of uncovering important pathways by which psychological factors influence health. From a methodological standpoint, investigation of mediation and moderation represents how a third variable may be incorporated in statistical analyses to uncover underlying mechanisms, differing effects on unique populations, or conditions under which an effect may be pronounced or diminished. Often the addition of these measures to research projects costs very little, but offers tremendous potential to yield detailed information critical to the advancement of theory and practice in health psychology.},
  langid = {english},
  pmcid = {PMC2821200},
  pmid = {18377161},
  keywords = {Behavioral Medicine,Humans,Mental Disorders},
  file = {/Users/jimmy_z/Zotero/storage/J2NL9Q42/MacKinnon and Luecken - 2008 - How and for whom Mediation and moderation in heal.pdf}
}

@article{marshStructuralEquationModels2004a,
  title = {Structural Equation Models of Latent Interactions: Evaluation of Alternative Estimation Strategies and Indicator Construction},
  shorttitle = {Structural Equation Models of Latent Interactions},
  author = {Marsh, Herbert W. and Wen, Zhonglin and Hau, Kit-Tai},
  year = {2004},
  month = sep,
  journal = {Psychol Methods},
  volume = {9},
  number = {3},
  pages = {275--300},
  issn = {1082-989X},
  doi = {10.1037/1082-989X.9.3.275},
  abstract = {Interactions between (multiple indicator) latent variables are rarely used because of implementation complexity and competing strategies. Based on 4 simulation studies, the traditional constrained approach performed more poorly than did 3 new approaches--unconstrained, generalized appended product indicator, and quasi-maximum-likelihood (QML). The authors' new unconstrained approach was easiest to apply. All 4 approaches were relatively unbiased for normally distributed indicators, but the constrained and QML approaches were more biased for nonnormal data; the size and direction of the bias varied with the distribution but not with the sample size. QML had more power, but this advantage was qualified by consistently higher Type I error rates. The authors also compared general strategies for defining product indicators to represent the latent interaction factor.},
  langid = {english},
  pmid = {15355150},
  keywords = {Analysis of Variance,Humans,Likelihood Functions,Mathematical Computing,Models Statistical,Nonlinear Dynamics,Psychology Experimental,Software}
}

@article{armingerBayesianApproachNonlinear1998a,
  title = {A {{Bayesian}} Approach to Nonlinear Latent Variable Models Using the {{Gibbs}} Sampler and the {{Metropolis-Hastings}} Algorithm},
  author = {Arminger, Gerhard and Muth{\'e}n, Bengt O.},
  year = {1998},
  journal = {Psychometrika},
  volume = {63},
  number = {3},
  pages = {271--300},
  publisher = {Springer},
  address = {Germany},
  issn = {1860-0980},
  doi = {10.1007/BF02294856},
  abstract = {Nonlinear latent variable models are specified that include quadratic forms and interactions of latent regressor variables as special cases. To estimate the parameters, the models are put in a Bayesian framework with conjugate priors for the parameters. The posterior distributions of the parameters and the latent variables are estimated using Markov chain Monte Carlo methods, such as the Gibbs sampler and the Metropolis-Hastings algorithm. The proposed estimation methods are illustrated by 2 simulation studies and by the estimation of a non-linear model for the dependence of performance on task complexity and goal specificity using empirical data. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Algorithms,Latent Variables,Mathematical Modeling,Nonlinear Regression},
  file = {/Users/jimmy_z/Zotero/storage/LKN6P6SI/Arminger and Muthén - 1998 - A Bayesian approach to nonlinear latent variable m.pdf;/Users/jimmy_z/Zotero/storage/ZZXKPF9U/1998-12086-005.html}
}

@article{kelavaNonlinearDynamicLatent2019,
  title = {A {{Nonlinear Dynamic Latent Class Structural Equation Model}}},
  author = {Kelava, Augustin and Brandt, Holger},
  year = {2019},
  month = jul,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {26},
  number = {4},
  pages = {509--528},
  issn = {1070-5511, 1532-8007},
  doi = {10.1080/10705511.2018.1555692},
  urldate = {2024-04-12},
  abstract = {In this article, we propose a nonlinear dynamic latent class structural equation modeling (NDLC-SEM). It can be used to examine intra-individual processes of observed or latent variables. These processes are decomposed into parts which include individual- and time-specific components. Unobserved heterogeneity of the intra-individual processes are modeled via a latent Markov process that can be predicted by individual- and time-specific variables as random effects. We discuss examples of sub-models which are special cases of the more general NDLC-SEM framework. Furthermore, we provide empirical examples and illustrate how to estimate this model in a Bayesian framework. Finally, we discuss essential properties of the proposed framework, give recommendations for applications, and highlight some general problems in the estimation of parameters in comprehensive frameworks for intensive longitudinal data.},
  langid = {english}
}

@article{maslowskyEstimatingInterpretingLatent2015a,
  title = {Estimating and Interpreting Latent Variable Interactions: {{A}} Tutorial for Applying the Latent Moderated Structural Equations Method},
  shorttitle = {Estimating and Interpreting Latent Variable Interactions},
  author = {Maslowsky, Julie and Jager, Justin and Hemken, Douglas},
  year = {2015},
  month = jan,
  journal = {Int J Behav Dev},
  volume = {39},
  number = {1},
  pages = {87--96},
  issn = {0165-0254},
  doi = {10.1177/0165025414552301},
  urldate = {2024-02-26},
  abstract = {Latent variables are common in psychological research. Research questions involving the interaction of two variables are likewise quite common. Methods for estimating and interpreting interactions between latent variables within a structural equation modeling framework have recently become available. The latent moderated structural equations (LMS) method is one that is built into Mplus software. The potential utility of this method is limited by the fact that the models do not produce traditional model fit indices, standardized coefficients, or effect sizes for the latent interaction, which renders model fitting and interpretation of the latent variable interaction difficult. This article compiles state-of-the-science techniques for assessing LMS model fit, obtaining standardized coefficients, and determining the size of the latent interaction effect in order to create a tutorial for new users of LMS models. The recommended sequence of model estimation and interpretation is demonstrated via a substantive example and a Monte Carlo simulation. Finally, extensions of this method are discussed, such as estimating quadratic effects of latent factors and interactions between latent slope and intercept factors, which hold significant potential for testing and advancing developmental theories.},
  pmcid = {PMC4606468},
  pmid = {26478643},
  file = {/Users/jimmy_z/Zotero/storage/WQRWCJJ8/Maslowsky et al. - 2015 - Estimating and interpreting latent variable intera.pdf}
}

@article{mcdonaldTheoreticalFoundationsPrincipal1970,
  title = {The Theoretical Foundations of Principal Factor Analysis, Canonical Factor Analysis, and Alpha Factor Analysis},
  author = {McDonald, Roderick P.},
  year = {1970},
  journal = {British Journal of Mathematical and Statistical Psychology},
  volume = {23},
  number = {1},
  pages = {1--21},
  issn = {2044-8317},
  doi = {10.1111/j.2044-8317.1970.tb00432.x},
  urldate = {2024-02-26},
  abstract = {It is shown that PFA, CFA and AFA are particular cases of a scale-invariant factoring procedure based on variance ratios of certain weighted combinations of variables. Standard derivations in the literature are shown, in contrast, to have unsatisfactory features. It is suggested that the choice between PFA, CFA and AFA involves relatively independent choices of features of each, and that in most cases CFA is to be preferred.},
  copyright = {1970 The British Psychological Society},
  langid = {english}
}

@article{moulderComparisonMethodsEstimating2002a,
  title = {Comparison of Methods for Estimating and Testing Latent Variable Interactions},
  author = {Moulder, Bradley C. and Algina, James},
  year = {2002},
  journal = {Structural Equation Modeling},
  volume = {9},
  number = {1},
  pages = {1--19},
  publisher = {Lawrence Erlbaum},
  address = {US},
  issn = {1532-8007},
  doi = {10.1207/S15328007SEM0901_1},
  abstract = {Structural equation modeling methods for estimating and testing hypotheses about an interaction between continuous variables were investigated. The methods were (1) K. A. Bollen's (1996) 2-stage least squares (TSLS) method, R. A. Ping's (1996) 2-step maximum likelihood (ML) method, and J. Jaccard and C. K. Wan's (1995) ML method for the Kenny--Judd model (D. A. Kenny and C. M. Judd, 1984); (2) a 2-step ML procedure and ML estimation of the J{\"o}reskog--Yang model (K. G. J{\"o}reskog and F. Yang 1996); and (3) ML estimation of a revised J{\"o}reskog--Yang model. The TSLS procedure exhibited more bias and lower power than the other methods. Under ML estimation of the J{\"o}reskog--Yang model, Type I error rates were not well controlled when robust standard errors were used. Among the remaining procedures, the Jaccard--Wan procedure and ML estimation of the revised J{\"o}reskog--Yang procedure were most effective, with the latter having some small advantages over the former. A technical description of the simulation is appended. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Empirical Methods,Estimation,Latent Variables,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/CQ9EEGXS/2002-10162-001.html}
}

@article{muellerStructuralEquationModeling1997a,
  title = {Structural Equation Modeling: {{Back}} to Basics},
  shorttitle = {Structural Equation Modeling},
  author = {Mueller, Ralph O.},
  year = {1997},
  journal = {Structural Equation Modeling},
  volume = {4},
  number = {4},
  pages = {353--369},
  publisher = {Lawrence Erlbaum},
  address = {US},
  issn = {1532-8007},
  doi = {10.1080/10705519709540081},
  abstract = {Major technological advances incorporated into structural equation modeling (SEM) computer programs now make it possible for practitioners who are basically unfamiliar with the purposes and limitations of SEM to use this tool within their research contexts. The quest to simplify the data analysis step in the research process has---at least with regard to SEM---created a situation that allows practitioners to apply SEM but forgetting, knowingly ignoring, or most dangerously, being ignorant of some basic philosophical and statistical issues that must be addressed before sound SEM analyses should be conducted. This article focuses on some of the almost forgotten topics taken here from each step in the SEM process: model conceptualization, identification and parameter estimation, and data-model fit assessment and model modification. The main objective is to raise awareness among researchers new to SEM of a few basic but key philosophical and statistical issues. These should be addressed before launching into any one of the new generation of SEM software packages and being led astray by the seemingly irresistible temptation to prematurely start "playing" with the data. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Experimentation,Statistical Analysis,Statistical Data,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/RXTF6LBE/1998-00937-005.html}
}

@Article{simdesign,
    title = {Writing effective and reliable {Monte Carlo} simulations
      with the {SimDesign} package},
    author = {R. Philip Chalmers and Mark C. Adkins},
    journal = {The Quantitative Methods for Psychology},
    year = {2020},
    volume = {16},
    number = {4},
    pages = {248--280},
    doi = {10.20982/tqmp.16.4.p248},
  }

@book{muthen2017mplus,
  title = {Mplus Version 8 User's Guide},
  author = {Muthen, L.K. and Muthen, B. and Angeles)., Muth{\'e}n \& Muth{\'e}n (Los},
  year = {2017},
  publisher = {Muthen \& Muthen},
  isbn = {978-0-9829983-2-8}
}

@article{muthenHowUseMonte2002,
  title = {How to Use a {{Monte Carlo}} Study to Decide on Sample Size and Determine Power},
  author = {Muth{\'e}n, Linda K. and Muth{\'e}n, Bengt O.},
  year = {2002},
  month = oct,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {9},
  number = {4},
  pages = {599--620},
  publisher = {Routledge},
  issn = {1070-5511},
  doi = {10.1207/S15328007SEM0904_8},
  urldate = {2024-02-26},
  abstract = {A common question asked by researchers is, "What sample size do I need for my study?" Over the years, several rules of thumb have been proposed. In reality there is no rule of thumb that applies to all situations. The sample size needed for a study depends on many factors, including the size of the model, distribution of the variables, amount of missing data, reliability of the variables, and strength of the relations among the variables. The purpose of this article is to demonstrate how substantive researchers can use a Monte Carlo study to decide on sample size and determine power. Two models are used as examples, a confirmatory factor analysis (CFA) model and a growth model. The analyses are carried out using the Mplus program (Muth{\'e}n\& Muth{\'e}n 1998).},
  file = {/Users/jimmy_z/Zotero/storage/LNT33RLJ/Muthén and Muthén - 2002 - How to Use a Monte Carlo Study to Decide on Sample.pdf}
}

@article{radloffCESDScaleSelfreport1977b,
  title = {The {{CES-D}} Scale: {{A}} Self-Report Depression Scale for Research in the General Population},
  shorttitle = {The {{CES-D Scale}}},
  author = {Radloff, Lenore Sawyer},
  year = {1977},
  month = jun,
  journal = {Applied Psychological Measurement},
  volume = {1},
  number = {3},
  pages = {385--401},
  publisher = {SAGE Publications Inc},
  issn = {0146-6216},
  doi = {10.1177/014662167700100306},
  urldate = {2024-02-26},
  abstract = {The CES-D scale is a short self-report scale designed to measure depressive symptomatology in the general population. The items of the scale are symptoms associated with depression which have been used in previously validated longer scales. The new scale was tested in household interview surveys and in psychiatric settings. It was found to have very high internal consistency and adequate test- retest repeatability. Validity was established by pat terns of correlations with other self-report measures, by correlations with clinical ratings of depression, and by relationships with other variables which support its construct validity. Reliability, validity, and factor structure were similar across a wide variety of demographic characteristics in the general population samples tested. The scale should be a useful tool for epidemiologic studies of de pression.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/LIYJE2B9/Radloff - 1977 - The CES-D Scale A Self-Report Depression Scale fo.pdf}
}

@article{raykovEstimationCompositeReliability1997,
  title = {Estimation of Composite Reliability for Congeneric Measures},
  author = {Raykov, Tenko},
  year = {1997},
  journal = {Applied Psychological Measurement},
  volume = {21},
  number = {2},
  pages = {173--184},
  publisher = {Sage Publications},
  address = {US},
  issn = {1552-3497},
  doi = {10.1177/01466216970212006},
  abstract = {A structural equation model is described that permits estimation of the reliability index and coefficient of a composite test for congeneric measures. The method is also helpful in exploring the factorial structure of an item set, and its use in scale reliability estimation and development is illustrated. The estimator of composite reliability it yields does not possess the general underestimation property of Cronbach's coefficient {$\alpha$}. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Statistical Correlation,Statistical Estimation,Statistical Reliability,Structural Equation Modeling},
  file = {/Users/jimmy_z/Zotero/storage/PD425XLS/1998-02976-006.html}
}

@article{wirthItemFactorAnalysis2007,
  title = {Item Factor Analysis: {{Current}} Approaches and Future Directions},
  shorttitle = {Item Factor Analysis},
  author = {Wirth, R. J. and Edwards, Michael C.},
  year = {2007},
  journal = {Psychological Methods},
  volume = {12},
  number = {1},
  pages = {58--79},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1463},
  doi = {10.1037/1082-989X.12.1.58},
  abstract = {The rationale underlying factor analysis applies to continuous and categorical variables alike; however, the models and estimation methods for continuous (i.e., interval or ratio scale) data are not appropriate for item-level data that are categorical in nature. The authors provide a targeted review and synthesis of the item factor analysis (IFA) estimation literature for ordered-categorical data (e.g., Likert-type response scales) with specific attention paid to the problems of estimating models with many items and many factors. Popular IFA models and estimation methods found in the structural equation modeling and item response theory literatures are presented. Following this presentation, recent developments in the estimation of IFA parameters (e.g., Markov chain Monte Carlo) are discussed. The authors conclude with considerations for future research on IFA, simulated examples, and advice for applied researchers. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Confirmatory Factor Analysis,Estimation,Factor Analysis,Item Response Theory,Markov Chains,Statistical Estimation},
  file = {/Users/jimmy_z/Zotero/storage/VNCCJL3J/Wirth and Edwards - 2007 - Item factor analysis Current approaches and futur.pdf}
}

@article{rousseeuwRobustStatisticsOutlier2011,
  title = {Robust Statistics for Outlier Detection},
  author = {Rousseeuw, Peter J. and Hubert, Mia},
  year = {2011},
  journal = {WIREs Data Mining and Knowledge Discovery},
  volume = {1},
  number = {1},
  pages = {73--79},
  issn = {1942-4795},
  doi = {10.1002/widm.2},
  urldate = {2024-02-26},
  abstract = {When analyzing data, outlying observations cause problems because they may strongly influence the result. Robust statistics aims at detecting the outliers by searching for the model fitted by the majority of the data. We present an overview of several robust methods and outlier detection tools. We discuss robust procedures for univariate, low-dimensional, and high-dimensional data such as estimation of location and scatter, linear regression, principal component analysis, and classification. {\copyright} 2011 John Wiley \& Sons, Inc. WIREs Data Mining Knowl Discov 2011 1 73-79 DOI: 10.1002/widm.2 This article is categorized under: Algorithmic Development {$>$} Biological Data Mining Algorithmic Development {$>$} Spatial and Temporal Data Mining Application Areas {$>$} Health Care Technologies {$>$} Structure Discovery and Clustering},
  copyright = {Copyright {\copyright} 2011 John Wiley \& Sons, Inc.},
  langid = {english},
  file = {/Users/jimmy_z/Zotero/storage/E7XUT67V/Rousseeuw and Hubert - 2011 - Robust statistics for outlier detection.pdf}
}

@article{rousseeuwAlternativesMedianAbsolute1993,
  title = {Alternatives to the {{Median Absolute Deviation}}},
  author = {Rousseeuw, Peter J. and Croux, Christophe},
  year = {1993},
  journal = {Journal of the American Statistical Association},
  volume = {88},
  number = {424},
  eprint = {2291267},
  eprinttype = {jstor},
  pages = {1273--1283},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  issn = {0162-1459},
  doi = {10.2307/2291267},
  urldate = {2024-03-08},
  abstract = {In robust estimation one frequently needs an initial or auxiliary estimate of scale. For this one usually takes the median absolute deviation {$<$}tex-math{$>\$\backslash$}mathrm\{MAD\}\_n = 1.4826 {\textbackslash}operatorname\{med\}\_i{\textbackslash}\{{\textbar} x\_i - {\textbackslash}operatorname\{med\}\_jx\_j{\textbar}{\textbackslash}\}\${$<$}/tex-math{$>$}, because it has a simple explicit formula, needs little computation time, and is very robust as witnessed by its bounded influence function and its 50\% breakdown point. But there is still room for improvement in two areas: the fact that MAD\textsubscript{n} is aimed at symmetric distributions and its low (37\%) Gaussian efficiency. In this article we set out to construct explicit and 50\% breakdown scale estimators that are more efficient. We consider the estimator {$<$}tex-math{$>\$$}S\_n = 1.1926 {\textbackslash}operatorname\{med\}\_i{\textbackslash}\{{\textbackslash}operatorname\{med\}\_j{\textbar}x\_i - x\_j{\textbar}{\textbackslash}\}\${$<$}/tex-math{$>$} and the estimator Q\textsubscript{n} given by the .25 quantile of the distances {$<$}latex{$>\$\backslash$}\{{\textbar}x\_i - x\_j{\textbar}; i {$<$} j{\textbackslash}\}\${$<$}/latex{$>$}. Note that S\textsubscript{n} and Q\textsubscript{n} do not need any location estimate. Both S\textsubscript{n} and Q\textsubscript{n} can be computed using O(n log n) time and O(n) storage. The Gaussian efficiency of S\textsubscript{n} is 58\%, whereas Q\textsubscript{n} attains 82\%. We study S\textsubscript{n} and Q\textsubscript{n} by means of their influence functions, their bias curves (for implosion as well as explosion), and their finite-sample performance. Their behavior is also compared at non-Gaussian models, including the negative exponential model where S\textsubscript{n} has a lower gross-error sensitivity than the MAD.}
}

@Manual{semtools,
    title = {\texttt{semTools}: {U}seful tools for structural equation
      modeling},
    author = {Terrence D. Jorgensen and Sunthud Pornprasertmanit and
      Alexander M. Schoemann and Yves Rosseel},
    year = {2022},
    note = {R package version 0.5-6},
    url = {https://CRAN.R-project.org/package=semTools},
  }

@article{schoemannTestingInterpretingLatent2021,
  title = {Testing and Interpreting Latent Variable Interactions Using the {{semTools}} Package},
  author = {Schoemann, Alexander M. and Jorgensen, Terrence D.},
  year = {2021},
  month = sep,
  journal = {Psych},
  volume = {3},
  number = {3},
  pages = {322--335},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2624-8611},
  doi = {10.3390/psych3030024},
  urldate = {2024-02-26},
  abstract = {Examining interactions among predictors is an important part of a developing research program. Estimating interactions using latent variables provides additional power to detect effects over testing interactions in regression. However, when predictors are modeled as latent variables, estimating and testing interactions requires additional steps beyond the models used for regression. We review methods of estimating and testing latent variable interactions with a focus on product indicator methods. Product indicator methods of examining latent interactions provide an accurate method to estimate and test latent interactions and can be implemented in any latent variable modeling software package. Significant latent interactions require additional steps (plotting and probing) to interpret interaction effects. We demonstrate how these methods can be easily implemented using functions in the semTools package with models fit using the lavaan package in R, and we illustrate how these methods work using an applied example concerning teacher stress and testing.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {interactions,latent variable,moderation,structural equation modeling},
  file = {/Users/jimmy_z/Zotero/storage/WHXNM2CP/Schoemann and Jorgensen - 2021 - Testing and Interpreting Latent Variable Interacti.pdf}
}

@article{steinmetzThreeApproachesEstimate2011a,
  title = {Three Approaches to Estimate Latent Interaction Effects: {{Intention}} and Perceived Behavioral Control in the Theory of Planned Behavior},
  shorttitle = {Three {{Approaches}} to {{Estimate Latent Interaction Effects}}},
  author = {Steinmetz, Holger and Davidov, Eldad and Schmidt, Peter},
  year = {2011},
  month = apr,
  journal = {Methodological Innovations Online},
  volume = {6},
  number = {1},
  pages = {95--110},
  publisher = {SAGE Publications},
  issn = {1748-0612},
  doi = {10.4256/mio.2010.0030},
  urldate = {2024-02-26},
  abstract = {Interaction effects between explanatory constructs are an important part of many social theories. Analyses of interaction effects between variables using regression techniques have low power because they do not control for measurement errors. Therefore, latent interaction modeling using structural equation modeling (SEM) has been proposed as a better alternative to test for interaction effects. In contrast to traditional and complicated ?constrained? SEM approaches, two recent developments, the unconstrained approach and the residual centering approach, are especially attractive for applied researchers as they are much easier to implement. However, applied researchers still seem to be unsure about how to apply these approaches. In this study, we illustrate the use of the unconstrained and the residual centering approach and compare these approaches with the constrained approach of Algina and Moulder (2001) using data from a field study of 1,442 students. Theoretical background is the theory of planned behavior (Ajzen, 1991) in which we test the proposed interaction between an individual's intention to perform a behavior and perceived behavioral control (PBC) on behavior. The illustration should assist researchers interested in testing interaction effects using structural equation modeling.},
  file = {/Users/jimmy_z/Zotero/storage/4I7HIEVP/Steinmetz et al. - 2011 - Three Approaches to Estimate Latent Interaction Ef.pdf}
}

@article{tenbergeGreatestLowerBound2004,
  title = {The Greatest Lower Bound to the Reliability of a Test and the Hypothesis of Unidimensionality},
  author = {Ten Berge, Jos M. F. and So{\v c}an, Gregor},
  year = {2004},
  month = dec,
  journal = {Psychometrika},
  volume = {69},
  number = {4},
  pages = {613--625},
  issn = {1860-0980},
  doi = {10.1007/BF02289858},
  urldate = {2024-02-26},
  abstract = {To assess the reliability of congeneric tests, specifically designed reliability measures have been proposed. This paper emphasizes that such measures rely on a unidimensionality hypothesis, which can neither be confirmed nor rejected when there are only three test parts, and will invariably be rejected when there are more than three test parts. Jackson and Agunwamba's (1977) greatest lower bound to reliability is proposed instead. Although this bound has a reputation for overestimating the population value when the sample size is small, this is no reason to prefer the unidimensionality-based reliability. Firstly, the sampling bias problem of the glb does not play a role when the number of test parts is small, as is often the case with congeneric measures. Secondly, glb and unidimensionality based reliability are often equal when there are three test parts, and when there are more test parts, their numerical values are still very similar. To the extent that the bias problem of the greatest lower bound does play a role, unidimensionality-based reliability is equally affected. Although unidimensionality and reliability are often thought of as unrelated, this paper shows that, from at least two perspectives, they act as antagonistic concepts. A measure, based on the same framework that led to the greatest lower bound, is discussed for assessing how close is a set of variables to unidimensionality. It is the percentage of common variance that can be explained by a single factor. An empirical example is given to demonstrate the main points of the paper.},
  langid = {english},
  keywords = {congeneric test,Reliability,unidimensionality of a test},
  file = {/Users/jimmy_z/Zotero/storage/U6XJ7QZ8/Ten Berge and Sočan - 2004 - The greatest lower bound to the reliability of a t.pdf}
}

@article{wuComparisonStrategiesForming2013,
  title = {A Comparison of Strategies for Forming Product Indicators for Unequal Numbers of Items in Structural Equation Models of Latent Interactions},
  author = {Wu, Yan and Wen, Zhonglin and Marsh, Herb and Hau, Kit-Tai},
  year = {2013},
  month = oct,
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {20},
  pages = {551--567},
  doi = {10.1080/10705511.2013.824772},
  abstract = {This Monte Carlo simulation study investigated different strategies for forming product indicators for the unconstrained approach in analyzing latent interaction models when the exogenous factors are measured by unequal numbers of indicators under both normal and nonnormal conditions. Product indicators were created by (a) multiplying parcels of the larger scale by items of the smaller scale, and (b) matching items according to reliability to create several product indicators, ignoring those items with lower reliability. Two scaling approaches were compared where parceling was not involved: (a) fixing the factor variances, and (b) fixing 1 loading to 1 for each factor. The unconstrained approach was compared with the latent moderated structural equations (LMS) approach. Results showed that under normal conditions, the LMS approach was preferred because the biases of its interaction estimates and associated standard errors were generally smaller, and its power was higher than that of the unconstrained approach. Under nonnormal conditions, however, the unconstrained approach was generally more robust than the LMS approach. It is recommended to form product indicators by using items with higher reliability (rather than parceling) in the matching and then to specify the model by fixing 1 loading of each factor to unity when adopting the unconstrained approach.}
}

@article{busemeyerAnalysisMultiplicativeCombination1983a,
  title = {Analysis of Multiplicative Combination Rules When the Causal Variables Are Measured with Error},
  author = {Busemeyer, Jerome R. and Jones, Lawrence E.},
  year = {1983},
  journal = {Psychological Bulletin},
  volume = {93},
  number = {3},
  pages = {549--562},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1455},
  doi = {10.1037/0033-2909.93.3.549},
  abstract = {Evaluates the validity of the observational method used to test multiplicative combination rules with respect to 2 measurement issues: measurement level (i.e., the effects produced by allowing monotonic transformations of the measures) and measurement error (i.e., the effects produced by using unreliable measures of the causal variables). The evaluation is based on a theoretical distinction between the structural model (the set of equations relating theoretical constructs to each other) and the measurement model (the set of equations relating the theoretical constructs to the observed measures). It is concluded that hierarchical regression analysis is inadequate for determining whether the structural model is additive or multiplicative for 2 reasons: First, an additive structural model may produce multiplicative effects through a nonlinear measurement model. Second, a multiplicative structural model may produce nondetectable multiplicative effects because of multiplicative measurement error. Some alternatives to hierarchical regression analysis are described. (35 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Errors,Measurement,Models,Statistical Analysis}
}
